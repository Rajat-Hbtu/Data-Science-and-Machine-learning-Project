{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic survival prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSCCU21x16vbmsHCy08CA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajat-Hbtu/Data-Science-and-Machine-learning-Project/blob/main/titanic_survival_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLxV4qUnfcqO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "mhi-NouSNtth",
        "outputId": "b741682c-9e51-4413-d902-f7779be5d2fb"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9745e518-9350-4abe-822f-ab1194813a63\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9745e518-9350-4abe-822f-ab1194813a63\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train.csv': b'PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\\r\\n1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S\\r\\n2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C\\r\\n3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S\\r\\n4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",female,35,1,0,113803,53.1,C123,S\\r\\n5,0,3,\"Allen, Mr. William Henry\",male,35,0,0,373450,8.05,,S\\r\\n6,0,3,\"Moran, Mr. James\",male,,0,0,330877,8.4583,,Q\\r\\n7,0,1,\"McCarthy, Mr. Timothy J\",male,54,0,0,17463,51.8625,E46,S\\r\\n8,0,3,\"Palsson, Master. Gosta Leonard\",male,2,3,1,349909,21.075,,S\\r\\n9,1,3,\"Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\",female,27,0,2,347742,11.1333,,S\\r\\n10,1,2,\"Nasser, Mrs. Nicholas (Adele Achem)\",female,14,1,0,237736,30.0708,,C\\r\\n11,1,3,\"Sandstrom, Miss. Marguerite Rut\",female,4,1,1,PP 9549,16.7,G6,S\\r\\n12,1,1,\"Bonnell, Miss. Elizabeth\",female,58,0,0,113783,26.55,C103,S\\r\\n13,0,3,\"Saundercock, Mr. William Henry\",male,20,0,0,A/5. 2151,8.05,,S\\r\\n14,0,3,\"Andersson, Mr. Anders Johan\",male,39,1,5,347082,31.275,,S\\r\\n15,0,3,\"Vestrom, Miss. Hulda Amanda Adolfina\",female,14,0,0,350406,7.8542,,S\\r\\n16,1,2,\"Hewlett, Mrs. (Mary D Kingcome) \",female,55,0,0,248706,16,,S\\r\\n17,0,3,\"Rice, Master. Eugene\",male,2,4,1,382652,29.125,,Q\\r\\n18,1,2,\"Williams, Mr. Charles Eugene\",male,,0,0,244373,13,,S\\r\\n19,0,3,\"Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)\",female,31,1,0,345763,18,,S\\r\\n20,1,3,\"Masselmani, Mrs. Fatima\",female,,0,0,2649,7.225,,C\\r\\n21,0,2,\"Fynney, Mr. Joseph J\",male,35,0,0,239865,26,,S\\r\\n22,1,2,\"Beesley, Mr. Lawrence\",male,34,0,0,248698,13,D56,S\\r\\n23,1,3,\"McGowan, Miss. Anna \"\"Annie\"\"\",female,15,0,0,330923,8.0292,,Q\\r\\n24,1,1,\"Sloper, Mr. William Thompson\",male,28,0,0,113788,35.5,A6,S\\r\\n25,0,3,\"Palsson, Miss. Torborg Danira\",female,8,3,1,349909,21.075,,S\\r\\n26,1,3,\"Asplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson)\",female,38,1,5,347077,31.3875,,S\\r\\n27,0,3,\"Emir, Mr. Farred Chehab\",male,,0,0,2631,7.225,,C\\r\\n28,0,1,\"Fortune, Mr. Charles Alexander\",male,19,3,2,19950,263,C23 C25 C27,S\\r\\n29,1,3,\"O\\'Dwyer, Miss. Ellen \"\"Nellie\"\"\",female,,0,0,330959,7.8792,,Q\\r\\n30,0,3,\"Todoroff, Mr. Lalio\",male,,0,0,349216,7.8958,,S\\r\\n31,0,1,\"Uruchurtu, Don. Manuel E\",male,40,0,0,PC 17601,27.7208,,C\\r\\n32,1,1,\"Spencer, Mrs. William Augustus (Marie Eugenie)\",female,,1,0,PC 17569,146.5208,B78,C\\r\\n33,1,3,\"Glynn, Miss. Mary Agatha\",female,,0,0,335677,7.75,,Q\\r\\n34,0,2,\"Wheadon, Mr. Edward H\",male,66,0,0,C.A. 24579,10.5,,S\\r\\n35,0,1,\"Meyer, Mr. Edgar Joseph\",male,28,1,0,PC 17604,82.1708,,C\\r\\n36,0,1,\"Holverson, Mr. Alexander Oskar\",male,42,1,0,113789,52,,S\\r\\n37,1,3,\"Mamee, Mr. Hanna\",male,,0,0,2677,7.2292,,C\\r\\n38,0,3,\"Cann, Mr. Ernest Charles\",male,21,0,0,A./5. 2152,8.05,,S\\r\\n39,0,3,\"Vander Planke, Miss. Augusta Maria\",female,18,2,0,345764,18,,S\\r\\n40,1,3,\"Nicola-Yarred, Miss. Jamila\",female,14,1,0,2651,11.2417,,C\\r\\n41,0,3,\"Ahlin, Mrs. Johan (Johanna Persdotter Larsson)\",female,40,1,0,7546,9.475,,S\\r\\n42,0,2,\"Turpin, Mrs. William John Robert (Dorothy Ann Wonnacott)\",female,27,1,0,11668,21,,S\\r\\n43,0,3,\"Kraeff, Mr. Theodor\",male,,0,0,349253,7.8958,,C\\r\\n44,1,2,\"Laroche, Miss. Simonne Marie Anne Andree\",female,3,1,2,SC/Paris 2123,41.5792,,C\\r\\n45,1,3,\"Devaney, Miss. Margaret Delia\",female,19,0,0,330958,7.8792,,Q\\r\\n46,0,3,\"Rogers, Mr. William John\",male,,0,0,S.C./A.4. 23567,8.05,,S\\r\\n47,0,3,\"Lennon, Mr. Denis\",male,,1,0,370371,15.5,,Q\\r\\n48,1,3,\"O\\'Driscoll, Miss. Bridget\",female,,0,0,14311,7.75,,Q\\r\\n49,0,3,\"Samaan, Mr. Youssef\",male,,2,0,2662,21.6792,,C\\r\\n50,0,3,\"Arnold-Franchi, Mrs. Josef (Josefine Franchi)\",female,18,1,0,349237,17.8,,S\\r\\n51,0,3,\"Panula, Master. Juha Niilo\",male,7,4,1,3101295,39.6875,,S\\r\\n52,0,3,\"Nosworthy, Mr. Richard Cater\",male,21,0,0,A/4. 39886,7.8,,S\\r\\n53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49,1,0,PC 17572,76.7292,D33,C\\r\\n54,1,2,\"Faunthorpe, Mrs. Lizzie (Elizabeth Anne Wilkinson)\",female,29,1,0,2926,26,,S\\r\\n55,0,1,\"Ostby, Mr. Engelhart Cornelius\",male,65,0,1,113509,61.9792,B30,C\\r\\n56,1,1,\"Woolner, Mr. Hugh\",male,,0,0,19947,35.5,C52,S\\r\\n57,1,2,\"Rugg, Miss. Emily\",female,21,0,0,C.A. 31026,10.5,,S\\r\\n58,0,3,\"Novel, Mr. Mansouer\",male,28.5,0,0,2697,7.2292,,C\\r\\n59,1,2,\"West, Miss. Constance Mirium\",female,5,1,2,C.A. 34651,27.75,,S\\r\\n60,0,3,\"Goodwin, Master. William Frederick\",male,11,5,2,CA 2144,46.9,,S\\r\\n61,0,3,\"Sirayanian, Mr. Orsen\",male,22,0,0,2669,7.2292,,C\\r\\n62,1,1,\"Icard, Miss. Amelie\",female,38,0,0,113572,80,B28,\\r\\n63,0,1,\"Harris, Mr. Henry Birkhardt\",male,45,1,0,36973,83.475,C83,S\\r\\n64,0,3,\"Skoog, Master. Harald\",male,4,3,2,347088,27.9,,S\\r\\n65,0,1,\"Stewart, Mr. Albert A\",male,,0,0,PC 17605,27.7208,,C\\r\\n66,1,3,\"Moubarek, Master. Gerios\",male,,1,1,2661,15.2458,,C\\r\\n67,1,2,\"Nye, Mrs. (Elizabeth Ramell)\",female,29,0,0,C.A. 29395,10.5,F33,S\\r\\n68,0,3,\"Crease, Mr. Ernest James\",male,19,0,0,S.P. 3464,8.1583,,S\\r\\n69,1,3,\"Andersson, Miss. Erna Alexandra\",female,17,4,2,3101281,7.925,,S\\r\\n70,0,3,\"Kink, Mr. Vincenz\",male,26,2,0,315151,8.6625,,S\\r\\n71,0,2,\"Jenkin, Mr. Stephen Curnow\",male,32,0,0,C.A. 33111,10.5,,S\\r\\n72,0,3,\"Goodwin, Miss. Lillian Amy\",female,16,5,2,CA 2144,46.9,,S\\r\\n73,0,2,\"Hood, Mr. Ambrose Jr\",male,21,0,0,S.O.C. 14879,73.5,,S\\r\\n74,0,3,\"Chronopoulos, Mr. Apostolos\",male,26,1,0,2680,14.4542,,C\\r\\n75,1,3,\"Bing, Mr. Lee\",male,32,0,0,1601,56.4958,,S\\r\\n76,0,3,\"Moen, Mr. Sigurd Hansen\",male,25,0,0,348123,7.65,F G73,S\\r\\n77,0,3,\"Staneff, Mr. Ivan\",male,,0,0,349208,7.8958,,S\\r\\n78,0,3,\"Moutal, Mr. Rahamin Haim\",male,,0,0,374746,8.05,,S\\r\\n79,1,2,\"Caldwell, Master. Alden Gates\",male,0.83,0,2,248738,29,,S\\r\\n80,1,3,\"Dowdell, Miss. Elizabeth\",female,30,0,0,364516,12.475,,S\\r\\n81,0,3,\"Waelens, Mr. Achille\",male,22,0,0,345767,9,,S\\r\\n82,1,3,\"Sheerlinck, Mr. Jan Baptist\",male,29,0,0,345779,9.5,,S\\r\\n83,1,3,\"McDermott, Miss. Brigdet Delia\",female,,0,0,330932,7.7875,,Q\\r\\n84,0,1,\"Carrau, Mr. Francisco M\",male,28,0,0,113059,47.1,,S\\r\\n85,1,2,\"Ilett, Miss. Bertha\",female,17,0,0,SO/C 14885,10.5,,S\\r\\n86,1,3,\"Backstrom, Mrs. Karl Alfred (Maria Mathilda Gustafsson)\",female,33,3,0,3101278,15.85,,S\\r\\n87,0,3,\"Ford, Mr. William Neal\",male,16,1,3,W./C. 6608,34.375,,S\\r\\n88,0,3,\"Slocovski, Mr. Selman Francis\",male,,0,0,SOTON/OQ 392086,8.05,,S\\r\\n89,1,1,\"Fortune, Miss. Mabel Helen\",female,23,3,2,19950,263,C23 C25 C27,S\\r\\n90,0,3,\"Celotti, Mr. Francesco\",male,24,0,0,343275,8.05,,S\\r\\n91,0,3,\"Christmann, Mr. Emil\",male,29,0,0,343276,8.05,,S\\r\\n92,0,3,\"Andreasson, Mr. Paul Edvin\",male,20,0,0,347466,7.8542,,S\\r\\n93,0,1,\"Chaffee, Mr. Herbert Fuller\",male,46,1,0,W.E.P. 5734,61.175,E31,S\\r\\n94,0,3,\"Dean, Mr. Bertram Frank\",male,26,1,2,C.A. 2315,20.575,,S\\r\\n95,0,3,\"Coxon, Mr. Daniel\",male,59,0,0,364500,7.25,,S\\r\\n96,0,3,\"Shorney, Mr. Charles Joseph\",male,,0,0,374910,8.05,,S\\r\\n97,0,1,\"Goldschmidt, Mr. George B\",male,71,0,0,PC 17754,34.6542,A5,C\\r\\n98,1,1,\"Greenfield, Mr. William Bertram\",male,23,0,1,PC 17759,63.3583,D10 D12,C\\r\\n99,1,2,\"Doling, Mrs. John T (Ada Julia Bone)\",female,34,0,1,231919,23,,S\\r\\n100,0,2,\"Kantor, Mr. Sinai\",male,34,1,0,244367,26,,S\\r\\n101,0,3,\"Petranec, Miss. Matilda\",female,28,0,0,349245,7.8958,,S\\r\\n102,0,3,\"Petroff, Mr. Pastcho (\"\"Pentcho\"\")\",male,,0,0,349215,7.8958,,S\\r\\n103,0,1,\"White, Mr. Richard Frasar\",male,21,0,1,35281,77.2875,D26,S\\r\\n104,0,3,\"Johansson, Mr. Gustaf Joel\",male,33,0,0,7540,8.6542,,S\\r\\n105,0,3,\"Gustafsson, Mr. Anders Vilhelm\",male,37,2,0,3101276,7.925,,S\\r\\n106,0,3,\"Mionoff, Mr. Stoytcho\",male,28,0,0,349207,7.8958,,S\\r\\n107,1,3,\"Salkjelsvik, Miss. Anna Kristine\",female,21,0,0,343120,7.65,,S\\r\\n108,1,3,\"Moss, Mr. Albert Johan\",male,,0,0,312991,7.775,,S\\r\\n109,0,3,\"Rekic, Mr. Tido\",male,38,0,0,349249,7.8958,,S\\r\\n110,1,3,\"Moran, Miss. Bertha\",female,,1,0,371110,24.15,,Q\\r\\n111,0,1,\"Porter, Mr. Walter Chamberlain\",male,47,0,0,110465,52,C110,S\\r\\n112,0,3,\"Zabour, Miss. Hileni\",female,14.5,1,0,2665,14.4542,,C\\r\\n113,0,3,\"Barton, Mr. David John\",male,22,0,0,324669,8.05,,S\\r\\n114,0,3,\"Jussila, Miss. Katriina\",female,20,1,0,4136,9.825,,S\\r\\n115,0,3,\"Attalah, Miss. Malake\",female,17,0,0,2627,14.4583,,C\\r\\n116,0,3,\"Pekoniemi, Mr. Edvard\",male,21,0,0,STON/O 2. 3101294,7.925,,S\\r\\n117,0,3,\"Connors, Mr. Patrick\",male,70.5,0,0,370369,7.75,,Q\\r\\n118,0,2,\"Turpin, Mr. William John Robert\",male,29,1,0,11668,21,,S\\r\\n119,0,1,\"Baxter, Mr. Quigg Edmond\",male,24,0,1,PC 17558,247.5208,B58 B60,C\\r\\n120,0,3,\"Andersson, Miss. Ellis Anna Maria\",female,2,4,2,347082,31.275,,S\\r\\n121,0,2,\"Hickman, Mr. Stanley George\",male,21,2,0,S.O.C. 14879,73.5,,S\\r\\n122,0,3,\"Moore, Mr. Leonard Charles\",male,,0,0,A4. 54510,8.05,,S\\r\\n123,0,2,\"Nasser, Mr. Nicholas\",male,32.5,1,0,237736,30.0708,,C\\r\\n124,1,2,\"Webber, Miss. Susan\",female,32.5,0,0,27267,13,E101,S\\r\\n125,0,1,\"White, Mr. Percival Wayland\",male,54,0,1,35281,77.2875,D26,S\\r\\n126,1,3,\"Nicola-Yarred, Master. Elias\",male,12,1,0,2651,11.2417,,C\\r\\n127,0,3,\"McMahon, Mr. Martin\",male,,0,0,370372,7.75,,Q\\r\\n128,1,3,\"Madsen, Mr. Fridtjof Arne\",male,24,0,0,C 17369,7.1417,,S\\r\\n129,1,3,\"Peter, Miss. Anna\",female,,1,1,2668,22.3583,F E69,C\\r\\n130,0,3,\"Ekstrom, Mr. Johan\",male,45,0,0,347061,6.975,,S\\r\\n131,0,3,\"Drazenoic, Mr. Jozef\",male,33,0,0,349241,7.8958,,C\\r\\n132,0,3,\"Coelho, Mr. Domingos Fernandeo\",male,20,0,0,SOTON/O.Q. 3101307,7.05,,S\\r\\n133,0,3,\"Robins, Mrs. Alexander A (Grace Charity Laury)\",female,47,1,0,A/5. 3337,14.5,,S\\r\\n134,1,2,\"Weisz, Mrs. Leopold (Mathilde Francoise Pede)\",female,29,1,0,228414,26,,S\\r\\n135,0,2,\"Sobey, Mr. Samuel James Hayden\",male,25,0,0,C.A. 29178,13,,S\\r\\n136,0,2,\"Richard, Mr. Emile\",male,23,0,0,SC/PARIS 2133,15.0458,,C\\r\\n137,1,1,\"Newsom, Miss. Helen Monypeny\",female,19,0,2,11752,26.2833,D47,S\\r\\n138,0,1,\"Futrelle, Mr. Jacques Heath\",male,37,1,0,113803,53.1,C123,S\\r\\n139,0,3,\"Osen, Mr. Olaf Elon\",male,16,0,0,7534,9.2167,,S\\r\\n140,0,1,\"Giglio, Mr. Victor\",male,24,0,0,PC 17593,79.2,B86,C\\r\\n141,0,3,\"Boulos, Mrs. Joseph (Sultana)\",female,,0,2,2678,15.2458,,C\\r\\n142,1,3,\"Nysten, Miss. Anna Sofia\",female,22,0,0,347081,7.75,,S\\r\\n143,1,3,\"Hakkarainen, Mrs. Pekka Pietari (Elin Matilda Dolck)\",female,24,1,0,STON/O2. 3101279,15.85,,S\\r\\n144,0,3,\"Burke, Mr. Jeremiah\",male,19,0,0,365222,6.75,,Q\\r\\n145,0,2,\"Andrew, Mr. Edgardo Samuel\",male,18,0,0,231945,11.5,,S\\r\\n146,0,2,\"Nicholls, Mr. Joseph Charles\",male,19,1,1,C.A. 33112,36.75,,S\\r\\n147,1,3,\"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\",male,27,0,0,350043,7.7958,,S\\r\\n148,0,3,\"Ford, Miss. Robina Maggie \"\"Ruby\"\"\",female,9,2,2,W./C. 6608,34.375,,S\\r\\n149,0,2,\"Navratil, Mr. Michel (\"\"Louis M Hoffman\"\")\",male,36.5,0,2,230080,26,F2,S\\r\\n150,0,2,\"Byles, Rev. Thomas Roussel Davids\",male,42,0,0,244310,13,,S\\r\\n151,0,2,\"Bateman, Rev. Robert James\",male,51,0,0,S.O.P. 1166,12.525,,S\\r\\n152,1,1,\"Pears, Mrs. Thomas (Edith Wearne)\",female,22,1,0,113776,66.6,C2,S\\r\\n153,0,3,\"Meo, Mr. Alfonzo\",male,55.5,0,0,A.5. 11206,8.05,,S\\r\\n154,0,3,\"van Billiard, Mr. Austin Blyler\",male,40.5,0,2,A/5. 851,14.5,,S\\r\\n155,0,3,\"Olsen, Mr. Ole Martin\",male,,0,0,Fa 265302,7.3125,,S\\r\\n156,0,1,\"Williams, Mr. Charles Duane\",male,51,0,1,PC 17597,61.3792,,C\\r\\n157,1,3,\"Gilnagh, Miss. Katherine \"\"Katie\"\"\",female,16,0,0,35851,7.7333,,Q\\r\\n158,0,3,\"Corn, Mr. Harry\",male,30,0,0,SOTON/OQ 392090,8.05,,S\\r\\n159,0,3,\"Smiljanic, Mr. Mile\",male,,0,0,315037,8.6625,,S\\r\\n160,0,3,\"Sage, Master. Thomas Henry\",male,,8,2,CA. 2343,69.55,,S\\r\\n161,0,3,\"Cribb, Mr. John Hatfield\",male,44,0,1,371362,16.1,,S\\r\\n162,1,2,\"Watt, Mrs. James (Elizabeth \"\"Bessie\"\" Inglis Milne)\",female,40,0,0,C.A. 33595,15.75,,S\\r\\n163,0,3,\"Bengtsson, Mr. John Viktor\",male,26,0,0,347068,7.775,,S\\r\\n164,0,3,\"Calic, Mr. Jovo\",male,17,0,0,315093,8.6625,,S\\r\\n165,0,3,\"Panula, Master. Eino Viljami\",male,1,4,1,3101295,39.6875,,S\\r\\n166,1,3,\"Goldsmith, Master. Frank John William \"\"Frankie\"\"\",male,9,0,2,363291,20.525,,S\\r\\n167,1,1,\"Chibnall, Mrs. (Edith Martha Bowerman)\",female,,0,1,113505,55,E33,S\\r\\n168,0,3,\"Skoog, Mrs. William (Anna Bernhardina Karlsson)\",female,45,1,4,347088,27.9,,S\\r\\n169,0,1,\"Baumann, Mr. John D\",male,,0,0,PC 17318,25.925,,S\\r\\n170,0,3,\"Ling, Mr. Lee\",male,28,0,0,1601,56.4958,,S\\r\\n171,0,1,\"Van der hoef, Mr. Wyckoff\",male,61,0,0,111240,33.5,B19,S\\r\\n172,0,3,\"Rice, Master. Arthur\",male,4,4,1,382652,29.125,,Q\\r\\n173,1,3,\"Johnson, Miss. Eleanor Ileen\",female,1,1,1,347742,11.1333,,S\\r\\n174,0,3,\"Sivola, Mr. Antti Wilhelm\",male,21,0,0,STON/O 2. 3101280,7.925,,S\\r\\n175,0,1,\"Smith, Mr. James Clinch\",male,56,0,0,17764,30.6958,A7,C\\r\\n176,0,3,\"Klasen, Mr. Klas Albin\",male,18,1,1,350404,7.8542,,S\\r\\n177,0,3,\"Lefebre, Master. Henry Forbes\",male,,3,1,4133,25.4667,,S\\r\\n178,0,1,\"Isham, Miss. Ann Elizabeth\",female,50,0,0,PC 17595,28.7125,C49,C\\r\\n179,0,2,\"Hale, Mr. Reginald\",male,30,0,0,250653,13,,S\\r\\n180,0,3,\"Leonard, Mr. Lionel\",male,36,0,0,LINE,0,,S\\r\\n181,0,3,\"Sage, Miss. Constance Gladys\",female,,8,2,CA. 2343,69.55,,S\\r\\n182,0,2,\"Pernot, Mr. Rene\",male,,0,0,SC/PARIS 2131,15.05,,C\\r\\n183,0,3,\"Asplund, Master. Clarence Gustaf Hugo\",male,9,4,2,347077,31.3875,,S\\r\\n184,1,2,\"Becker, Master. Richard F\",male,1,2,1,230136,39,F4,S\\r\\n185,1,3,\"Kink-Heilmann, Miss. Luise Gretchen\",female,4,0,2,315153,22.025,,S\\r\\n186,0,1,\"Rood, Mr. Hugh Roscoe\",male,,0,0,113767,50,A32,S\\r\\n187,1,3,\"O\\'Brien, Mrs. Thomas (Johanna \"\"Hannah\"\" Godfrey)\",female,,1,0,370365,15.5,,Q\\r\\n188,1,1,\"Romaine, Mr. Charles Hallace (\"\"Mr C Rolmane\"\")\",male,45,0,0,111428,26.55,,S\\r\\n189,0,3,\"Bourke, Mr. John\",male,40,1,1,364849,15.5,,Q\\r\\n190,0,3,\"Turcin, Mr. Stjepan\",male,36,0,0,349247,7.8958,,S\\r\\n191,1,2,\"Pinsky, Mrs. (Rosa)\",female,32,0,0,234604,13,,S\\r\\n192,0,2,\"Carbines, Mr. William\",male,19,0,0,28424,13,,S\\r\\n193,1,3,\"Andersen-Jensen, Miss. Carla Christine Nielsine\",female,19,1,0,350046,7.8542,,S\\r\\n194,1,2,\"Navratil, Master. Michel M\",male,3,1,1,230080,26,F2,S\\r\\n195,1,1,\"Brown, Mrs. James Joseph (Margaret Tobin)\",female,44,0,0,PC 17610,27.7208,B4,C\\r\\n196,1,1,\"Lurette, Miss. Elise\",female,58,0,0,PC 17569,146.5208,B80,C\\r\\n197,0,3,\"Mernagh, Mr. Robert\",male,,0,0,368703,7.75,,Q\\r\\n198,0,3,\"Olsen, Mr. Karl Siegwart Andreas\",male,42,0,1,4579,8.4042,,S\\r\\n199,1,3,\"Madigan, Miss. Margaret \"\"Maggie\"\"\",female,,0,0,370370,7.75,,Q\\r\\n200,0,2,\"Yrois, Miss. Henriette (\"\"Mrs Harbeck\"\")\",female,24,0,0,248747,13,,S\\r\\n201,0,3,\"Vande Walle, Mr. Nestor Cyriel\",male,28,0,0,345770,9.5,,S\\r\\n202,0,3,\"Sage, Mr. Frederick\",male,,8,2,CA. 2343,69.55,,S\\r\\n203,0,3,\"Johanson, Mr. Jakob Alfred\",male,34,0,0,3101264,6.4958,,S\\r\\n204,0,3,\"Youseff, Mr. Gerious\",male,45.5,0,0,2628,7.225,,C\\r\\n205,1,3,\"Cohen, Mr. Gurshon \"\"Gus\"\"\",male,18,0,0,A/5 3540,8.05,,S\\r\\n206,0,3,\"Strom, Miss. Telma Matilda\",female,2,0,1,347054,10.4625,G6,S\\r\\n207,0,3,\"Backstrom, Mr. Karl Alfred\",male,32,1,0,3101278,15.85,,S\\r\\n208,1,3,\"Albimona, Mr. Nassef Cassem\",male,26,0,0,2699,18.7875,,C\\r\\n209,1,3,\"Carr, Miss. Helen \"\"Ellen\"\"\",female,16,0,0,367231,7.75,,Q\\r\\n210,1,1,\"Blank, Mr. Henry\",male,40,0,0,112277,31,A31,C\\r\\n211,0,3,\"Ali, Mr. Ahmed\",male,24,0,0,SOTON/O.Q. 3101311,7.05,,S\\r\\n212,1,2,\"Cameron, Miss. Clear Annie\",female,35,0,0,F.C.C. 13528,21,,S\\r\\n213,0,3,\"Perkin, Mr. John Henry\",male,22,0,0,A/5 21174,7.25,,S\\r\\n214,0,2,\"Givard, Mr. Hans Kristensen\",male,30,0,0,250646,13,,S\\r\\n215,0,3,\"Kiernan, Mr. Philip\",male,,1,0,367229,7.75,,Q\\r\\n216,1,1,\"Newell, Miss. Madeleine\",female,31,1,0,35273,113.275,D36,C\\r\\n217,1,3,\"Honkanen, Miss. Eliina\",female,27,0,0,STON/O2. 3101283,7.925,,S\\r\\n218,0,2,\"Jacobsohn, Mr. Sidney Samuel\",male,42,1,0,243847,27,,S\\r\\n219,1,1,\"Bazzani, Miss. Albina\",female,32,0,0,11813,76.2917,D15,C\\r\\n220,0,2,\"Harris, Mr. Walter\",male,30,0,0,W/C 14208,10.5,,S\\r\\n221,1,3,\"Sunderland, Mr. Victor Francis\",male,16,0,0,SOTON/OQ 392089,8.05,,S\\r\\n222,0,2,\"Bracken, Mr. James H\",male,27,0,0,220367,13,,S\\r\\n223,0,3,\"Green, Mr. George Henry\",male,51,0,0,21440,8.05,,S\\r\\n224,0,3,\"Nenkoff, Mr. Christo\",male,,0,0,349234,7.8958,,S\\r\\n225,1,1,\"Hoyt, Mr. Frederick Maxfield\",male,38,1,0,19943,90,C93,S\\r\\n226,0,3,\"Berglund, Mr. Karl Ivar Sven\",male,22,0,0,PP 4348,9.35,,S\\r\\n227,1,2,\"Mellors, Mr. William John\",male,19,0,0,SW/PP 751,10.5,,S\\r\\n228,0,3,\"Lovell, Mr. John Hall (\"\"Henry\"\")\",male,20.5,0,0,A/5 21173,7.25,,S\\r\\n229,0,2,\"Fahlstrom, Mr. Arne Jonas\",male,18,0,0,236171,13,,S\\r\\n230,0,3,\"Lefebre, Miss. Mathilde\",female,,3,1,4133,25.4667,,S\\r\\n231,1,1,\"Harris, Mrs. Henry Birkhardt (Irene Wallach)\",female,35,1,0,36973,83.475,C83,S\\r\\n232,0,3,\"Larsson, Mr. Bengt Edvin\",male,29,0,0,347067,7.775,,S\\r\\n233,0,2,\"Sjostedt, Mr. Ernst Adolf\",male,59,0,0,237442,13.5,,S\\r\\n234,1,3,\"Asplund, Miss. Lillian Gertrud\",female,5,4,2,347077,31.3875,,S\\r\\n235,0,2,\"Leyson, Mr. Robert William Norman\",male,24,0,0,C.A. 29566,10.5,,S\\r\\n236,0,3,\"Harknett, Miss. Alice Phoebe\",female,,0,0,W./C. 6609,7.55,,S\\r\\n237,0,2,\"Hold, Mr. Stephen\",male,44,1,0,26707,26,,S\\r\\n238,1,2,\"Collyer, Miss. Marjorie \"\"Lottie\"\"\",female,8,0,2,C.A. 31921,26.25,,S\\r\\n239,0,2,\"Pengelly, Mr. Frederick William\",male,19,0,0,28665,10.5,,S\\r\\n240,0,2,\"Hunt, Mr. George Henry\",male,33,0,0,SCO/W 1585,12.275,,S\\r\\n241,0,3,\"Zabour, Miss. Thamine\",female,,1,0,2665,14.4542,,C\\r\\n242,1,3,\"Murphy, Miss. Katherine \"\"Kate\"\"\",female,,1,0,367230,15.5,,Q\\r\\n243,0,2,\"Coleridge, Mr. Reginald Charles\",male,29,0,0,W./C. 14263,10.5,,S\\r\\n244,0,3,\"Maenpaa, Mr. Matti Alexanteri\",male,22,0,0,STON/O 2. 3101275,7.125,,S\\r\\n245,0,3,\"Attalah, Mr. Sleiman\",male,30,0,0,2694,7.225,,C\\r\\n246,0,1,\"Minahan, Dr. William Edward\",male,44,2,0,19928,90,C78,Q\\r\\n247,0,3,\"Lindahl, Miss. Agda Thorilda Viktoria\",female,25,0,0,347071,7.775,,S\\r\\n248,1,2,\"Hamalainen, Mrs. William (Anna)\",female,24,0,2,250649,14.5,,S\\r\\n249,1,1,\"Beckwith, Mr. Richard Leonard\",male,37,1,1,11751,52.5542,D35,S\\r\\n250,0,2,\"Carter, Rev. Ernest Courtenay\",male,54,1,0,244252,26,,S\\r\\n251,0,3,\"Reed, Mr. James George\",male,,0,0,362316,7.25,,S\\r\\n252,0,3,\"Strom, Mrs. Wilhelm (Elna Matilda Persson)\",female,29,1,1,347054,10.4625,G6,S\\r\\n253,0,1,\"Stead, Mr. William Thomas\",male,62,0,0,113514,26.55,C87,S\\r\\n254,0,3,\"Lobb, Mr. William Arthur\",male,30,1,0,A/5. 3336,16.1,,S\\r\\n255,0,3,\"Rosblom, Mrs. Viktor (Helena Wilhelmina)\",female,41,0,2,370129,20.2125,,S\\r\\n256,1,3,\"Touma, Mrs. Darwis (Hanne Youssef Razi)\",female,29,0,2,2650,15.2458,,C\\r\\n257,1,1,\"Thorne, Mrs. Gertrude Maybelle\",female,,0,0,PC 17585,79.2,,C\\r\\n258,1,1,\"Cherry, Miss. Gladys\",female,30,0,0,110152,86.5,B77,S\\r\\n259,1,1,\"Ward, Miss. Anna\",female,35,0,0,PC 17755,512.3292,,C\\r\\n260,1,2,\"Parrish, Mrs. (Lutie Davis)\",female,50,0,1,230433,26,,S\\r\\n261,0,3,\"Smith, Mr. Thomas\",male,,0,0,384461,7.75,,Q\\r\\n262,1,3,\"Asplund, Master. Edvin Rojj Felix\",male,3,4,2,347077,31.3875,,S\\r\\n263,0,1,\"Taussig, Mr. Emil\",male,52,1,1,110413,79.65,E67,S\\r\\n264,0,1,\"Harrison, Mr. William\",male,40,0,0,112059,0,B94,S\\r\\n265,0,3,\"Henry, Miss. Delia\",female,,0,0,382649,7.75,,Q\\r\\n266,0,2,\"Reeves, Mr. David\",male,36,0,0,C.A. 17248,10.5,,S\\r\\n267,0,3,\"Panula, Mr. Ernesti Arvid\",male,16,4,1,3101295,39.6875,,S\\r\\n268,1,3,\"Persson, Mr. Ernst Ulrik\",male,25,1,0,347083,7.775,,S\\r\\n269,1,1,\"Graham, Mrs. William Thompson (Edith Junkins)\",female,58,0,1,PC 17582,153.4625,C125,S\\r\\n270,1,1,\"Bissette, Miss. Amelia\",female,35,0,0,PC 17760,135.6333,C99,S\\r\\n271,0,1,\"Cairns, Mr. Alexander\",male,,0,0,113798,31,,S\\r\\n272,1,3,\"Tornquist, Mr. William Henry\",male,25,0,0,LINE,0,,S\\r\\n273,1,2,\"Mellinger, Mrs. (Elizabeth Anne Maidment)\",female,41,0,1,250644,19.5,,S\\r\\n274,0,1,\"Natsch, Mr. Charles H\",male,37,0,1,PC 17596,29.7,C118,C\\r\\n275,1,3,\"Healy, Miss. Hanora \"\"Nora\"\"\",female,,0,0,370375,7.75,,Q\\r\\n276,1,1,\"Andrews, Miss. Kornelia Theodosia\",female,63,1,0,13502,77.9583,D7,S\\r\\n277,0,3,\"Lindblom, Miss. Augusta Charlotta\",female,45,0,0,347073,7.75,,S\\r\\n278,0,2,\"Parkes, Mr. Francis \"\"Frank\"\"\",male,,0,0,239853,0,,S\\r\\n279,0,3,\"Rice, Master. Eric\",male,7,4,1,382652,29.125,,Q\\r\\n280,1,3,\"Abbott, Mrs. Stanton (Rosa Hunt)\",female,35,1,1,C.A. 2673,20.25,,S\\r\\n281,0,3,\"Duane, Mr. Frank\",male,65,0,0,336439,7.75,,Q\\r\\n282,0,3,\"Olsson, Mr. Nils Johan Goransson\",male,28,0,0,347464,7.8542,,S\\r\\n283,0,3,\"de Pelsmaeker, Mr. Alfons\",male,16,0,0,345778,9.5,,S\\r\\n284,1,3,\"Dorking, Mr. Edward Arthur\",male,19,0,0,A/5. 10482,8.05,,S\\r\\n285,0,1,\"Smith, Mr. Richard William\",male,,0,0,113056,26,A19,S\\r\\n286,0,3,\"Stankovic, Mr. Ivan\",male,33,0,0,349239,8.6625,,C\\r\\n287,1,3,\"de Mulder, Mr. Theodore\",male,30,0,0,345774,9.5,,S\\r\\n288,0,3,\"Naidenoff, Mr. Penko\",male,22,0,0,349206,7.8958,,S\\r\\n289,1,2,\"Hosono, Mr. Masabumi\",male,42,0,0,237798,13,,S\\r\\n290,1,3,\"Connolly, Miss. Kate\",female,22,0,0,370373,7.75,,Q\\r\\n291,1,1,\"Barber, Miss. Ellen \"\"Nellie\"\"\",female,26,0,0,19877,78.85,,S\\r\\n292,1,1,\"Bishop, Mrs. Dickinson H (Helen Walton)\",female,19,1,0,11967,91.0792,B49,C\\r\\n293,0,2,\"Levy, Mr. Rene Jacques\",male,36,0,0,SC/Paris 2163,12.875,D,C\\r\\n294,0,3,\"Haas, Miss. Aloisia\",female,24,0,0,349236,8.85,,S\\r\\n295,0,3,\"Mineff, Mr. Ivan\",male,24,0,0,349233,7.8958,,S\\r\\n296,0,1,\"Lewy, Mr. Ervin G\",male,,0,0,PC 17612,27.7208,,C\\r\\n297,0,3,\"Hanna, Mr. Mansour\",male,23.5,0,0,2693,7.2292,,C\\r\\n298,0,1,\"Allison, Miss. Helen Loraine\",female,2,1,2,113781,151.55,C22 C26,S\\r\\n299,1,1,\"Saalfeld, Mr. Adolphe\",male,,0,0,19988,30.5,C106,S\\r\\n300,1,1,\"Baxter, Mrs. James (Helene DeLaudeniere Chaput)\",female,50,0,1,PC 17558,247.5208,B58 B60,C\\r\\n301,1,3,\"Kelly, Miss. Anna Katherine \"\"Annie Kate\"\"\",female,,0,0,9234,7.75,,Q\\r\\n302,1,3,\"McCoy, Mr. Bernard\",male,,2,0,367226,23.25,,Q\\r\\n303,0,3,\"Johnson, Mr. William Cahoone Jr\",male,19,0,0,LINE,0,,S\\r\\n304,1,2,\"Keane, Miss. Nora A\",female,,0,0,226593,12.35,E101,Q\\r\\n305,0,3,\"Williams, Mr. Howard Hugh \"\"Harry\"\"\",male,,0,0,A/5 2466,8.05,,S\\r\\n306,1,1,\"Allison, Master. Hudson Trevor\",male,0.92,1,2,113781,151.55,C22 C26,S\\r\\n307,1,1,\"Fleming, Miss. Margaret\",female,,0,0,17421,110.8833,,C\\r\\n308,1,1,\"Penasco y Castellana, Mrs. Victor de Satode (Maria Josefa Perez de Soto y Vallejo)\",female,17,1,0,PC 17758,108.9,C65,C\\r\\n309,0,2,\"Abelson, Mr. Samuel\",male,30,1,0,P/PP 3381,24,,C\\r\\n310,1,1,\"Francatelli, Miss. Laura Mabel\",female,30,0,0,PC 17485,56.9292,E36,C\\r\\n311,1,1,\"Hays, Miss. Margaret Bechstein\",female,24,0,0,11767,83.1583,C54,C\\r\\n312,1,1,\"Ryerson, Miss. Emily Borie\",female,18,2,2,PC 17608,262.375,B57 B59 B63 B66,C\\r\\n313,0,2,\"Lahtinen, Mrs. William (Anna Sylfven)\",female,26,1,1,250651,26,,S\\r\\n314,0,3,\"Hendekovic, Mr. Ignjac\",male,28,0,0,349243,7.8958,,S\\r\\n315,0,2,\"Hart, Mr. Benjamin\",male,43,1,1,F.C.C. 13529,26.25,,S\\r\\n316,1,3,\"Nilsson, Miss. Helmina Josefina\",female,26,0,0,347470,7.8542,,S\\r\\n317,1,2,\"Kantor, Mrs. Sinai (Miriam Sternin)\",female,24,1,0,244367,26,,S\\r\\n318,0,2,\"Moraweck, Dr. Ernest\",male,54,0,0,29011,14,,S\\r\\n319,1,1,\"Wick, Miss. Mary Natalie\",female,31,0,2,36928,164.8667,C7,S\\r\\n320,1,1,\"Spedden, Mrs. Frederic Oakley (Margaretta Corning Stone)\",female,40,1,1,16966,134.5,E34,C\\r\\n321,0,3,\"Dennis, Mr. Samuel\",male,22,0,0,A/5 21172,7.25,,S\\r\\n322,0,3,\"Danoff, Mr. Yoto\",male,27,0,0,349219,7.8958,,S\\r\\n323,1,2,\"Slayter, Miss. Hilda Mary\",female,30,0,0,234818,12.35,,Q\\r\\n324,1,2,\"Caldwell, Mrs. Albert Francis (Sylvia Mae Harbaugh)\",female,22,1,1,248738,29,,S\\r\\n325,0,3,\"Sage, Mr. George John Jr\",male,,8,2,CA. 2343,69.55,,S\\r\\n326,1,1,\"Young, Miss. Marie Grice\",female,36,0,0,PC 17760,135.6333,C32,C\\r\\n327,0,3,\"Nysveen, Mr. Johan Hansen\",male,61,0,0,345364,6.2375,,S\\r\\n328,1,2,\"Ball, Mrs. (Ada E Hall)\",female,36,0,0,28551,13,D,S\\r\\n329,1,3,\"Goldsmith, Mrs. Frank John (Emily Alice Brown)\",female,31,1,1,363291,20.525,,S\\r\\n330,1,1,\"Hippach, Miss. Jean Gertrude\",female,16,0,1,111361,57.9792,B18,C\\r\\n331,1,3,\"McCoy, Miss. Agnes\",female,,2,0,367226,23.25,,Q\\r\\n332,0,1,\"Partner, Mr. Austen\",male,45.5,0,0,113043,28.5,C124,S\\r\\n333,0,1,\"Graham, Mr. George Edward\",male,38,0,1,PC 17582,153.4625,C91,S\\r\\n334,0,3,\"Vander Planke, Mr. Leo Edmondus\",male,16,2,0,345764,18,,S\\r\\n335,1,1,\"Frauenthal, Mrs. Henry William (Clara Heinsheimer)\",female,,1,0,PC 17611,133.65,,S\\r\\n336,0,3,\"Denkoff, Mr. Mitto\",male,,0,0,349225,7.8958,,S\\r\\n337,0,1,\"Pears, Mr. Thomas Clinton\",male,29,1,0,113776,66.6,C2,S\\r\\n338,1,1,\"Burns, Miss. Elizabeth Margaret\",female,41,0,0,16966,134.5,E40,C\\r\\n339,1,3,\"Dahl, Mr. Karl Edwart\",male,45,0,0,7598,8.05,,S\\r\\n340,0,1,\"Blackwell, Mr. Stephen Weart\",male,45,0,0,113784,35.5,T,S\\r\\n341,1,2,\"Navratil, Master. Edmond Roger\",male,2,1,1,230080,26,F2,S\\r\\n342,1,1,\"Fortune, Miss. Alice Elizabeth\",female,24,3,2,19950,263,C23 C25 C27,S\\r\\n343,0,2,\"Collander, Mr. Erik Gustaf\",male,28,0,0,248740,13,,S\\r\\n344,0,2,\"Sedgwick, Mr. Charles Frederick Waddington\",male,25,0,0,244361,13,,S\\r\\n345,0,2,\"Fox, Mr. Stanley Hubert\",male,36,0,0,229236,13,,S\\r\\n346,1,2,\"Brown, Miss. Amelia \"\"Mildred\"\"\",female,24,0,0,248733,13,F33,S\\r\\n347,1,2,\"Smith, Miss. Marion Elsie\",female,40,0,0,31418,13,,S\\r\\n348,1,3,\"Davison, Mrs. Thomas Henry (Mary E Finck)\",female,,1,0,386525,16.1,,S\\r\\n349,1,3,\"Coutts, Master. William Loch \"\"William\"\"\",male,3,1,1,C.A. 37671,15.9,,S\\r\\n350,0,3,\"Dimic, Mr. Jovan\",male,42,0,0,315088,8.6625,,S\\r\\n351,0,3,\"Odahl, Mr. Nils Martin\",male,23,0,0,7267,9.225,,S\\r\\n352,0,1,\"Williams-Lambert, Mr. Fletcher Fellows\",male,,0,0,113510,35,C128,S\\r\\n353,0,3,\"Elias, Mr. Tannous\",male,15,1,1,2695,7.2292,,C\\r\\n354,0,3,\"Arnold-Franchi, Mr. Josef\",male,25,1,0,349237,17.8,,S\\r\\n355,0,3,\"Yousif, Mr. Wazli\",male,,0,0,2647,7.225,,C\\r\\n356,0,3,\"Vanden Steen, Mr. Leo Peter\",male,28,0,0,345783,9.5,,S\\r\\n357,1,1,\"Bowerman, Miss. Elsie Edith\",female,22,0,1,113505,55,E33,S\\r\\n358,0,2,\"Funk, Miss. Annie Clemmer\",female,38,0,0,237671,13,,S\\r\\n359,1,3,\"McGovern, Miss. Mary\",female,,0,0,330931,7.8792,,Q\\r\\n360,1,3,\"Mockler, Miss. Helen Mary \"\"Ellie\"\"\",female,,0,0,330980,7.8792,,Q\\r\\n361,0,3,\"Skoog, Mr. Wilhelm\",male,40,1,4,347088,27.9,,S\\r\\n362,0,2,\"del Carlo, Mr. Sebastiano\",male,29,1,0,SC/PARIS 2167,27.7208,,C\\r\\n363,0,3,\"Barbara, Mrs. (Catherine David)\",female,45,0,1,2691,14.4542,,C\\r\\n364,0,3,\"Asim, Mr. Adola\",male,35,0,0,SOTON/O.Q. 3101310,7.05,,S\\r\\n365,0,3,\"O\\'Brien, Mr. Thomas\",male,,1,0,370365,15.5,,Q\\r\\n366,0,3,\"Adahl, Mr. Mauritz Nils Martin\",male,30,0,0,C 7076,7.25,,S\\r\\n367,1,1,\"Warren, Mrs. Frank Manley (Anna Sophia Atkinson)\",female,60,1,0,110813,75.25,D37,C\\r\\n368,1,3,\"Moussa, Mrs. (Mantoura Boulos)\",female,,0,0,2626,7.2292,,C\\r\\n369,1,3,\"Jermyn, Miss. Annie\",female,,0,0,14313,7.75,,Q\\r\\n370,1,1,\"Aubart, Mme. Leontine Pauline\",female,24,0,0,PC 17477,69.3,B35,C\\r\\n371,1,1,\"Harder, Mr. George Achilles\",male,25,1,0,11765,55.4417,E50,C\\r\\n372,0,3,\"Wiklund, Mr. Jakob Alfred\",male,18,1,0,3101267,6.4958,,S\\r\\n373,0,3,\"Beavan, Mr. William Thomas\",male,19,0,0,323951,8.05,,S\\r\\n374,0,1,\"Ringhini, Mr. Sante\",male,22,0,0,PC 17760,135.6333,,C\\r\\n375,0,3,\"Palsson, Miss. Stina Viola\",female,3,3,1,349909,21.075,,S\\r\\n376,1,1,\"Meyer, Mrs. Edgar Joseph (Leila Saks)\",female,,1,0,PC 17604,82.1708,,C\\r\\n377,1,3,\"Landergren, Miss. Aurora Adelia\",female,22,0,0,C 7077,7.25,,S\\r\\n378,0,1,\"Widener, Mr. Harry Elkins\",male,27,0,2,113503,211.5,C82,C\\r\\n379,0,3,\"Betros, Mr. Tannous\",male,20,0,0,2648,4.0125,,C\\r\\n380,0,3,\"Gustafsson, Mr. Karl Gideon\",male,19,0,0,347069,7.775,,S\\r\\n381,1,1,\"Bidois, Miss. Rosalie\",female,42,0,0,PC 17757,227.525,,C\\r\\n382,1,3,\"Nakid, Miss. Maria (\"\"Mary\"\")\",female,1,0,2,2653,15.7417,,C\\r\\n383,0,3,\"Tikkanen, Mr. Juho\",male,32,0,0,STON/O 2. 3101293,7.925,,S\\r\\n384,1,1,\"Holverson, Mrs. Alexander Oskar (Mary Aline Towner)\",female,35,1,0,113789,52,,S\\r\\n385,0,3,\"Plotcharsky, Mr. Vasil\",male,,0,0,349227,7.8958,,S\\r\\n386,0,2,\"Davies, Mr. Charles Henry\",male,18,0,0,S.O.C. 14879,73.5,,S\\r\\n387,0,3,\"Goodwin, Master. Sidney Leonard\",male,1,5,2,CA 2144,46.9,,S\\r\\n388,1,2,\"Buss, Miss. Kate\",female,36,0,0,27849,13,,S\\r\\n389,0,3,\"Sadlier, Mr. Matthew\",male,,0,0,367655,7.7292,,Q\\r\\n390,1,2,\"Lehmann, Miss. Bertha\",female,17,0,0,SC 1748,12,,C\\r\\n391,1,1,\"Carter, Mr. William Ernest\",male,36,1,2,113760,120,B96 B98,S\\r\\n392,1,3,\"Jansson, Mr. Carl Olof\",male,21,0,0,350034,7.7958,,S\\r\\n393,0,3,\"Gustafsson, Mr. Johan Birger\",male,28,2,0,3101277,7.925,,S\\r\\n394,1,1,\"Newell, Miss. Marjorie\",female,23,1,0,35273,113.275,D36,C\\r\\n395,1,3,\"Sandstrom, Mrs. Hjalmar (Agnes Charlotta Bengtsson)\",female,24,0,2,PP 9549,16.7,G6,S\\r\\n396,0,3,\"Johansson, Mr. Erik\",male,22,0,0,350052,7.7958,,S\\r\\n397,0,3,\"Olsson, Miss. Elina\",female,31,0,0,350407,7.8542,,S\\r\\n398,0,2,\"McKane, Mr. Peter David\",male,46,0,0,28403,26,,S\\r\\n399,0,2,\"Pain, Dr. Alfred\",male,23,0,0,244278,10.5,,S\\r\\n400,1,2,\"Trout, Mrs. William H (Jessie L)\",female,28,0,0,240929,12.65,,S\\r\\n401,1,3,\"Niskanen, Mr. Juha\",male,39,0,0,STON/O 2. 3101289,7.925,,S\\r\\n402,0,3,\"Adams, Mr. John\",male,26,0,0,341826,8.05,,S\\r\\n403,0,3,\"Jussila, Miss. Mari Aina\",female,21,1,0,4137,9.825,,S\\r\\n404,0,3,\"Hakkarainen, Mr. Pekka Pietari\",male,28,1,0,STON/O2. 3101279,15.85,,S\\r\\n405,0,3,\"Oreskovic, Miss. Marija\",female,20,0,0,315096,8.6625,,S\\r\\n406,0,2,\"Gale, Mr. Shadrach\",male,34,1,0,28664,21,,S\\r\\n407,0,3,\"Widegren, Mr. Carl/Charles Peter\",male,51,0,0,347064,7.75,,S\\r\\n408,1,2,\"Richards, Master. William Rowe\",male,3,1,1,29106,18.75,,S\\r\\n409,0,3,\"Birkeland, Mr. Hans Martin Monsen\",male,21,0,0,312992,7.775,,S\\r\\n410,0,3,\"Lefebre, Miss. Ida\",female,,3,1,4133,25.4667,,S\\r\\n411,0,3,\"Sdycoff, Mr. Todor\",male,,0,0,349222,7.8958,,S\\r\\n412,0,3,\"Hart, Mr. Henry\",male,,0,0,394140,6.8583,,Q\\r\\n413,1,1,\"Minahan, Miss. Daisy E\",female,33,1,0,19928,90,C78,Q\\r\\n414,0,2,\"Cunningham, Mr. Alfred Fleming\",male,,0,0,239853,0,,S\\r\\n415,1,3,\"Sundman, Mr. Johan Julian\",male,44,0,0,STON/O 2. 3101269,7.925,,S\\r\\n416,0,3,\"Meek, Mrs. Thomas (Annie Louise Rowley)\",female,,0,0,343095,8.05,,S\\r\\n417,1,2,\"Drew, Mrs. James Vivian (Lulu Thorne Christian)\",female,34,1,1,28220,32.5,,S\\r\\n418,1,2,\"Silven, Miss. Lyyli Karoliina\",female,18,0,2,250652,13,,S\\r\\n419,0,2,\"Matthews, Mr. William John\",male,30,0,0,28228,13,,S\\r\\n420,0,3,\"Van Impe, Miss. Catharina\",female,10,0,2,345773,24.15,,S\\r\\n421,0,3,\"Gheorgheff, Mr. Stanio\",male,,0,0,349254,7.8958,,C\\r\\n422,0,3,\"Charters, Mr. David\",male,21,0,0,A/5. 13032,7.7333,,Q\\r\\n423,0,3,\"Zimmerman, Mr. Leo\",male,29,0,0,315082,7.875,,S\\r\\n424,0,3,\"Danbom, Mrs. Ernst Gilbert (Anna Sigrid Maria Brogren)\",female,28,1,1,347080,14.4,,S\\r\\n425,0,3,\"Rosblom, Mr. Viktor Richard\",male,18,1,1,370129,20.2125,,S\\r\\n426,0,3,\"Wiseman, Mr. Phillippe\",male,,0,0,A/4. 34244,7.25,,S\\r\\n427,1,2,\"Clarke, Mrs. Charles V (Ada Maria Winfield)\",female,28,1,0,2003,26,,S\\r\\n428,1,2,\"Phillips, Miss. Kate Florence (\"\"Mrs Kate Louise Phillips Marshall\"\")\",female,19,0,0,250655,26,,S\\r\\n429,0,3,\"Flynn, Mr. James\",male,,0,0,364851,7.75,,Q\\r\\n430,1,3,\"Pickard, Mr. Berk (Berk Trembisky)\",male,32,0,0,SOTON/O.Q. 392078,8.05,E10,S\\r\\n431,1,1,\"Bjornstrom-Steffansson, Mr. Mauritz Hakan\",male,28,0,0,110564,26.55,C52,S\\r\\n432,1,3,\"Thorneycroft, Mrs. Percival (Florence Kate White)\",female,,1,0,376564,16.1,,S\\r\\n433,1,2,\"Louch, Mrs. Charles Alexander (Alice Adelaide Slow)\",female,42,1,0,SC/AH 3085,26,,S\\r\\n434,0,3,\"Kallio, Mr. Nikolai Erland\",male,17,0,0,STON/O 2. 3101274,7.125,,S\\r\\n435,0,1,\"Silvey, Mr. William Baird\",male,50,1,0,13507,55.9,E44,S\\r\\n436,1,1,\"Carter, Miss. Lucile Polk\",female,14,1,2,113760,120,B96 B98,S\\r\\n437,0,3,\"Ford, Miss. Doolina Margaret \"\"Daisy\"\"\",female,21,2,2,W./C. 6608,34.375,,S\\r\\n438,1,2,\"Richards, Mrs. Sidney (Emily Hocking)\",female,24,2,3,29106,18.75,,S\\r\\n439,0,1,\"Fortune, Mr. Mark\",male,64,1,4,19950,263,C23 C25 C27,S\\r\\n440,0,2,\"Kvillner, Mr. Johan Henrik Johannesson\",male,31,0,0,C.A. 18723,10.5,,S\\r\\n441,1,2,\"Hart, Mrs. Benjamin (Esther Ada Bloomfield)\",female,45,1,1,F.C.C. 13529,26.25,,S\\r\\n442,0,3,\"Hampe, Mr. Leon\",male,20,0,0,345769,9.5,,S\\r\\n443,0,3,\"Petterson, Mr. Johan Emil\",male,25,1,0,347076,7.775,,S\\r\\n444,1,2,\"Reynaldo, Ms. Encarnacion\",female,28,0,0,230434,13,,S\\r\\n445,1,3,\"Johannesen-Bratthammer, Mr. Bernt\",male,,0,0,65306,8.1125,,S\\r\\n446,1,1,\"Dodge, Master. Washington\",male,4,0,2,33638,81.8583,A34,S\\r\\n447,1,2,\"Mellinger, Miss. Madeleine Violet\",female,13,0,1,250644,19.5,,S\\r\\n448,1,1,\"Seward, Mr. Frederic Kimber\",male,34,0,0,113794,26.55,,S\\r\\n449,1,3,\"Baclini, Miss. Marie Catherine\",female,5,2,1,2666,19.2583,,C\\r\\n450,1,1,\"Peuchen, Major. Arthur Godfrey\",male,52,0,0,113786,30.5,C104,S\\r\\n451,0,2,\"West, Mr. Edwy Arthur\",male,36,1,2,C.A. 34651,27.75,,S\\r\\n452,0,3,\"Hagland, Mr. Ingvald Olai Olsen\",male,,1,0,65303,19.9667,,S\\r\\n453,0,1,\"Foreman, Mr. Benjamin Laventall\",male,30,0,0,113051,27.75,C111,C\\r\\n454,1,1,\"Goldenberg, Mr. Samuel L\",male,49,1,0,17453,89.1042,C92,C\\r\\n455,0,3,\"Peduzzi, Mr. Joseph\",male,,0,0,A/5 2817,8.05,,S\\r\\n456,1,3,\"Jalsevac, Mr. Ivan\",male,29,0,0,349240,7.8958,,C\\r\\n457,0,1,\"Millet, Mr. Francis Davis\",male,65,0,0,13509,26.55,E38,S\\r\\n458,1,1,\"Kenyon, Mrs. Frederick R (Marion)\",female,,1,0,17464,51.8625,D21,S\\r\\n459,1,2,\"Toomey, Miss. Ellen\",female,50,0,0,F.C.C. 13531,10.5,,S\\r\\n460,0,3,\"O\\'Connor, Mr. Maurice\",male,,0,0,371060,7.75,,Q\\r\\n461,1,1,\"Anderson, Mr. Harry\",male,48,0,0,19952,26.55,E12,S\\r\\n462,0,3,\"Morley, Mr. William\",male,34,0,0,364506,8.05,,S\\r\\n463,0,1,\"Gee, Mr. Arthur H\",male,47,0,0,111320,38.5,E63,S\\r\\n464,0,2,\"Milling, Mr. Jacob Christian\",male,48,0,0,234360,13,,S\\r\\n465,0,3,\"Maisner, Mr. Simon\",male,,0,0,A/S 2816,8.05,,S\\r\\n466,0,3,\"Goncalves, Mr. Manuel Estanslas\",male,38,0,0,SOTON/O.Q. 3101306,7.05,,S\\r\\n467,0,2,\"Campbell, Mr. William\",male,,0,0,239853,0,,S\\r\\n468,0,1,\"Smart, Mr. John Montgomery\",male,56,0,0,113792,26.55,,S\\r\\n469,0,3,\"Scanlan, Mr. James\",male,,0,0,36209,7.725,,Q\\r\\n470,1,3,\"Baclini, Miss. Helene Barbara\",female,0.75,2,1,2666,19.2583,,C\\r\\n471,0,3,\"Keefe, Mr. Arthur\",male,,0,0,323592,7.25,,S\\r\\n472,0,3,\"Cacic, Mr. Luka\",male,38,0,0,315089,8.6625,,S\\r\\n473,1,2,\"West, Mrs. Edwy Arthur (Ada Mary Worth)\",female,33,1,2,C.A. 34651,27.75,,S\\r\\n474,1,2,\"Jerwan, Mrs. Amin S (Marie Marthe Thuillard)\",female,23,0,0,SC/AH Basle 541,13.7917,D,C\\r\\n475,0,3,\"Strandberg, Miss. Ida Sofia\",female,22,0,0,7553,9.8375,,S\\r\\n476,0,1,\"Clifford, Mr. George Quincy\",male,,0,0,110465,52,A14,S\\r\\n477,0,2,\"Renouf, Mr. Peter Henry\",male,34,1,0,31027,21,,S\\r\\n478,0,3,\"Braund, Mr. Lewis Richard\",male,29,1,0,3460,7.0458,,S\\r\\n479,0,3,\"Karlsson, Mr. Nils August\",male,22,0,0,350060,7.5208,,S\\r\\n480,1,3,\"Hirvonen, Miss. Hildur E\",female,2,0,1,3101298,12.2875,,S\\r\\n481,0,3,\"Goodwin, Master. Harold Victor\",male,9,5,2,CA 2144,46.9,,S\\r\\n482,0,2,\"Frost, Mr. Anthony Wood \"\"Archie\"\"\",male,,0,0,239854,0,,S\\r\\n483,0,3,\"Rouse, Mr. Richard Henry\",male,50,0,0,A/5 3594,8.05,,S\\r\\n484,1,3,\"Turkula, Mrs. (Hedwig)\",female,63,0,0,4134,9.5875,,S\\r\\n485,1,1,\"Bishop, Mr. Dickinson H\",male,25,1,0,11967,91.0792,B49,C\\r\\n486,0,3,\"Lefebre, Miss. Jeannie\",female,,3,1,4133,25.4667,,S\\r\\n487,1,1,\"Hoyt, Mrs. Frederick Maxfield (Jane Anne Forby)\",female,35,1,0,19943,90,C93,S\\r\\n488,0,1,\"Kent, Mr. Edward Austin\",male,58,0,0,11771,29.7,B37,C\\r\\n489,0,3,\"Somerton, Mr. Francis William\",male,30,0,0,A.5. 18509,8.05,,S\\r\\n490,1,3,\"Coutts, Master. Eden Leslie \"\"Neville\"\"\",male,9,1,1,C.A. 37671,15.9,,S\\r\\n491,0,3,\"Hagland, Mr. Konrad Mathias Reiersen\",male,,1,0,65304,19.9667,,S\\r\\n492,0,3,\"Windelov, Mr. Einar\",male,21,0,0,SOTON/OQ 3101317,7.25,,S\\r\\n493,0,1,\"Molson, Mr. Harry Markland\",male,55,0,0,113787,30.5,C30,S\\r\\n494,0,1,\"Artagaveytia, Mr. Ramon\",male,71,0,0,PC 17609,49.5042,,C\\r\\n495,0,3,\"Stanley, Mr. Edward Roland\",male,21,0,0,A/4 45380,8.05,,S\\r\\n496,0,3,\"Yousseff, Mr. Gerious\",male,,0,0,2627,14.4583,,C\\r\\n497,1,1,\"Eustis, Miss. Elizabeth Mussey\",female,54,1,0,36947,78.2667,D20,C\\r\\n498,0,3,\"Shellard, Mr. Frederick William\",male,,0,0,C.A. 6212,15.1,,S\\r\\n499,0,1,\"Allison, Mrs. Hudson J C (Bessie Waldo Daniels)\",female,25,1,2,113781,151.55,C22 C26,S\\r\\n500,0,3,\"Svensson, Mr. Olof\",male,24,0,0,350035,7.7958,,S\\r\\n501,0,3,\"Calic, Mr. Petar\",male,17,0,0,315086,8.6625,,S\\r\\n502,0,3,\"Canavan, Miss. Mary\",female,21,0,0,364846,7.75,,Q\\r\\n503,0,3,\"O\\'Sullivan, Miss. Bridget Mary\",female,,0,0,330909,7.6292,,Q\\r\\n504,0,3,\"Laitinen, Miss. Kristina Sofia\",female,37,0,0,4135,9.5875,,S\\r\\n505,1,1,\"Maioni, Miss. Roberta\",female,16,0,0,110152,86.5,B79,S\\r\\n506,0,1,\"Penasco y Castellana, Mr. Victor de Satode\",male,18,1,0,PC 17758,108.9,C65,C\\r\\n507,1,2,\"Quick, Mrs. Frederick Charles (Jane Richards)\",female,33,0,2,26360,26,,S\\r\\n508,1,1,\"Bradley, Mr. George (\"\"George Arthur Brayton\"\")\",male,,0,0,111427,26.55,,S\\r\\n509,0,3,\"Olsen, Mr. Henry Margido\",male,28,0,0,C 4001,22.525,,S\\r\\n510,1,3,\"Lang, Mr. Fang\",male,26,0,0,1601,56.4958,,S\\r\\n511,1,3,\"Daly, Mr. Eugene Patrick\",male,29,0,0,382651,7.75,,Q\\r\\n512,0,3,\"Webber, Mr. James\",male,,0,0,SOTON/OQ 3101316,8.05,,S\\r\\n513,1,1,\"McGough, Mr. James Robert\",male,36,0,0,PC 17473,26.2875,E25,S\\r\\n514,1,1,\"Rothschild, Mrs. Martin (Elizabeth L. Barrett)\",female,54,1,0,PC 17603,59.4,,C\\r\\n515,0,3,\"Coleff, Mr. Satio\",male,24,0,0,349209,7.4958,,S\\r\\n516,0,1,\"Walker, Mr. William Anderson\",male,47,0,0,36967,34.0208,D46,S\\r\\n517,1,2,\"Lemore, Mrs. (Amelia Milley)\",female,34,0,0,C.A. 34260,10.5,F33,S\\r\\n518,0,3,\"Ryan, Mr. Patrick\",male,,0,0,371110,24.15,,Q\\r\\n519,1,2,\"Angle, Mrs. William A (Florence \"\"Mary\"\" Agnes Hughes)\",female,36,1,0,226875,26,,S\\r\\n520,0,3,\"Pavlovic, Mr. Stefo\",male,32,0,0,349242,7.8958,,S\\r\\n521,1,1,\"Perreault, Miss. Anne\",female,30,0,0,12749,93.5,B73,S\\r\\n522,0,3,\"Vovk, Mr. Janko\",male,22,0,0,349252,7.8958,,S\\r\\n523,0,3,\"Lahoud, Mr. Sarkis\",male,,0,0,2624,7.225,,C\\r\\n524,1,1,\"Hippach, Mrs. Louis Albert (Ida Sophia Fischer)\",female,44,0,1,111361,57.9792,B18,C\\r\\n525,0,3,\"Kassem, Mr. Fared\",male,,0,0,2700,7.2292,,C\\r\\n526,0,3,\"Farrell, Mr. James\",male,40.5,0,0,367232,7.75,,Q\\r\\n527,1,2,\"Ridsdale, Miss. Lucy\",female,50,0,0,W./C. 14258,10.5,,S\\r\\n528,0,1,\"Farthing, Mr. John\",male,,0,0,PC 17483,221.7792,C95,S\\r\\n529,0,3,\"Salonen, Mr. Johan Werner\",male,39,0,0,3101296,7.925,,S\\r\\n530,0,2,\"Hocking, Mr. Richard George\",male,23,2,1,29104,11.5,,S\\r\\n531,1,2,\"Quick, Miss. Phyllis May\",female,2,1,1,26360,26,,S\\r\\n532,0,3,\"Toufik, Mr. Nakli\",male,,0,0,2641,7.2292,,C\\r\\n533,0,3,\"Elias, Mr. Joseph Jr\",male,17,1,1,2690,7.2292,,C\\r\\n534,1,3,\"Peter, Mrs. Catherine (Catherine Rizk)\",female,,0,2,2668,22.3583,,C\\r\\n535,0,3,\"Cacic, Miss. Marija\",female,30,0,0,315084,8.6625,,S\\r\\n536,1,2,\"Hart, Miss. Eva Miriam\",female,7,0,2,F.C.C. 13529,26.25,,S\\r\\n537,0,1,\"Butt, Major. Archibald Willingham\",male,45,0,0,113050,26.55,B38,S\\r\\n538,1,1,\"LeRoy, Miss. Bertha\",female,30,0,0,PC 17761,106.425,,C\\r\\n539,0,3,\"Risien, Mr. Samuel Beard\",male,,0,0,364498,14.5,,S\\r\\n540,1,1,\"Frolicher, Miss. Hedwig Margaritha\",female,22,0,2,13568,49.5,B39,C\\r\\n541,1,1,\"Crosby, Miss. Harriet R\",female,36,0,2,WE/P 5735,71,B22,S\\r\\n542,0,3,\"Andersson, Miss. Ingeborg Constanzia\",female,9,4,2,347082,31.275,,S\\r\\n543,0,3,\"Andersson, Miss. Sigrid Elisabeth\",female,11,4,2,347082,31.275,,S\\r\\n544,1,2,\"Beane, Mr. Edward\",male,32,1,0,2908,26,,S\\r\\n545,0,1,\"Douglas, Mr. Walter Donald\",male,50,1,0,PC 17761,106.425,C86,C\\r\\n546,0,1,\"Nicholson, Mr. Arthur Ernest\",male,64,0,0,693,26,,S\\r\\n547,1,2,\"Beane, Mrs. Edward (Ethel Clarke)\",female,19,1,0,2908,26,,S\\r\\n548,1,2,\"Padro y Manent, Mr. Julian\",male,,0,0,SC/PARIS 2146,13.8625,,C\\r\\n549,0,3,\"Goldsmith, Mr. Frank John\",male,33,1,1,363291,20.525,,S\\r\\n550,1,2,\"Davies, Master. John Morgan Jr\",male,8,1,1,C.A. 33112,36.75,,S\\r\\n551,1,1,\"Thayer, Mr. John Borland Jr\",male,17,0,2,17421,110.8833,C70,C\\r\\n552,0,2,\"Sharp, Mr. Percival James R\",male,27,0,0,244358,26,,S\\r\\n553,0,3,\"O\\'Brien, Mr. Timothy\",male,,0,0,330979,7.8292,,Q\\r\\n554,1,3,\"Leeni, Mr. Fahim (\"\"Philip Zenni\"\")\",male,22,0,0,2620,7.225,,C\\r\\n555,1,3,\"Ohman, Miss. Velin\",female,22,0,0,347085,7.775,,S\\r\\n556,0,1,\"Wright, Mr. George\",male,62,0,0,113807,26.55,,S\\r\\n557,1,1,\"Duff Gordon, Lady. (Lucille Christiana Sutherland) (\"\"Mrs Morgan\"\")\",female,48,1,0,11755,39.6,A16,C\\r\\n558,0,1,\"Robbins, Mr. Victor\",male,,0,0,PC 17757,227.525,,C\\r\\n559,1,1,\"Taussig, Mrs. Emil (Tillie Mandelbaum)\",female,39,1,1,110413,79.65,E67,S\\r\\n560,1,3,\"de Messemaeker, Mrs. Guillaume Joseph (Emma)\",female,36,1,0,345572,17.4,,S\\r\\n561,0,3,\"Morrow, Mr. Thomas Rowan\",male,,0,0,372622,7.75,,Q\\r\\n562,0,3,\"Sivic, Mr. Husein\",male,40,0,0,349251,7.8958,,S\\r\\n563,0,2,\"Norman, Mr. Robert Douglas\",male,28,0,0,218629,13.5,,S\\r\\n564,0,3,\"Simmons, Mr. John\",male,,0,0,SOTON/OQ 392082,8.05,,S\\r\\n565,0,3,\"Meanwell, Miss. (Marion Ogden)\",female,,0,0,SOTON/O.Q. 392087,8.05,,S\\r\\n566,0,3,\"Davies, Mr. Alfred J\",male,24,2,0,A/4 48871,24.15,,S\\r\\n567,0,3,\"Stoytcheff, Mr. Ilia\",male,19,0,0,349205,7.8958,,S\\r\\n568,0,3,\"Palsson, Mrs. Nils (Alma Cornelia Berglund)\",female,29,0,4,349909,21.075,,S\\r\\n569,0,3,\"Doharr, Mr. Tannous\",male,,0,0,2686,7.2292,,C\\r\\n570,1,3,\"Jonsson, Mr. Carl\",male,32,0,0,350417,7.8542,,S\\r\\n571,1,2,\"Harris, Mr. George\",male,62,0,0,S.W./PP 752,10.5,,S\\r\\n572,1,1,\"Appleton, Mrs. Edward Dale (Charlotte Lamson)\",female,53,2,0,11769,51.4792,C101,S\\r\\n573,1,1,\"Flynn, Mr. John Irwin (\"\"Irving\"\")\",male,36,0,0,PC 17474,26.3875,E25,S\\r\\n574,1,3,\"Kelly, Miss. Mary\",female,,0,0,14312,7.75,,Q\\r\\n575,0,3,\"Rush, Mr. Alfred George John\",male,16,0,0,A/4. 20589,8.05,,S\\r\\n576,0,3,\"Patchett, Mr. George\",male,19,0,0,358585,14.5,,S\\r\\n577,1,2,\"Garside, Miss. Ethel\",female,34,0,0,243880,13,,S\\r\\n578,1,1,\"Silvey, Mrs. William Baird (Alice Munger)\",female,39,1,0,13507,55.9,E44,S\\r\\n579,0,3,\"Caram, Mrs. Joseph (Maria Elias)\",female,,1,0,2689,14.4583,,C\\r\\n580,1,3,\"Jussila, Mr. Eiriik\",male,32,0,0,STON/O 2. 3101286,7.925,,S\\r\\n581,1,2,\"Christy, Miss. Julie Rachel\",female,25,1,1,237789,30,,S\\r\\n582,1,1,\"Thayer, Mrs. John Borland (Marian Longstreth Morris)\",female,39,1,1,17421,110.8833,C68,C\\r\\n583,0,2,\"Downton, Mr. William James\",male,54,0,0,28403,26,,S\\r\\n584,0,1,\"Ross, Mr. John Hugo\",male,36,0,0,13049,40.125,A10,C\\r\\n585,0,3,\"Paulner, Mr. Uscher\",male,,0,0,3411,8.7125,,C\\r\\n586,1,1,\"Taussig, Miss. Ruth\",female,18,0,2,110413,79.65,E68,S\\r\\n587,0,2,\"Jarvis, Mr. John Denzil\",male,47,0,0,237565,15,,S\\r\\n588,1,1,\"Frolicher-Stehli, Mr. Maxmillian\",male,60,1,1,13567,79.2,B41,C\\r\\n589,0,3,\"Gilinski, Mr. Eliezer\",male,22,0,0,14973,8.05,,S\\r\\n590,0,3,\"Murdlin, Mr. Joseph\",male,,0,0,A./5. 3235,8.05,,S\\r\\n591,0,3,\"Rintamaki, Mr. Matti\",male,35,0,0,STON/O 2. 3101273,7.125,,S\\r\\n592,1,1,\"Stephenson, Mrs. Walter Bertram (Martha Eustis)\",female,52,1,0,36947,78.2667,D20,C\\r\\n593,0,3,\"Elsbury, Mr. William James\",male,47,0,0,A/5 3902,7.25,,S\\r\\n594,0,3,\"Bourke, Miss. Mary\",female,,0,2,364848,7.75,,Q\\r\\n595,0,2,\"Chapman, Mr. John Henry\",male,37,1,0,SC/AH 29037,26,,S\\r\\n596,0,3,\"Van Impe, Mr. Jean Baptiste\",male,36,1,1,345773,24.15,,S\\r\\n597,1,2,\"Leitch, Miss. Jessie Wills\",female,,0,0,248727,33,,S\\r\\n598,0,3,\"Johnson, Mr. Alfred\",male,49,0,0,LINE,0,,S\\r\\n599,0,3,\"Boulos, Mr. Hanna\",male,,0,0,2664,7.225,,C\\r\\n600,1,1,\"Duff Gordon, Sir. Cosmo Edmund (\"\"Mr Morgan\"\")\",male,49,1,0,PC 17485,56.9292,A20,C\\r\\n601,1,2,\"Jacobsohn, Mrs. Sidney Samuel (Amy Frances Christy)\",female,24,2,1,243847,27,,S\\r\\n602,0,3,\"Slabenoff, Mr. Petco\",male,,0,0,349214,7.8958,,S\\r\\n603,0,1,\"Harrington, Mr. Charles H\",male,,0,0,113796,42.4,,S\\r\\n604,0,3,\"Torber, Mr. Ernst William\",male,44,0,0,364511,8.05,,S\\r\\n605,1,1,\"Homer, Mr. Harry (\"\"Mr E Haven\"\")\",male,35,0,0,111426,26.55,,C\\r\\n606,0,3,\"Lindell, Mr. Edvard Bengtsson\",male,36,1,0,349910,15.55,,S\\r\\n607,0,3,\"Karaic, Mr. Milan\",male,30,0,0,349246,7.8958,,S\\r\\n608,1,1,\"Daniel, Mr. Robert Williams\",male,27,0,0,113804,30.5,,S\\r\\n609,1,2,\"Laroche, Mrs. Joseph (Juliette Marie Louise Lafargue)\",female,22,1,2,SC/Paris 2123,41.5792,,C\\r\\n610,1,1,\"Shutes, Miss. Elizabeth W\",female,40,0,0,PC 17582,153.4625,C125,S\\r\\n611,0,3,\"Andersson, Mrs. Anders Johan (Alfrida Konstantia Brogren)\",female,39,1,5,347082,31.275,,S\\r\\n612,0,3,\"Jardin, Mr. Jose Neto\",male,,0,0,SOTON/O.Q. 3101305,7.05,,S\\r\\n613,1,3,\"Murphy, Miss. Margaret Jane\",female,,1,0,367230,15.5,,Q\\r\\n614,0,3,\"Horgan, Mr. John\",male,,0,0,370377,7.75,,Q\\r\\n615,0,3,\"Brocklebank, Mr. William Alfred\",male,35,0,0,364512,8.05,,S\\r\\n616,1,2,\"Herman, Miss. Alice\",female,24,1,2,220845,65,,S\\r\\n617,0,3,\"Danbom, Mr. Ernst Gilbert\",male,34,1,1,347080,14.4,,S\\r\\n618,0,3,\"Lobb, Mrs. William Arthur (Cordelia K Stanlick)\",female,26,1,0,A/5. 3336,16.1,,S\\r\\n619,1,2,\"Becker, Miss. Marion Louise\",female,4,2,1,230136,39,F4,S\\r\\n620,0,2,\"Gavey, Mr. Lawrence\",male,26,0,0,31028,10.5,,S\\r\\n621,0,3,\"Yasbeck, Mr. Antoni\",male,27,1,0,2659,14.4542,,C\\r\\n622,1,1,\"Kimball, Mr. Edwin Nelson Jr\",male,42,1,0,11753,52.5542,D19,S\\r\\n623,1,3,\"Nakid, Mr. Sahid\",male,20,1,1,2653,15.7417,,C\\r\\n624,0,3,\"Hansen, Mr. Henry Damsgaard\",male,21,0,0,350029,7.8542,,S\\r\\n625,0,3,\"Bowen, Mr. David John \"\"Dai\"\"\",male,21,0,0,54636,16.1,,S\\r\\n626,0,1,\"Sutton, Mr. Frederick\",male,61,0,0,36963,32.3208,D50,S\\r\\n627,0,2,\"Kirkland, Rev. Charles Leonard\",male,57,0,0,219533,12.35,,Q\\r\\n628,1,1,\"Longley, Miss. Gretchen Fiske\",female,21,0,0,13502,77.9583,D9,S\\r\\n629,0,3,\"Bostandyeff, Mr. Guentcho\",male,26,0,0,349224,7.8958,,S\\r\\n630,0,3,\"O\\'Connell, Mr. Patrick D\",male,,0,0,334912,7.7333,,Q\\r\\n631,1,1,\"Barkworth, Mr. Algernon Henry Wilson\",male,80,0,0,27042,30,A23,S\\r\\n632,0,3,\"Lundahl, Mr. Johan Svensson\",male,51,0,0,347743,7.0542,,S\\r\\n633,1,1,\"Stahelin-Maeglin, Dr. Max\",male,32,0,0,13214,30.5,B50,C\\r\\n634,0,1,\"Parr, Mr. William Henry Marsh\",male,,0,0,112052,0,,S\\r\\n635,0,3,\"Skoog, Miss. Mabel\",female,9,3,2,347088,27.9,,S\\r\\n636,1,2,\"Davis, Miss. Mary\",female,28,0,0,237668,13,,S\\r\\n637,0,3,\"Leinonen, Mr. Antti Gustaf\",male,32,0,0,STON/O 2. 3101292,7.925,,S\\r\\n638,0,2,\"Collyer, Mr. Harvey\",male,31,1,1,C.A. 31921,26.25,,S\\r\\n639,0,3,\"Panula, Mrs. Juha (Maria Emilia Ojala)\",female,41,0,5,3101295,39.6875,,S\\r\\n640,0,3,\"Thorneycroft, Mr. Percival\",male,,1,0,376564,16.1,,S\\r\\n641,0,3,\"Jensen, Mr. Hans Peder\",male,20,0,0,350050,7.8542,,S\\r\\n642,1,1,\"Sagesser, Mlle. Emma\",female,24,0,0,PC 17477,69.3,B35,C\\r\\n643,0,3,\"Skoog, Miss. Margit Elizabeth\",female,2,3,2,347088,27.9,,S\\r\\n644,1,3,\"Foo, Mr. Choong\",male,,0,0,1601,56.4958,,S\\r\\n645,1,3,\"Baclini, Miss. Eugenie\",female,0.75,2,1,2666,19.2583,,C\\r\\n646,1,1,\"Harper, Mr. Henry Sleeper\",male,48,1,0,PC 17572,76.7292,D33,C\\r\\n647,0,3,\"Cor, Mr. Liudevit\",male,19,0,0,349231,7.8958,,S\\r\\n648,1,1,\"Simonius-Blumer, Col. Oberst Alfons\",male,56,0,0,13213,35.5,A26,C\\r\\n649,0,3,\"Willey, Mr. Edward\",male,,0,0,S.O./P.P. 751,7.55,,S\\r\\n650,1,3,\"Stanley, Miss. Amy Zillah Elsie\",female,23,0,0,CA. 2314,7.55,,S\\r\\n651,0,3,\"Mitkoff, Mr. Mito\",male,,0,0,349221,7.8958,,S\\r\\n652,1,2,\"Doling, Miss. Elsie\",female,18,0,1,231919,23,,S\\r\\n653,0,3,\"Kalvik, Mr. Johannes Halvorsen\",male,21,0,0,8475,8.4333,,S\\r\\n654,1,3,\"O\\'Leary, Miss. Hanora \"\"Norah\"\"\",female,,0,0,330919,7.8292,,Q\\r\\n655,0,3,\"Hegarty, Miss. Hanora \"\"Nora\"\"\",female,18,0,0,365226,6.75,,Q\\r\\n656,0,2,\"Hickman, Mr. Leonard Mark\",male,24,2,0,S.O.C. 14879,73.5,,S\\r\\n657,0,3,\"Radeff, Mr. Alexander\",male,,0,0,349223,7.8958,,S\\r\\n658,0,3,\"Bourke, Mrs. John (Catherine)\",female,32,1,1,364849,15.5,,Q\\r\\n659,0,2,\"Eitemiller, Mr. George Floyd\",male,23,0,0,29751,13,,S\\r\\n660,0,1,\"Newell, Mr. Arthur Webster\",male,58,0,2,35273,113.275,D48,C\\r\\n661,1,1,\"Frauenthal, Dr. Henry William\",male,50,2,0,PC 17611,133.65,,S\\r\\n662,0,3,\"Badt, Mr. Mohamed\",male,40,0,0,2623,7.225,,C\\r\\n663,0,1,\"Colley, Mr. Edward Pomeroy\",male,47,0,0,5727,25.5875,E58,S\\r\\n664,0,3,\"Coleff, Mr. Peju\",male,36,0,0,349210,7.4958,,S\\r\\n665,1,3,\"Lindqvist, Mr. Eino William\",male,20,1,0,STON/O 2. 3101285,7.925,,S\\r\\n666,0,2,\"Hickman, Mr. Lewis\",male,32,2,0,S.O.C. 14879,73.5,,S\\r\\n667,0,2,\"Butler, Mr. Reginald Fenton\",male,25,0,0,234686,13,,S\\r\\n668,0,3,\"Rommetvedt, Mr. Knud Paust\",male,,0,0,312993,7.775,,S\\r\\n669,0,3,\"Cook, Mr. Jacob\",male,43,0,0,A/5 3536,8.05,,S\\r\\n670,1,1,\"Taylor, Mrs. Elmer Zebley (Juliet Cummins Wright)\",female,,1,0,19996,52,C126,S\\r\\n671,1,2,\"Brown, Mrs. Thomas William Solomon (Elizabeth Catherine Ford)\",female,40,1,1,29750,39,,S\\r\\n672,0,1,\"Davidson, Mr. Thornton\",male,31,1,0,F.C. 12750,52,B71,S\\r\\n673,0,2,\"Mitchell, Mr. Henry Michael\",male,70,0,0,C.A. 24580,10.5,,S\\r\\n674,1,2,\"Wilhelms, Mr. Charles\",male,31,0,0,244270,13,,S\\r\\n675,0,2,\"Watson, Mr. Ennis Hastings\",male,,0,0,239856,0,,S\\r\\n676,0,3,\"Edvardsson, Mr. Gustaf Hjalmar\",male,18,0,0,349912,7.775,,S\\r\\n677,0,3,\"Sawyer, Mr. Frederick Charles\",male,24.5,0,0,342826,8.05,,S\\r\\n678,1,3,\"Turja, Miss. Anna Sofia\",female,18,0,0,4138,9.8417,,S\\r\\n679,0,3,\"Goodwin, Mrs. Frederick (Augusta Tyler)\",female,43,1,6,CA 2144,46.9,,S\\r\\n680,1,1,\"Cardeza, Mr. Thomas Drake Martinez\",male,36,0,1,PC 17755,512.3292,B51 B53 B55,C\\r\\n681,0,3,\"Peters, Miss. Katie\",female,,0,0,330935,8.1375,,Q\\r\\n682,1,1,\"Hassab, Mr. Hammad\",male,27,0,0,PC 17572,76.7292,D49,C\\r\\n683,0,3,\"Olsvigen, Mr. Thor Anderson\",male,20,0,0,6563,9.225,,S\\r\\n684,0,3,\"Goodwin, Mr. Charles Edward\",male,14,5,2,CA 2144,46.9,,S\\r\\n685,0,2,\"Brown, Mr. Thomas William Solomon\",male,60,1,1,29750,39,,S\\r\\n686,0,2,\"Laroche, Mr. Joseph Philippe Lemercier\",male,25,1,2,SC/Paris 2123,41.5792,,C\\r\\n687,0,3,\"Panula, Mr. Jaako Arnold\",male,14,4,1,3101295,39.6875,,S\\r\\n688,0,3,\"Dakic, Mr. Branko\",male,19,0,0,349228,10.1708,,S\\r\\n689,0,3,\"Fischer, Mr. Eberhard Thelander\",male,18,0,0,350036,7.7958,,S\\r\\n690,1,1,\"Madill, Miss. Georgette Alexandra\",female,15,0,1,24160,211.3375,B5,S\\r\\n691,1,1,\"Dick, Mr. Albert Adrian\",male,31,1,0,17474,57,B20,S\\r\\n692,1,3,\"Karun, Miss. Manca\",female,4,0,1,349256,13.4167,,C\\r\\n693,1,3,\"Lam, Mr. Ali\",male,,0,0,1601,56.4958,,S\\r\\n694,0,3,\"Saad, Mr. Khalil\",male,25,0,0,2672,7.225,,C\\r\\n695,0,1,\"Weir, Col. John\",male,60,0,0,113800,26.55,,S\\r\\n696,0,2,\"Chapman, Mr. Charles Henry\",male,52,0,0,248731,13.5,,S\\r\\n697,0,3,\"Kelly, Mr. James\",male,44,0,0,363592,8.05,,S\\r\\n698,1,3,\"Mullens, Miss. Katherine \"\"Katie\"\"\",female,,0,0,35852,7.7333,,Q\\r\\n699,0,1,\"Thayer, Mr. John Borland\",male,49,1,1,17421,110.8833,C68,C\\r\\n700,0,3,\"Humblen, Mr. Adolf Mathias Nicolai Olsen\",male,42,0,0,348121,7.65,F G63,S\\r\\n701,1,1,\"Astor, Mrs. John Jacob (Madeleine Talmadge Force)\",female,18,1,0,PC 17757,227.525,C62 C64,C\\r\\n702,1,1,\"Silverthorne, Mr. Spencer Victor\",male,35,0,0,PC 17475,26.2875,E24,S\\r\\n703,0,3,\"Barbara, Miss. Saiide\",female,18,0,1,2691,14.4542,,C\\r\\n704,0,3,\"Gallagher, Mr. Martin\",male,25,0,0,36864,7.7417,,Q\\r\\n705,0,3,\"Hansen, Mr. Henrik Juul\",male,26,1,0,350025,7.8542,,S\\r\\n706,0,2,\"Morley, Mr. Henry Samuel (\"\"Mr Henry Marshall\"\")\",male,39,0,0,250655,26,,S\\r\\n707,1,2,\"Kelly, Mrs. Florence \"\"Fannie\"\"\",female,45,0,0,223596,13.5,,S\\r\\n708,1,1,\"Calderhead, Mr. Edward Pennington\",male,42,0,0,PC 17476,26.2875,E24,S\\r\\n709,1,1,\"Cleaver, Miss. Alice\",female,22,0,0,113781,151.55,,S\\r\\n710,1,3,\"Moubarek, Master. Halim Gonios (\"\"William George\"\")\",male,,1,1,2661,15.2458,,C\\r\\n711,1,1,\"Mayne, Mlle. Berthe Antonine (\"\"Mrs de Villiers\"\")\",female,24,0,0,PC 17482,49.5042,C90,C\\r\\n712,0,1,\"Klaber, Mr. Herman\",male,,0,0,113028,26.55,C124,S\\r\\n713,1,1,\"Taylor, Mr. Elmer Zebley\",male,48,1,0,19996,52,C126,S\\r\\n714,0,3,\"Larsson, Mr. August Viktor\",male,29,0,0,7545,9.4833,,S\\r\\n715,0,2,\"Greenberg, Mr. Samuel\",male,52,0,0,250647,13,,S\\r\\n716,0,3,\"Soholt, Mr. Peter Andreas Lauritz Andersen\",male,19,0,0,348124,7.65,F G73,S\\r\\n717,1,1,\"Endres, Miss. Caroline Louise\",female,38,0,0,PC 17757,227.525,C45,C\\r\\n718,1,2,\"Troutt, Miss. Edwina Celia \"\"Winnie\"\"\",female,27,0,0,34218,10.5,E101,S\\r\\n719,0,3,\"McEvoy, Mr. Michael\",male,,0,0,36568,15.5,,Q\\r\\n720,0,3,\"Johnson, Mr. Malkolm Joackim\",male,33,0,0,347062,7.775,,S\\r\\n721,1,2,\"Harper, Miss. Annie Jessie \"\"Nina\"\"\",female,6,0,1,248727,33,,S\\r\\n722,0,3,\"Jensen, Mr. Svend Lauritz\",male,17,1,0,350048,7.0542,,S\\r\\n723,0,2,\"Gillespie, Mr. William Henry\",male,34,0,0,12233,13,,S\\r\\n724,0,2,\"Hodges, Mr. Henry Price\",male,50,0,0,250643,13,,S\\r\\n725,1,1,\"Chambers, Mr. Norman Campbell\",male,27,1,0,113806,53.1,E8,S\\r\\n726,0,3,\"Oreskovic, Mr. Luka\",male,20,0,0,315094,8.6625,,S\\r\\n727,1,2,\"Renouf, Mrs. Peter Henry (Lillian Jefferys)\",female,30,3,0,31027,21,,S\\r\\n728,1,3,\"Mannion, Miss. Margareth\",female,,0,0,36866,7.7375,,Q\\r\\n729,0,2,\"Bryhl, Mr. Kurt Arnold Gottfrid\",male,25,1,0,236853,26,,S\\r\\n730,0,3,\"Ilmakangas, Miss. Pieta Sofia\",female,25,1,0,STON/O2. 3101271,7.925,,S\\r\\n731,1,1,\"Allen, Miss. Elisabeth Walton\",female,29,0,0,24160,211.3375,B5,S\\r\\n732,0,3,\"Hassan, Mr. Houssein G N\",male,11,0,0,2699,18.7875,,C\\r\\n733,0,2,\"Knight, Mr. Robert J\",male,,0,0,239855,0,,S\\r\\n734,0,2,\"Berriman, Mr. William John\",male,23,0,0,28425,13,,S\\r\\n735,0,2,\"Troupiansky, Mr. Moses Aaron\",male,23,0,0,233639,13,,S\\r\\n736,0,3,\"Williams, Mr. Leslie\",male,28.5,0,0,54636,16.1,,S\\r\\n737,0,3,\"Ford, Mrs. Edward (Margaret Ann Watson)\",female,48,1,3,W./C. 6608,34.375,,S\\r\\n738,1,1,\"Lesurer, Mr. Gustave J\",male,35,0,0,PC 17755,512.3292,B101,C\\r\\n739,0,3,\"Ivanoff, Mr. Kanio\",male,,0,0,349201,7.8958,,S\\r\\n740,0,3,\"Nankoff, Mr. Minko\",male,,0,0,349218,7.8958,,S\\r\\n741,1,1,\"Hawksford, Mr. Walter James\",male,,0,0,16988,30,D45,S\\r\\n742,0,1,\"Cavendish, Mr. Tyrell William\",male,36,1,0,19877,78.85,C46,S\\r\\n743,1,1,\"Ryerson, Miss. Susan Parker \"\"Suzette\"\"\",female,21,2,2,PC 17608,262.375,B57 B59 B63 B66,C\\r\\n744,0,3,\"McNamee, Mr. Neal\",male,24,1,0,376566,16.1,,S\\r\\n745,1,3,\"Stranden, Mr. Juho\",male,31,0,0,STON/O 2. 3101288,7.925,,S\\r\\n746,0,1,\"Crosby, Capt. Edward Gifford\",male,70,1,1,WE/P 5735,71,B22,S\\r\\n747,0,3,\"Abbott, Mr. Rossmore Edward\",male,16,1,1,C.A. 2673,20.25,,S\\r\\n748,1,2,\"Sinkkonen, Miss. Anna\",female,30,0,0,250648,13,,S\\r\\n749,0,1,\"Marvin, Mr. Daniel Warner\",male,19,1,0,113773,53.1,D30,S\\r\\n750,0,3,\"Connaghton, Mr. Michael\",male,31,0,0,335097,7.75,,Q\\r\\n751,1,2,\"Wells, Miss. Joan\",female,4,1,1,29103,23,,S\\r\\n752,1,3,\"Moor, Master. Meier\",male,6,0,1,392096,12.475,E121,S\\r\\n753,0,3,\"Vande Velde, Mr. Johannes Joseph\",male,33,0,0,345780,9.5,,S\\r\\n754,0,3,\"Jonkoff, Mr. Lalio\",male,23,0,0,349204,7.8958,,S\\r\\n755,1,2,\"Herman, Mrs. Samuel (Jane Laver)\",female,48,1,2,220845,65,,S\\r\\n756,1,2,\"Hamalainen, Master. Viljo\",male,0.67,1,1,250649,14.5,,S\\r\\n757,0,3,\"Carlsson, Mr. August Sigfrid\",male,28,0,0,350042,7.7958,,S\\r\\n758,0,2,\"Bailey, Mr. Percy Andrew\",male,18,0,0,29108,11.5,,S\\r\\n759,0,3,\"Theobald, Mr. Thomas Leonard\",male,34,0,0,363294,8.05,,S\\r\\n760,1,1,\"Rothes, the Countess. of (Lucy Noel Martha Dyer-Edwards)\",female,33,0,0,110152,86.5,B77,S\\r\\n761,0,3,\"Garfirth, Mr. John\",male,,0,0,358585,14.5,,S\\r\\n762,0,3,\"Nirva, Mr. Iisakki Antino Aijo\",male,41,0,0,SOTON/O2 3101272,7.125,,S\\r\\n763,1,3,\"Barah, Mr. Hanna Assi\",male,20,0,0,2663,7.2292,,C\\r\\n764,1,1,\"Carter, Mrs. William Ernest (Lucile Polk)\",female,36,1,2,113760,120,B96 B98,S\\r\\n765,0,3,\"Eklund, Mr. Hans Linus\",male,16,0,0,347074,7.775,,S\\r\\n766,1,1,\"Hogeboom, Mrs. John C (Anna Andrews)\",female,51,1,0,13502,77.9583,D11,S\\r\\n767,0,1,\"Brewe, Dr. Arthur Jackson\",male,,0,0,112379,39.6,,C\\r\\n768,0,3,\"Mangan, Miss. Mary\",female,30.5,0,0,364850,7.75,,Q\\r\\n769,0,3,\"Moran, Mr. Daniel J\",male,,1,0,371110,24.15,,Q\\r\\n770,0,3,\"Gronnestad, Mr. Daniel Danielsen\",male,32,0,0,8471,8.3625,,S\\r\\n771,0,3,\"Lievens, Mr. Rene Aime\",male,24,0,0,345781,9.5,,S\\r\\n772,0,3,\"Jensen, Mr. Niels Peder\",male,48,0,0,350047,7.8542,,S\\r\\n773,0,2,\"Mack, Mrs. (Mary)\",female,57,0,0,S.O./P.P. 3,10.5,E77,S\\r\\n774,0,3,\"Elias, Mr. Dibo\",male,,0,0,2674,7.225,,C\\r\\n775,1,2,\"Hocking, Mrs. Elizabeth (Eliza Needs)\",female,54,1,3,29105,23,,S\\r\\n776,0,3,\"Myhrman, Mr. Pehr Fabian Oliver Malkolm\",male,18,0,0,347078,7.75,,S\\r\\n777,0,3,\"Tobin, Mr. Roger\",male,,0,0,383121,7.75,F38,Q\\r\\n778,1,3,\"Emanuel, Miss. Virginia Ethel\",female,5,0,0,364516,12.475,,S\\r\\n779,0,3,\"Kilgannon, Mr. Thomas J\",male,,0,0,36865,7.7375,,Q\\r\\n780,1,1,\"Robert, Mrs. Edward Scott (Elisabeth Walton McMillan)\",female,43,0,1,24160,211.3375,B3,S\\r\\n781,1,3,\"Ayoub, Miss. Banoura\",female,13,0,0,2687,7.2292,,C\\r\\n782,1,1,\"Dick, Mrs. Albert Adrian (Vera Gillespie)\",female,17,1,0,17474,57,B20,S\\r\\n783,0,1,\"Long, Mr. Milton Clyde\",male,29,0,0,113501,30,D6,S\\r\\n784,0,3,\"Johnston, Mr. Andrew G\",male,,1,2,W./C. 6607,23.45,,S\\r\\n785,0,3,\"Ali, Mr. William\",male,25,0,0,SOTON/O.Q. 3101312,7.05,,S\\r\\n786,0,3,\"Harmer, Mr. Abraham (David Lishin)\",male,25,0,0,374887,7.25,,S\\r\\n787,1,3,\"Sjoblom, Miss. Anna Sofia\",female,18,0,0,3101265,7.4958,,S\\r\\n788,0,3,\"Rice, Master. George Hugh\",male,8,4,1,382652,29.125,,Q\\r\\n789,1,3,\"Dean, Master. Bertram Vere\",male,1,1,2,C.A. 2315,20.575,,S\\r\\n790,0,1,\"Guggenheim, Mr. Benjamin\",male,46,0,0,PC 17593,79.2,B82 B84,C\\r\\n791,0,3,\"Keane, Mr. Andrew \"\"Andy\"\"\",male,,0,0,12460,7.75,,Q\\r\\n792,0,2,\"Gaskell, Mr. Alfred\",male,16,0,0,239865,26,,S\\r\\n793,0,3,\"Sage, Miss. Stella Anna\",female,,8,2,CA. 2343,69.55,,S\\r\\n794,0,1,\"Hoyt, Mr. William Fisher\",male,,0,0,PC 17600,30.6958,,C\\r\\n795,0,3,\"Dantcheff, Mr. Ristiu\",male,25,0,0,349203,7.8958,,S\\r\\n796,0,2,\"Otter, Mr. Richard\",male,39,0,0,28213,13,,S\\r\\n797,1,1,\"Leader, Dr. Alice (Farnham)\",female,49,0,0,17465,25.9292,D17,S\\r\\n798,1,3,\"Osman, Mrs. Mara\",female,31,0,0,349244,8.6833,,S\\r\\n799,0,3,\"Ibrahim Shawah, Mr. Yousseff\",male,30,0,0,2685,7.2292,,C\\r\\n800,0,3,\"Van Impe, Mrs. Jean Baptiste (Rosalie Paula Govaert)\",female,30,1,1,345773,24.15,,S\\r\\n801,0,2,\"Ponesell, Mr. Martin\",male,34,0,0,250647,13,,S\\r\\n802,1,2,\"Collyer, Mrs. Harvey (Charlotte Annie Tate)\",female,31,1,1,C.A. 31921,26.25,,S\\r\\n803,1,1,\"Carter, Master. William Thornton II\",male,11,1,2,113760,120,B96 B98,S\\r\\n804,1,3,\"Thomas, Master. Assad Alexander\",male,0.42,0,1,2625,8.5167,,C\\r\\n805,1,3,\"Hedman, Mr. Oskar Arvid\",male,27,0,0,347089,6.975,,S\\r\\n806,0,3,\"Johansson, Mr. Karl Johan\",male,31,0,0,347063,7.775,,S\\r\\n807,0,1,\"Andrews, Mr. Thomas Jr\",male,39,0,0,112050,0,A36,S\\r\\n808,0,3,\"Pettersson, Miss. Ellen Natalia\",female,18,0,0,347087,7.775,,S\\r\\n809,0,2,\"Meyer, Mr. August\",male,39,0,0,248723,13,,S\\r\\n810,1,1,\"Chambers, Mrs. Norman Campbell (Bertha Griggs)\",female,33,1,0,113806,53.1,E8,S\\r\\n811,0,3,\"Alexander, Mr. William\",male,26,0,0,3474,7.8875,,S\\r\\n812,0,3,\"Lester, Mr. James\",male,39,0,0,A/4 48871,24.15,,S\\r\\n813,0,2,\"Slemen, Mr. Richard James\",male,35,0,0,28206,10.5,,S\\r\\n814,0,3,\"Andersson, Miss. Ebba Iris Alfrida\",female,6,4,2,347082,31.275,,S\\r\\n815,0,3,\"Tomlin, Mr. Ernest Portage\",male,30.5,0,0,364499,8.05,,S\\r\\n816,0,1,\"Fry, Mr. Richard\",male,,0,0,112058,0,B102,S\\r\\n817,0,3,\"Heininen, Miss. Wendla Maria\",female,23,0,0,STON/O2. 3101290,7.925,,S\\r\\n818,0,2,\"Mallet, Mr. Albert\",male,31,1,1,S.C./PARIS 2079,37.0042,,C\\r\\n819,0,3,\"Holm, Mr. John Fredrik Alexander\",male,43,0,0,C 7075,6.45,,S\\r\\n820,0,3,\"Skoog, Master. Karl Thorsten\",male,10,3,2,347088,27.9,,S\\r\\n821,1,1,\"Hays, Mrs. Charles Melville (Clara Jennings Gregg)\",female,52,1,1,12749,93.5,B69,S\\r\\n822,1,3,\"Lulic, Mr. Nikola\",male,27,0,0,315098,8.6625,,S\\r\\n823,0,1,\"Reuchlin, Jonkheer. John George\",male,38,0,0,19972,0,,S\\r\\n824,1,3,\"Moor, Mrs. (Beila)\",female,27,0,1,392096,12.475,E121,S\\r\\n825,0,3,\"Panula, Master. Urho Abraham\",male,2,4,1,3101295,39.6875,,S\\r\\n826,0,3,\"Flynn, Mr. John\",male,,0,0,368323,6.95,,Q\\r\\n827,0,3,\"Lam, Mr. Len\",male,,0,0,1601,56.4958,,S\\r\\n828,1,2,\"Mallet, Master. Andre\",male,1,0,2,S.C./PARIS 2079,37.0042,,C\\r\\n829,1,3,\"McCormack, Mr. Thomas Joseph\",male,,0,0,367228,7.75,,Q\\r\\n830,1,1,\"Stone, Mrs. George Nelson (Martha Evelyn)\",female,62,0,0,113572,80,B28,\\r\\n831,1,3,\"Yasbeck, Mrs. Antoni (Selini Alexander)\",female,15,1,0,2659,14.4542,,C\\r\\n832,1,2,\"Richards, Master. George Sibley\",male,0.83,1,1,29106,18.75,,S\\r\\n833,0,3,\"Saad, Mr. Amin\",male,,0,0,2671,7.2292,,C\\r\\n834,0,3,\"Augustsson, Mr. Albert\",male,23,0,0,347468,7.8542,,S\\r\\n835,0,3,\"Allum, Mr. Owen George\",male,18,0,0,2223,8.3,,S\\r\\n836,1,1,\"Compton, Miss. Sara Rebecca\",female,39,1,1,PC 17756,83.1583,E49,C\\r\\n837,0,3,\"Pasic, Mr. Jakob\",male,21,0,0,315097,8.6625,,S\\r\\n838,0,3,\"Sirota, Mr. Maurice\",male,,0,0,392092,8.05,,S\\r\\n839,1,3,\"Chip, Mr. Chang\",male,32,0,0,1601,56.4958,,S\\r\\n840,1,1,\"Marechal, Mr. Pierre\",male,,0,0,11774,29.7,C47,C\\r\\n841,0,3,\"Alhomaki, Mr. Ilmari Rudolf\",male,20,0,0,SOTON/O2 3101287,7.925,,S\\r\\n842,0,2,\"Mudd, Mr. Thomas Charles\",male,16,0,0,S.O./P.P. 3,10.5,,S\\r\\n843,1,1,\"Serepeca, Miss. Augusta\",female,30,0,0,113798,31,,C\\r\\n844,0,3,\"Lemberopolous, Mr. Peter L\",male,34.5,0,0,2683,6.4375,,C\\r\\n845,0,3,\"Culumovic, Mr. Jeso\",male,17,0,0,315090,8.6625,,S\\r\\n846,0,3,\"Abbing, Mr. Anthony\",male,42,0,0,C.A. 5547,7.55,,S\\r\\n847,0,3,\"Sage, Mr. Douglas Bullen\",male,,8,2,CA. 2343,69.55,,S\\r\\n848,0,3,\"Markoff, Mr. Marin\",male,35,0,0,349213,7.8958,,C\\r\\n849,0,2,\"Harper, Rev. John\",male,28,0,1,248727,33,,S\\r\\n850,1,1,\"Goldenberg, Mrs. Samuel L (Edwiga Grabowska)\",female,,1,0,17453,89.1042,C92,C\\r\\n851,0,3,\"Andersson, Master. Sigvard Harald Elias\",male,4,4,2,347082,31.275,,S\\r\\n852,0,3,\"Svensson, Mr. Johan\",male,74,0,0,347060,7.775,,S\\r\\n853,0,3,\"Boulos, Miss. Nourelain\",female,9,1,1,2678,15.2458,,C\\r\\n854,1,1,\"Lines, Miss. Mary Conover\",female,16,0,1,PC 17592,39.4,D28,S\\r\\n855,0,2,\"Carter, Mrs. Ernest Courtenay (Lilian Hughes)\",female,44,1,0,244252,26,,S\\r\\n856,1,3,\"Aks, Mrs. Sam (Leah Rosen)\",female,18,0,1,392091,9.35,,S\\r\\n857,1,1,\"Wick, Mrs. George Dennick (Mary Hitchcock)\",female,45,1,1,36928,164.8667,,S\\r\\n858,1,1,\"Daly, Mr. Peter Denis \",male,51,0,0,113055,26.55,E17,S\\r\\n859,1,3,\"Baclini, Mrs. Solomon (Latifa Qurban)\",female,24,0,3,2666,19.2583,,C\\r\\n860,0,3,\"Razi, Mr. Raihed\",male,,0,0,2629,7.2292,,C\\r\\n861,0,3,\"Hansen, Mr. Claus Peter\",male,41,2,0,350026,14.1083,,S\\r\\n862,0,2,\"Giles, Mr. Frederick Edward\",male,21,1,0,28134,11.5,,S\\r\\n863,1,1,\"Swift, Mrs. Frederick Joel (Margaret Welles Barron)\",female,48,0,0,17466,25.9292,D17,S\\r\\n864,0,3,\"Sage, Miss. Dorothy Edith \"\"Dolly\"\"\",female,,8,2,CA. 2343,69.55,,S\\r\\n865,0,2,\"Gill, Mr. John William\",male,24,0,0,233866,13,,S\\r\\n866,1,2,\"Bystrom, Mrs. (Karolina)\",female,42,0,0,236852,13,,S\\r\\n867,1,2,\"Duran y More, Miss. Asuncion\",female,27,1,0,SC/PARIS 2149,13.8583,,C\\r\\n868,0,1,\"Roebling, Mr. Washington Augustus II\",male,31,0,0,PC 17590,50.4958,A24,S\\r\\n869,0,3,\"van Melkebeke, Mr. Philemon\",male,,0,0,345777,9.5,,S\\r\\n870,1,3,\"Johnson, Master. Harold Theodor\",male,4,1,1,347742,11.1333,,S\\r\\n871,0,3,\"Balkic, Mr. Cerin\",male,26,0,0,349248,7.8958,,S\\r\\n872,1,1,\"Beckwith, Mrs. Richard Leonard (Sallie Monypeny)\",female,47,1,1,11751,52.5542,D35,S\\r\\n873,0,1,\"Carlsson, Mr. Frans Olof\",male,33,0,0,695,5,B51 B53 B55,S\\r\\n874,0,3,\"Vander Cruyssen, Mr. Victor\",male,47,0,0,345765,9,,S\\r\\n875,1,2,\"Abelson, Mrs. Samuel (Hannah Wizosky)\",female,28,1,0,P/PP 3381,24,,C\\r\\n876,1,3,\"Najib, Miss. Adele Kiamie \"\"Jane\"\"\",female,15,0,0,2667,7.225,,C\\r\\n877,0,3,\"Gustafsson, Mr. Alfred Ossian\",male,20,0,0,7534,9.8458,,S\\r\\n878,0,3,\"Petroff, Mr. Nedelio\",male,19,0,0,349212,7.8958,,S\\r\\n879,0,3,\"Laleff, Mr. Kristo\",male,,0,0,349217,7.8958,,S\\r\\n880,1,1,\"Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)\",female,56,0,1,11767,83.1583,C50,C\\r\\n881,1,2,\"Shelley, Mrs. William (Imanita Parrish Hall)\",female,25,0,1,230433,26,,S\\r\\n882,0,3,\"Markun, Mr. Johann\",male,33,0,0,349257,7.8958,,S\\r\\n883,0,3,\"Dahlberg, Miss. Gerda Ulrika\",female,22,0,0,7552,10.5167,,S\\r\\n884,0,2,\"Banfield, Mr. Frederick James\",male,28,0,0,C.A./SOTON 34068,10.5,,S\\r\\n885,0,3,\"Sutehall, Mr. Henry Jr\",male,25,0,0,SOTON/OQ 392076,7.05,,S\\r\\n886,0,3,\"Rice, Mrs. William (Margaret Norton)\",female,39,0,5,382652,29.125,,Q\\r\\n887,0,2,\"Montvila, Rev. Juozas\",male,27,0,0,211536,13,,S\\r\\n888,1,1,\"Graham, Miss. Margaret Edith\",female,19,0,0,112053,30,B42,S\\r\\n889,0,3,\"Johnston, Miss. Catherine Helen \"\"Carrie\"\"\",female,,1,2,W./C. 6607,23.45,,S\\r\\n890,1,1,\"Behr, Mr. Karl Howell\",male,26,0,0,111369,30,C148,C\\r\\n891,0,3,\"Dooley, Mr. Patrick\",male,32,0,0,370376,7.75,,Q\\r\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_BWzyhUOG1F"
      },
      "source": [
        "data=pd.read_csv('/content/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMWDyGRKf6VO",
        "outputId": "3a961e17-430f-4554-b12c-cba57dc084d7"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "-R6gK6_mhPds",
        "outputId": "bbce05c1-d14c-4d22-e65f-e06904602930"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows  12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0              1         0       3  ...   7.2500   NaN         S\n",
              "1              2         1       1  ...  71.2833   C85         C\n",
              "2              3         1       3  ...   7.9250   NaN         S\n",
              "3              4         1       1  ...  53.1000  C123         S\n",
              "4              5         0       3  ...   8.0500   NaN         S\n",
              "..           ...       ...     ...  ...      ...   ...       ...\n",
              "886          887         0       2  ...  13.0000   NaN         S\n",
              "887          888         1       1  ...  30.0000   B42         S\n",
              "888          889         0       3  ...  23.4500   NaN         S\n",
              "889          890         1       1  ...  30.0000  C148         C\n",
              "890          891         0       3  ...   7.7500   NaN         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L895PWrHixrj",
        "outputId": "a4f08ca4-dfc1-48c0-acf2-4f1efd6934c5"
      },
      "source": [
        "data['Sex'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "male      577\n",
              "female    314\n",
              "Name: Sex, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOJy7j5umY0B"
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "wE01QYENlaow",
        "outputId": "b5e66be2-edb3-454f-ae43-3065fb29587e"
      },
      "source": [
        "sns.countplot(data['Sex'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f73101f06d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "8Zojg1Mxm2_N",
        "outputId": "b2bea91f-3dfb-42dc-ab63-d6489fdd50c9"
      },
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.hist(data['Age'],color='g')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjch5Ra1nzeG",
        "outputId": "ef2b6309-64ae-4000-e731-14fe1a104e64"
      },
      "source": [
        "data.info()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "6LcHp1bCtKIY",
        "outputId": "677970d1-1e8c-4c13-ffdc-3132a81a7458"
      },
      "source": [
        "sns.countplot(data['Pclass'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f731011bb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "2Am6J0iduvrL",
        "outputId": "015ed137-787e-4958-c626-cd839a36de10"
      },
      "source": [
        "sns.countplot(data['Survived'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7310110ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNSjxCFGvDbT",
        "outputId": "fb917d1b-a3a4-4874-df14-5de5051894a1"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNThAIZjvN2c"
      },
      "source": [
        "data.drop(['Name','Cabin','Ticket'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGifhSvUvr21"
      },
      "source": [
        "#data.drop(data.loc[data['age'].isnull()].index,axis=0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MV7Hl-YxGO0"
      },
      "source": [
        "#data.drop(data.loc[data['fare'].isnull()].index,axis=0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "urFKBwklCrnE",
        "outputId": "b2092c2d-3637-441c-a05d-00b4699e2168"
      },
      "source": [
        "sns.countplot(data['Embarked'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f731006b890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttv2Ft-ZC2xV"
      },
      "source": [
        "#data['embarked'].fillna('s',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDy8w8GjZ5aV"
      },
      "source": [
        "#data.drop(['name', 'ticket'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "hgQBMxlKayhe",
        "outputId": "b8ac9367-719f-468a-ae62-1aaa82ccacdf"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>C</th>\n",
              "      <th>Q</th>\n",
              "      <th>S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  C  Q  S\n",
              "0         0       3    1  22.0      1      0   7.2500  0  0  1\n",
              "1         1       1    0  38.0      1      0  71.2833  1  0  0\n",
              "2         1       3    0  26.0      0      0   7.9250  0  0  1\n",
              "3         1       1    0  35.0      1      0  53.1000  0  0  1\n",
              "4         0       3    1  35.0      0      0   8.0500  0  0  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C03FximXfixl"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "en=LabelEncoder()\n",
        "data['Sex']=en.fit_transform(data['Sex'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVU5MeOzgqcJ",
        "outputId": "2a36a83f-bd74-4813-ca09-5e729f55beb7"
      },
      "source": [
        "data['Embarked'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "S    644\n",
              "C    168\n",
              "Q     77\n",
              "Name: Embarked, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKHnsLpSgCv7"
      },
      "source": [
        "data=pd.concat((data,pd.get_dummies(data['Embarked'])),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcn3kE5Hhwtd"
      },
      "source": [
        "data.drop('Embarked',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UtHFmtaZMuj",
        "outputId": "ba69d540-0d84-4177-f638-6aa0dbe7b1dc"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Fare             0\n",
              "C                0\n",
              "Q                0\n",
              "S                0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MM0uFFCSxFC"
      },
      "source": [
        "data['Age'].fillna(data['Age'].median(),inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M65of77Etp-v"
      },
      "source": [
        "data.drop('PassengerId',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgNl9v8lmlT6"
      },
      "source": [
        "x=data.drop('Survived',axis=1)\n",
        "y=data['Survived'].astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "9Plp43Eitk4c",
        "outputId": "8af700a7-5299-4369-b942-32ebef5653a8"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>C</th>\n",
              "      <th>Q</th>\n",
              "      <th>S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows  9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass  Sex   Age  SibSp  Parch     Fare  C  Q  S\n",
              "0         3    1  22.0      1      0   7.2500  0  0  1\n",
              "1         1    0  38.0      1      0  71.2833  1  0  0\n",
              "2         3    0  26.0      0      0   7.9250  0  0  1\n",
              "3         1    0  35.0      1      0  53.1000  0  0  1\n",
              "4         3    1  35.0      0      0   8.0500  0  0  1\n",
              "..      ...  ...   ...    ...    ...      ... .. .. ..\n",
              "886       2    1  27.0      0      0  13.0000  0  0  1\n",
              "887       1    0  19.0      0      0  30.0000  0  0  1\n",
              "888       3    0  28.0      1      2  23.4500  0  0  1\n",
              "889       1    1  26.0      0      0  30.0000  1  0  0\n",
              "890       3    1  32.0      0      0   7.7500  0  1  0\n",
              "\n",
              "[891 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxgl5-5utDXw"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "s=StandardScaler()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tuy9rHcZuvGr"
      },
      "source": [
        "for a in x.columns:\n",
        "  x[a]=s.fit_transform(x[a].values.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XSl_-vctSBt",
        "outputId": "51e15f94-e002-4b12-c2ef-14c8966961be"
      },
      "source": [
        "x.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass   -2.031048e-16\n",
              "Sex      -4.059603e-16\n",
              "Age       3.841546e-16\n",
              "SibSp     3.456519e-16\n",
              "Parch     6.716164e-17\n",
              "Fare     -4.373606e-17\n",
              "C         1.167541e-16\n",
              "Q        -4.017238e-16\n",
              "S         5.632108e-17\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7Lq6BgCEnRI"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ2NMusBnOho",
        "outputId": "32ee36df-f9ac-4085-f0a8-6039a1c68d2d"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(712, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcATUWMtnkD1",
        "outputId": "5affc111-3489-4a0b-9c45-f40f1463fb7d"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lt=LogisticRegression()\n",
        "lt.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9QBFzNO9Fgp",
        "outputId": "44742fbb-2ab9-42ae-d9d4-f62378dea626"
      },
      "source": [
        "lt.score(x_test,y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8268156424581006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDvDjATLQDu9",
        "outputId": "c221c829-7e11-4c5f-9226-cc17f0569835"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn=KNeighborsClassifier()\n",
        "knn.fit(x_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwZKtNmNQSSY",
        "outputId": "fce70b6a-6051-442e-9eca-b54f97f99fe9"
      },
      "source": [
        "knn.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8212290502793296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygn-ZlT1uk2H"
      },
      "source": [
        "from sklearn.base import clone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5hkz2i3zEiG"
      },
      "source": [
        "RandomizedSearchCV?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEoWqrg18QKP",
        "outputId": "92d0a4a1-191d-445e-b373-ee4af371d8b8"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "n_neighbors=list(np.arange(1,200,2))\n",
        "weights=['uniform','distance']\n",
        "algorithm=['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "p=[1,2]\n",
        "leaf_size=list(np.arange(1,50,1))\n",
        "params={'n_neighbors':n_neighbors,\n",
        "        'weights':weights,\n",
        "        'algorithm':algorithm,\n",
        "        'leaf_size':leaf_size,\n",
        "        'p':p}\n",
        "\n",
        "rscv_knn = RandomizedSearchCV(knn,params,100,scoring='accuracy',n_jobs=-1,cv=5,verbose=1,random_state=2)\n",
        "\n",
        "rscv_knn.fit(x_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    5.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=KNeighborsClassifier(algorithm='auto',\n",
              "                                                  leaf_size=30,\n",
              "                                                  metric='minkowski',\n",
              "                                                  metric_params=None,\n",
              "                                                  n_jobs=None, n_neighbors=5,\n",
              "                                                  p=2, weights='uniform'),\n",
              "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={'algorithm': ['auto', 'ball_tree',\n",
              "                                                      'kd_tree', 'brute'],\n",
              "                                        'leaf_size': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
              "                                                      10, 11, 12, 13, 14, 15,\n",
              "                                                      16, 17, 18, 19, 20, 21,\n",
              "                                                      22, 23, 24, 25, 26, 27,\n",
              "                                                      28, 29, 30, ...],\n",
              "                                        'n_neighbors': [1, 3, 5, 7, 9, 11, 13,\n",
              "                                                        15, 17, 19, 21, 23, 25,\n",
              "                                                        27, 29, 31, 33, 35, 37,\n",
              "                                                        39, 41, 43, 45, 47, 49,\n",
              "                                                        51, 53, 55, 57, 59, ...],\n",
              "                                        'p': [1, 2],\n",
              "                                        'weights': ['uniform', 'distance']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=2, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZsgxJUrRq9O",
        "outputId": "c3a59f36-a5f8-42ad-b557-513af8235056"
      },
      "source": [
        "rscv_knn.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='brute', leaf_size=18, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=17, p=1,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh51AhEgSKtV",
        "outputId": "c0986fc1-6285-45d1-a48d-e5c5f2238138"
      },
      "source": [
        "rscv_knn.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8324022346368715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkaG1UTku7fn"
      },
      "source": [
        "knn_best=clone(rscv_knn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1uGDaQj02Y1",
        "outputId": "134adf68-5689-4d59-9284-add120a69ece"
      },
      "source": [
        "penalty=['l1', 'l2', 'elasticnet', 'none']\n",
        "c=list(np.arange(0.1,2.0,0.1))\n",
        "#iter=200\n",
        "intercept_scaling=list(np.arange(0.1,10.0,0.1))\n",
        "class_weight=['balanced']\n",
        "solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "lt_params={\n",
        "            'penalty':penalty,\n",
        "           'intercept_scaling':intercept_scaling,\n",
        "           'class_weight':class_weight,\n",
        "            'C':c,\n",
        "           'solver':solver\n",
        "}\n",
        "\n",
        "rscv_lt=RandomizedSearchCV(lt,lt_params,500,scoring='accuracy',n_jobs=-1,cv=5,verbose=1,random_state=20)\n",
        "rscv_lt.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 956 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed:   13.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                dual=False, fit_intercept=True,\n",
              "                                                intercept_scaling=1,\n",
              "                                                l1_ratio=None, max_iter=100,\n",
              "                                                multi_class='auto', n_jobs=None,\n",
              "                                                penalty='l2', random_state=None,\n",
              "                                                solver='lbfgs', tol=0.0001,\n",
              "                                                verbose=0, warm_start=False),\n",
              "                   iid='deprecated', n_iter=500, n_jobs=-1,\n",
              "                   param_distributions={'C': [...\n",
              "                                                              1.9000000000000001,\n",
              "                                                              2.0, 2.1, 2.2,\n",
              "                                                              2.3000000000000003,\n",
              "                                                              2.4000000000000004,\n",
              "                                                              2.5000000000000004,\n",
              "                                                              2.6, 2.7,\n",
              "                                                              2.8000000000000003,\n",
              "                                                              2.9000000000000004,\n",
              "                                                              3.0000000000000004, ...],\n",
              "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
              "                                                    'none'],\n",
              "                                        'solver': ['newton-cg', 'lbfgs',\n",
              "                                                   'liblinear', 'sag',\n",
              "                                                   'saga']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=20, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOPck4358i__"
      },
      "source": [
        "LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,\n",
        "                   intercept_scaling=1, l1_ratio=None, max_iter=103,\n",
        "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
        "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
        "                   warm_start=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-_qumsV6fIk",
        "outputId": "fae1019a-b03b-47d8-a22c-0eb73b7ca23b"
      },
      "source": [
        "rscv_lt.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.7000000000000001, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=4.3, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjUvaRyp7UDi",
        "outputId": "1801ada9-2aee-416b-ce4c-f54426bca7bc"
      },
      "source": [
        "rscv_lt.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8268156424581006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jivhsf4ZvEIm"
      },
      "source": [
        "lt_best=clone(rscv_lt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNdnPDE5LPXi",
        "outputId": "073ed80b-1d16-43aa-ef59-c99999e700d2"
      },
      "source": [
        "rscv_lt.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.00110688, 0.00191994, 0.00082812, 0.00074072, 0.00090013,\n",
              "        0.00083337, 0.00107484, 0.00186539, 0.00090857, 0.00126247,\n",
              "        0.00489645, 0.0007997 , 0.01971116, 0.00071864, 0.00065851,\n",
              "        0.00092163, 0.02374082, 0.00087967, 0.00097203, 0.02408457,\n",
              "        0.02177258, 0.01758347, 0.02628636, 0.00086422, 0.00085845,\n",
              "        0.00211449, 0.00747943, 0.01194725, 0.00074553, 0.00068231,\n",
              "        0.00081182, 0.00440173, 0.01897216, 0.01112857, 0.00073309,\n",
              "        0.01471181, 0.01587   , 0.02324677, 0.01948099, 0.00088997,\n",
              "        0.00086656, 0.02180829, 0.00094147, 0.00083475, 0.00336108,\n",
              "        0.02295618, 0.01939311, 0.00106144, 0.01940527, 0.00081463,\n",
              "        0.00091534, 0.00315733, 0.01005683, 0.00101876, 0.00092263,\n",
              "        0.00456853, 0.00639091, 0.00217996, 0.00471621, 0.02018352,\n",
              "        0.00079575, 0.0007647 , 0.00395875, 0.00088558, 0.00090079,\n",
              "        0.01965923, 0.01560631, 0.01954761, 0.00095882, 0.00427647,\n",
              "        0.01256089, 0.01174712, 0.00100732, 0.01102567, 0.00084152,\n",
              "        0.02257924, 0.00086598, 0.00445414, 0.0007246 , 0.00068464,\n",
              "        0.00078807, 0.00083432, 0.02202125, 0.03545108, 0.00783305,\n",
              "        0.0271121 , 0.0209269 , 0.01858506, 0.00557528, 0.01868129,\n",
              "        0.00093689, 0.00085406, 0.00078735, 0.01235476, 0.01866322,\n",
              "        0.0231606 , 0.02354012, 0.00103936, 0.01186886, 0.00088511,\n",
              "        0.00082822, 0.00083885, 0.00159426, 0.00698543, 0.01991401,\n",
              "        0.01058855, 0.00091038, 0.00510907, 0.01060152, 0.00094647,\n",
              "        0.02004194, 0.00559649, 0.00769191, 0.00097876, 0.00290828,\n",
              "        0.01820431, 0.0206027 , 0.01392026, 0.00941544, 0.02479386,\n",
              "        0.00104313, 0.0228539 , 0.02973247, 0.01564951, 0.00084562,\n",
              "        0.00076609, 0.00773811, 0.00149851, 0.02050161, 0.00083203,\n",
              "        0.0041182 , 0.00409079, 0.02953939, 0.01982346, 0.00773783,\n",
              "        0.02334843, 0.01790895, 0.00075855, 0.00081816, 0.0007082 ,\n",
              "        0.00075045, 0.01423669, 0.01487784, 0.0007925 , 0.02090826,\n",
              "        0.00091996, 0.00109682, 0.00238395, 0.0012814 , 0.01844072,\n",
              "        0.00801964, 0.00090637, 0.04155617, 0.00096188, 0.01661725,\n",
              "        0.00087137, 0.02189074, 0.02371225, 0.0010293 , 0.00249715,\n",
              "        0.00110545, 0.0047276 , 0.01556807, 0.01407161, 0.00161128,\n",
              "        0.02442603, 0.00820713, 0.00718751, 0.00103612, 0.00071979,\n",
              "        0.00998626, 0.0089509 , 0.00421891, 0.00396595, 0.01586361,\n",
              "        0.00079288, 0.00396447, 0.01813698, 0.0031332 , 0.01168098,\n",
              "        0.01868458, 0.0007946 , 0.01074295, 0.00073247, 0.00076122,\n",
              "        0.00233426, 0.01873398, 0.00095053, 0.02053685, 0.00094385,\n",
              "        0.02001896, 0.02349553, 0.00074611, 0.00066462, 0.00074511,\n",
              "        0.02187567, 0.01763134, 0.00097322, 0.01615992, 0.01675925,\n",
              "        0.00080996, 0.00084639, 0.00081239, 0.01124125, 0.0019731 ,\n",
              "        0.02107468, 0.01589899, 0.00092444, 0.01884112, 0.01223574,\n",
              "        0.00420465, 0.00371308, 0.00071239, 0.00067005, 0.00078206,\n",
              "        0.01260643, 0.00098405, 0.0032485 , 0.00315199, 0.00099607,\n",
              "        0.00087318, 0.01635008, 0.00093002, 0.03299079, 0.00088005,\n",
              "        0.00394917, 0.00723624, 0.01399393, 0.03573165, 0.00086675,\n",
              "        0.0022563 , 0.00551767, 0.00090351, 0.00080833, 0.00088429,\n",
              "        0.01231585, 0.02147589, 0.00136967, 0.00107946, 0.01277375,\n",
              "        0.00460472, 0.02690878, 0.00200472, 0.00083604, 0.0007123 ,\n",
              "        0.0007647 , 0.02875752, 0.0009047 , 0.0009027 , 0.0023931 ,\n",
              "        0.02042561, 0.0167397 , 0.00519395, 0.0195498 , 0.01847816,\n",
              "        0.00747972, 0.02904921, 0.00074749, 0.00078578, 0.00074253,\n",
              "        0.01607337, 0.01572294, 0.00087166, 0.00075922, 0.02507076,\n",
              "        0.02445307, 0.00094647, 0.01858311, 0.00233064, 0.00778918,\n",
              "        0.00077982, 0.0010119 , 0.023315  , 0.00085292, 0.00085649,\n",
              "        0.00087695, 0.03178744, 0.00093479, 0.02509599, 0.02017179,\n",
              "        0.01954403, 0.00092988, 0.03013592, 0.00767202, 0.03235245,\n",
              "        0.01219549, 0.00100079, 0.02216644, 0.01219468, 0.02060795,\n",
              "        0.00081315, 0.00738368, 0.02774715, 0.00239873, 0.01886821,\n",
              "        0.0008122 , 0.00120287, 0.00078511, 0.00072246, 0.03452268,\n",
              "        0.01557961, 0.00084491, 0.01181149, 0.01901541, 0.00080161,\n",
              "        0.01778188, 0.02366958, 0.01775661, 0.0200079 , 0.00089068,\n",
              "        0.00085344, 0.00088625, 0.00477285, 0.00457668, 0.00084805,\n",
              "        0.03372889, 0.00082903, 0.01532159, 0.0209918 , 0.0009635 ,\n",
              "        0.00657902, 0.00093536, 0.00087032, 0.00096459, 0.00088105,\n",
              "        0.0185802 , 0.00073724, 0.00380898, 0.01945505, 0.00091348,\n",
              "        0.02630134, 0.00080748, 0.00706639, 0.00082226, 0.00073271,\n",
              "        0.00076394, 0.00068631, 0.00072765, 0.00077114, 0.02561049,\n",
              "        0.00097742, 0.00080161, 0.00086541, 0.00079045, 0.01835423,\n",
              "        0.00800829, 0.00120935, 0.01239057, 0.02096715, 0.00078063,\n",
              "        0.00079412, 0.01799202, 0.0011014 , 0.00083828, 0.01846342,\n",
              "        0.00088181, 0.00069079, 0.02359209, 0.01754637, 0.00655107,\n",
              "        0.01999936, 0.02553711, 0.00093064, 0.0128427 , 0.00076838,\n",
              "        0.00100679, 0.00067024, 0.00729303, 0.01163654, 0.00088291,\n",
              "        0.01850648, 0.0009707 , 0.00388927, 0.00094619, 0.00100026,\n",
              "        0.00089984, 0.00093489, 0.00079918, 0.02648568, 0.0092442 ,\n",
              "        0.00089755, 0.01264849, 0.03312044, 0.02710958, 0.000808  ,\n",
              "        0.00081134, 0.03092561, 0.00101628, 0.00086598, 0.02068534,\n",
              "        0.02087874, 0.02742448, 0.00087271, 0.00075159, 0.00082345,\n",
              "        0.00072374, 0.01099668, 0.00881009, 0.00092978, 0.02176089,\n",
              "        0.00392194, 0.00087738, 0.01861925, 0.01324139, 0.00393782,\n",
              "        0.00075517, 0.00341449, 0.00076809, 0.00087247, 0.02462926,\n",
              "        0.01299343, 0.00438094, 0.01922669, 0.00085745, 0.00078444,\n",
              "        0.00403743, 0.01796584, 0.0126853 , 0.0008575 , 0.00091009,\n",
              "        0.00092072, 0.01403971, 0.02150059, 0.00105376, 0.00205884,\n",
              "        0.0191082 , 0.0008893 , 0.01845164, 0.00083351, 0.00075979,\n",
              "        0.01488156, 0.02253675, 0.00082841, 0.02274466, 0.01859093,\n",
              "        0.0127737 , 0.00098772, 0.00091085, 0.00084081, 0.00082197,\n",
              "        0.00089107, 0.00752802, 0.00085139, 0.00084519, 0.0206696 ,\n",
              "        0.02001257, 0.01126018, 0.00095377, 0.00079188, 0.02002606,\n",
              "        0.00083818, 0.00070214, 0.00378828, 0.00086827, 0.02165537,\n",
              "        0.00097337, 0.01808019, 0.02339678, 0.01458206, 0.0009913 ,\n",
              "        0.01772923, 0.00081058, 0.00094209, 0.00689816, 0.00073304,\n",
              "        0.0007688 , 0.01858549, 0.01151295, 0.00095043, 0.00729136,\n",
              "        0.00084686, 0.02047267, 0.00098381, 0.01440406, 0.01700759,\n",
              "        0.00077286, 0.00685091, 0.03044577, 0.00101395, 0.02038198,\n",
              "        0.01876125, 0.00450535, 0.01321707, 0.01793122, 0.01638174,\n",
              "        0.00549259, 0.00080652, 0.00076013, 0.00086083, 0.01144724,\n",
              "        0.00386286, 0.00421333, 0.0046701 , 0.01313448, 0.01009669,\n",
              "        0.00388627, 0.00307145, 0.00419779, 0.00971236, 0.01890569]),\n",
              " 'mean_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00158124, 0.        , 0.00163231, 0.        , 0.        ,\n",
              "        0.        , 0.00192356, 0.        , 0.        , 0.00195165,\n",
              "        0.00190048, 0.00169048, 0.00160766, 0.        , 0.        ,\n",
              "        0.        , 0.00156021, 0.00173631, 0.        , 0.        ,\n",
              "        0.        , 0.003057  , 0.00228682, 0.0017097 , 0.        ,\n",
              "        0.00172639, 0.00171566, 0.00447421, 0.00200706, 0.        ,\n",
              "        0.        , 0.00199633, 0.        , 0.        , 0.        ,\n",
              "        0.00221248, 0.00173745, 0.        , 0.00196033, 0.        ,\n",
              "        0.        , 0.        , 0.00263481, 0.        , 0.        ,\n",
              "        0.00188198, 0.00317287, 0.        , 0.00155883, 0.00185628,\n",
              "        0.        , 0.        , 0.00139608, 0.        , 0.        ,\n",
              "        0.00178146, 0.00166445, 0.0019208 , 0.        , 0.00261188,\n",
              "        0.00195956, 0.00178838, 0.        , 0.00169964, 0.        ,\n",
              "        0.00188894, 0.        , 0.00302668, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00171623, 0.00198598, 0.00179996,\n",
              "        0.00169005, 0.00208101, 0.00180387, 0.00210481, 0.00274806,\n",
              "        0.        , 0.        , 0.        , 0.00195665, 0.00181026,\n",
              "        0.00203943, 0.00190835, 0.        , 0.00182652, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00172524, 0.00184021,\n",
              "        0.00176268, 0.        , 0.00153508, 0.00166254, 0.        ,\n",
              "        0.00187283, 0.00172315, 0.00164299, 0.        , 0.        ,\n",
              "        0.00172467, 0.00214558, 0.00204921, 0.00192261, 0.00204964,\n",
              "        0.        , 0.00175476, 0.00178094, 0.00184832, 0.        ,\n",
              "        0.        , 0.00149879, 0.        , 0.0018271 , 0.        ,\n",
              "        0.00143251, 0.00143924, 0.00173068, 0.00303655, 0.00168157,\n",
              "        0.00212255, 0.00203924, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00165954, 0.00184822, 0.        , 0.00193849,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00182266,\n",
              "        0.00172267, 0.        , 0.0018827 , 0.        , 0.0020534 ,\n",
              "        0.        , 0.0020813 , 0.0018898 , 0.        , 0.        ,\n",
              "        0.        , 0.00157681, 0.00159879, 0.00167608, 0.        ,\n",
              "        0.00189738, 0.0018548 , 0.0014884 , 0.        , 0.        ,\n",
              "        0.00175662, 0.00183029, 0.00152164, 0.00165162, 0.00189137,\n",
              "        0.        , 0.00134516, 0.00170021, 0.        , 0.00186844,\n",
              "        0.00182209, 0.        , 0.00166049, 0.        , 0.        ,\n",
              "        0.        , 0.00171056, 0.        , 0.00183964, 0.        ,\n",
              "        0.0035017 , 0.00184474, 0.        , 0.        , 0.        ,\n",
              "        0.00181227, 0.00193281, 0.        , 0.00167508, 0.00161171,\n",
              "        0.        , 0.        , 0.        , 0.00236039, 0.        ,\n",
              "        0.00177407, 0.00167384, 0.        , 0.0018115 , 0.00173469,\n",
              "        0.00276875, 0.00124059, 0.        , 0.        , 0.        ,\n",
              "        0.00219216, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00177526, 0.        , 0.00185843, 0.        ,\n",
              "        0.0014112 , 0.00170302, 0.00206423, 0.00173101, 0.        ,\n",
              "        0.        , 0.0016964 , 0.        , 0.        , 0.        ,\n",
              "        0.00170937, 0.00183735, 0.        , 0.        , 0.00249271,\n",
              "        0.00168519, 0.00192671, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00174556, 0.        , 0.        , 0.        ,\n",
              "        0.00193424, 0.00213594, 0.0016468 , 0.00196552, 0.00188355,\n",
              "        0.00177956, 0.00177832, 0.        , 0.        , 0.        ,\n",
              "        0.00173392, 0.00179844, 0.        , 0.        , 0.00187955,\n",
              "        0.00187697, 0.        , 0.00195031, 0.        , 0.0017724 ,\n",
              "        0.        , 0.        , 0.00173059, 0.        , 0.        ,\n",
              "        0.        , 0.00205603, 0.        , 0.0019218 , 0.00178251,\n",
              "        0.00218639, 0.        , 0.00179687, 0.0017345 , 0.00190783,\n",
              "        0.00184731, 0.        , 0.00198164, 0.00186667, 0.00325232,\n",
              "        0.        , 0.00158315, 0.00199871, 0.        , 0.00175591,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00232105,\n",
              "        0.00181022, 0.        , 0.00156369, 0.00173879, 0.        ,\n",
              "        0.00180879, 0.00306726, 0.00185003, 0.00175209, 0.        ,\n",
              "        0.        , 0.        , 0.00326486, 0.00181417, 0.        ,\n",
              "        0.00184669, 0.        , 0.00167289, 0.00177279, 0.        ,\n",
              "        0.00310659, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00186839, 0.        , 0.00132747, 0.00172582, 0.        ,\n",
              "        0.00289826, 0.        , 0.00155015, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00313859,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00161304,\n",
              "        0.00150075, 0.        , 0.00162544, 0.00184565, 0.        ,\n",
              "        0.        , 0.00173597, 0.        , 0.        , 0.00210938,\n",
              "        0.        , 0.        , 0.00177989, 0.00207486, 0.00141792,\n",
              "        0.00172849, 0.00323501, 0.        , 0.0019598 , 0.        ,\n",
              "        0.        , 0.        , 0.00151577, 0.0017704 , 0.        ,\n",
              "        0.00169249, 0.        , 0.00160146, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00262337, 0.00190244,\n",
              "        0.        , 0.00198574, 0.00168452, 0.00162001, 0.        ,\n",
              "        0.        , 0.00175757, 0.        , 0.        , 0.00187945,\n",
              "        0.00182085, 0.00163121, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00186291, 0.00186486, 0.        , 0.00186539,\n",
              "        0.00140872, 0.        , 0.00183058, 0.00166535, 0.0013711 ,\n",
              "        0.        , 0.00129061, 0.        , 0.        , 0.00176673,\n",
              "        0.00182252, 0.00158639, 0.00183301, 0.        , 0.        ,\n",
              "        0.00262442, 0.00165949, 0.00172014, 0.        , 0.        ,\n",
              "        0.        , 0.00197597, 0.00187798, 0.        , 0.        ,\n",
              "        0.00172958, 0.        , 0.00254688, 0.        , 0.        ,\n",
              "        0.00164218, 0.00176525, 0.        , 0.00179539, 0.00183215,\n",
              "        0.0017251 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00309324, 0.        , 0.        , 0.00173464,\n",
              "        0.00174885, 0.00337167, 0.        , 0.        , 0.00174932,\n",
              "        0.        , 0.        , 0.00134344, 0.        , 0.00277205,\n",
              "        0.        , 0.00195899, 0.00241933, 0.00166583, 0.        ,\n",
              "        0.0018856 , 0.        , 0.        , 0.00149136, 0.        ,\n",
              "        0.        , 0.00167336, 0.00184054, 0.        , 0.00295959,\n",
              "        0.        , 0.00462837, 0.        , 0.00178628, 0.00198841,\n",
              "        0.        , 0.00148678, 0.00182853, 0.        , 0.00184474,\n",
              "        0.00179358, 0.00164442, 0.00187168, 0.00182323, 0.00174985,\n",
              "        0.00174856, 0.        , 0.        , 0.        , 0.00177493,\n",
              "        0.00140109, 0.00158572, 0.0016449 , 0.00201392, 0.00155044,\n",
              "        0.00141668, 0.        , 0.00142417, 0.00145717, 0.00182967]),\n",
              " 'mean_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.76554713,        nan, 0.76835418,        nan,        nan,\n",
              "               nan, 0.76835418,        nan,        nan, 0.76835418,\n",
              "        0.76835418, 0.76835418, 0.76835418,        nan,        nan,\n",
              "               nan, 0.76553728, 0.76835418,        nan,        nan,\n",
              "               nan, 0.76412883, 0.76553728, 0.76835418,        nan,\n",
              "        0.76835418, 0.76835418, 0.76835418, 0.76835418,        nan,\n",
              "               nan, 0.76835418,        nan,        nan,        nan,\n",
              "        0.76835418, 0.76835418,        nan, 0.76835418,        nan,\n",
              "               nan,        nan, 0.75989363,        nan,        nan,\n",
              "        0.76412883, 0.76695558,        nan, 0.76411898, 0.76553728,\n",
              "               nan,        nan, 0.76695558,        nan,        nan,\n",
              "        0.76834433, 0.76835418, 0.76835418,        nan, 0.76554713,\n",
              "        0.76834433, 0.76835418,        nan, 0.76835418,        nan,\n",
              "        0.76835418,        nan, 0.76835418,        nan,        nan,\n",
              "               nan,        nan, 0.76835418, 0.76835418, 0.76554713,\n",
              "        0.76835418, 0.76835418, 0.76835418, 0.76694573, 0.76834433,\n",
              "               nan,        nan,        nan, 0.76695558, 0.76835418,\n",
              "        0.76835418, 0.76835418,        nan, 0.76835418,        nan,\n",
              "               nan,        nan,        nan, 0.76412883, 0.76835418,\n",
              "        0.76694573,        nan, 0.76695558, 0.76553728,        nan,\n",
              "        0.76835418, 0.76695558, 0.76554713,        nan,        nan,\n",
              "        0.76835418, 0.76835418, 0.76835418, 0.76695558, 0.76835418,\n",
              "               nan, 0.76835418, 0.76835418, 0.76412883,        nan,\n",
              "               nan, 0.76554713,        nan, 0.76835418,        nan,\n",
              "        0.76554713, 0.76835418, 0.76835418, 0.76835418, 0.76412883,\n",
              "        0.76835418, 0.76835418,        nan,        nan,        nan,\n",
              "               nan, 0.76835418, 0.76835418,        nan, 0.76835418,\n",
              "               nan,        nan,        nan,        nan, 0.76835418,\n",
              "        0.76695558,        nan, 0.76835418,        nan, 0.75989363,\n",
              "               nan, 0.76835418, 0.76835418,        nan,        nan,\n",
              "               nan, 0.76412883, 0.76835418, 0.76835418,        nan,\n",
              "        0.76835418, 0.76695558, 0.76412883,        nan,        nan,\n",
              "        0.76412883, 0.76694573, 0.76552743, 0.76130208, 0.76835418,\n",
              "               nan, 0.76835418, 0.76835418,        nan, 0.76412883,\n",
              "        0.76835418,        nan, 0.76695558,        nan,        nan,\n",
              "               nan, 0.76835418,        nan, 0.76835418,        nan,\n",
              "        0.76835418, 0.76835418,        nan,        nan,        nan,\n",
              "        0.76835418, 0.76835418,        nan, 0.76553728, 0.76835418,\n",
              "               nan,        nan,        nan, 0.76834433,        nan,\n",
              "        0.76835418, 0.76694573,        nan, 0.76835418, 0.76835418,\n",
              "        0.76413868, 0.76835418,        nan,        nan,        nan,\n",
              "        0.76694573,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.76835418,        nan, 0.76835418,        nan,\n",
              "        0.76975278, 0.76412883, 0.76835418, 0.76835418,        nan,\n",
              "               nan, 0.76835418,        nan,        nan,        nan,\n",
              "        0.76835418, 0.76835418,        nan,        nan, 0.76835418,\n",
              "        0.76835418, 0.76835418,        nan,        nan,        nan,\n",
              "               nan, 0.76835418,        nan,        nan,        nan,\n",
              "        0.76835418, 0.76835418, 0.76694573, 0.76835418, 0.76835418,\n",
              "        0.76413868, 0.76835418,        nan,        nan,        nan,\n",
              "        0.76835418, 0.76835418,        nan,        nan, 0.76835418,\n",
              "        0.76835418,        nan, 0.76835418,        nan, 0.76412883,\n",
              "               nan,        nan, 0.76835418,        nan,        nan,\n",
              "               nan, 0.76835418,        nan, 0.76834433, 0.76835418,\n",
              "        0.76835418,        nan, 0.76835418, 0.76412883, 0.76835418,\n",
              "        0.76835418,        nan, 0.76835418, 0.76835418, 0.76835418,\n",
              "               nan, 0.76411898, 0.76835418,        nan, 0.76835418,\n",
              "               nan,        nan,        nan,        nan, 0.76835418,\n",
              "        0.76834433,        nan, 0.75989363, 0.76835418,        nan,\n",
              "        0.76835418, 0.76835418, 0.76835418, 0.76835418,        nan,\n",
              "               nan,        nan, 0.76554713, 0.76695558,        nan,\n",
              "        0.76835418,        nan, 0.76694573, 0.76835418,        nan,\n",
              "        0.76554713,        nan,        nan,        nan,        nan,\n",
              "        0.76835418,        nan, 0.76835418, 0.76835418,        nan,\n",
              "        0.76835418,        nan, 0.76695558,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.76835418,\n",
              "               nan,        nan,        nan,        nan, 0.76694573,\n",
              "        0.76411898,        nan, 0.76834433, 0.76835418,        nan,\n",
              "               nan, 0.76835418,        nan,        nan, 0.76835418,\n",
              "               nan,        nan, 0.76835418, 0.76835418, 0.76411898,\n",
              "        0.76835418, 0.76835418,        nan, 0.76835418,        nan,\n",
              "               nan,        nan, 0.76694573, 0.76834433,        nan,\n",
              "        0.76835418,        nan, 0.75288092,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.76835418, 0.76412883,\n",
              "               nan, 0.76834433, 0.76835418, 0.76835418,        nan,\n",
              "               nan, 0.76835418,        nan,        nan, 0.76835418,\n",
              "        0.76835418, 0.76835418,        nan,        nan,        nan,\n",
              "               nan, 0.76554713, 0.76554713,        nan, 0.76835418,\n",
              "        0.76554713,        nan, 0.76835418, 0.76695558, 0.76554713,\n",
              "               nan, 0.76835418,        nan,        nan, 0.76835418,\n",
              "        0.76834433, 0.76835418, 0.76835418,        nan,        nan,\n",
              "        0.76835418, 0.76835418, 0.76834433,        nan,        nan,\n",
              "               nan, 0.76412883, 0.76835418,        nan,        nan,\n",
              "        0.76835418,        nan, 0.76835418,        nan,        nan,\n",
              "        0.76553728, 0.76835418,        nan, 0.76835418, 0.76834433,\n",
              "        0.76835418,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.76835418,        nan,        nan, 0.76835418,\n",
              "        0.76835418, 0.76553728,        nan,        nan, 0.76835418,\n",
              "               nan,        nan, 0.76835418,        nan, 0.76835418,\n",
              "               nan, 0.76835418, 0.76835418, 0.76835418,        nan,\n",
              "        0.75989363,        nan,        nan, 0.76694573,        nan,\n",
              "               nan, 0.76835418, 0.76834433,        nan, 0.76412883,\n",
              "               nan, 0.76835418,        nan, 0.76694573, 0.76835418,\n",
              "               nan, 0.76412883, 0.76835418,        nan, 0.76835418,\n",
              "        0.76835418, 0.76412883, 0.76834433, 0.76835418, 0.75989363,\n",
              "        0.76554713,        nan,        nan,        nan, 0.76834433,\n",
              "        0.76835418, 0.76694573, 0.76835418, 0.76835418, 0.75989363,\n",
              "        0.76412883,        nan, 0.76835418, 0.75989363, 0.76834433]),\n",
              " 'param_C': masked_array(data=[0.2, 0.2, 1.4000000000000001, 1.7000000000000002,\n",
              "                    1.9000000000000001, 1.2000000000000002, 0.4, 0.4, 0.8,\n",
              "                    0.1, 1.0, 0.6, 1.9000000000000001, 1.8000000000000003,\n",
              "                    0.2, 1.9000000000000001, 0.1, 1.1, 1.5000000000000002,\n",
              "                    1.4000000000000001, 1.1, 0.9, 1.9000000000000001, 0.9,\n",
              "                    1.6, 0.1, 0.8, 0.9, 1.5000000000000002, 1.1, 0.2, 0.6,\n",
              "                    0.4, 1.6, 1.0, 1.1, 1.7000000000000002, 0.8, 0.5, 1.6,\n",
              "                    0.6, 1.9000000000000001, 1.5000000000000002, 1.1,\n",
              "                    1.8000000000000003, 1.3000000000000003, 0.9,\n",
              "                    1.2000000000000002, 1.1, 1.5000000000000002,\n",
              "                    0.30000000000000004, 0.5, 0.1, 1.4000000000000001, 0.5,\n",
              "                    0.6, 1.8000000000000003, 1.3000000000000003,\n",
              "                    0.30000000000000004, 0.4, 0.1, 1.3000000000000003, 1.6,\n",
              "                    1.4000000000000001, 1.5000000000000002, 0.6,\n",
              "                    1.3000000000000003, 1.4000000000000001,\n",
              "                    1.9000000000000001, 1.4000000000000001,\n",
              "                    0.7000000000000001, 1.8000000000000003, 1.1,\n",
              "                    1.3000000000000003, 0.4, 1.7000000000000002, 0.5,\n",
              "                    1.3000000000000003, 1.4000000000000001,\n",
              "                    0.30000000000000004, 1.4000000000000001,\n",
              "                    1.7000000000000002, 1.2000000000000002, 0.8, 1.1,\n",
              "                    1.9000000000000001, 0.7000000000000001,\n",
              "                    1.7000000000000002, 0.6, 0.7000000000000001, 0.4,\n",
              "                    1.9000000000000001, 1.9000000000000001,\n",
              "                    1.7000000000000002, 0.30000000000000004, 0.8,\n",
              "                    1.8000000000000003, 1.6, 0.8, 1.5000000000000002, 1.6,\n",
              "                    0.6, 1.7000000000000002, 0.6, 0.2, 0.5, 0.5,\n",
              "                    1.7000000000000002, 0.4, 0.6, 1.5000000000000002,\n",
              "                    1.7000000000000002, 1.1, 0.9, 0.7000000000000001,\n",
              "                    1.9000000000000001, 1.5000000000000002,\n",
              "                    1.9000000000000001, 1.8000000000000003,\n",
              "                    1.8000000000000003, 0.2, 0.5, 1.9000000000000001, 0.2,\n",
              "                    0.8, 0.4, 1.3000000000000003, 1.1, 1.2000000000000002,\n",
              "                    0.9, 1.2000000000000002, 1.9000000000000001,\n",
              "                    0.7000000000000001, 1.5000000000000002, 0.6,\n",
              "                    1.2000000000000002, 1.1, 1.3000000000000003,\n",
              "                    1.8000000000000003, 0.4, 0.8, 1.9000000000000001, 1.0,\n",
              "                    0.5, 0.2, 0.2, 1.0, 0.9, 1.6, 0.30000000000000004,\n",
              "                    1.9000000000000001, 0.6, 1.2000000000000002, 0.8, 0.1,\n",
              "                    1.6, 1.2000000000000002, 0.6, 1.7000000000000002, 0.2,\n",
              "                    0.2, 0.2, 1.4000000000000001, 1.4000000000000001, 1.6,\n",
              "                    1.2000000000000002, 1.8000000000000003, 0.5, 0.1, 0.6,\n",
              "                    0.2, 0.30000000000000004, 0.4, 0.2, 1.1,\n",
              "                    1.9000000000000001, 1.6, 0.5, 0.9, 0.7000000000000001,\n",
              "                    1.0, 1.1, 1.7000000000000002, 1.6, 1.4000000000000001,\n",
              "                    1.2000000000000002, 0.7000000000000001,\n",
              "                    1.4000000000000001, 1.9000000000000001,\n",
              "                    1.3000000000000003, 1.3000000000000003,\n",
              "                    0.7000000000000001, 1.6, 1.0, 1.5000000000000002,\n",
              "                    1.2000000000000002, 1.9000000000000001,\n",
              "                    1.5000000000000002, 0.4, 1.0, 0.9, 0.6,\n",
              "                    1.3000000000000003, 0.6, 1.4000000000000001, 0.2, 0.5,\n",
              "                    0.7000000000000001, 1.1, 1.4000000000000001, 0.8,\n",
              "                    1.9000000000000001, 1.0, 0.4, 0.7000000000000001,\n",
              "                    0.30000000000000004, 1.4000000000000001, 0.4, 0.1,\n",
              "                    1.3000000000000003, 0.9, 1.6, 0.4, 0.4, 1.1,\n",
              "                    0.7000000000000001, 0.6, 0.8, 1.2000000000000002,\n",
              "                    0.30000000000000004, 1.7000000000000002,\n",
              "                    1.5000000000000002, 1.1, 1.0, 0.1, 1.7000000000000002,\n",
              "                    1.5000000000000002, 1.9000000000000001,\n",
              "                    1.8000000000000003, 1.3000000000000003,\n",
              "                    1.5000000000000002, 0.2, 1.1, 1.5000000000000002, 0.5,\n",
              "                    1.2000000000000002, 0.2, 0.5, 0.30000000000000004,\n",
              "                    1.8000000000000003, 0.5, 1.6, 0.5, 1.7000000000000002,\n",
              "                    1.5000000000000002, 0.8, 0.9, 0.1, 1.9000000000000001,\n",
              "                    1.0, 1.3000000000000003, 0.8, 1.9000000000000001, 1.1,\n",
              "                    1.9000000000000001, 1.6, 0.7000000000000001,\n",
              "                    1.7000000000000002, 1.1, 0.5, 0.4, 0.7000000000000001,\n",
              "                    1.1, 0.5, 1.5000000000000002, 0.4, 1.7000000000000002,\n",
              "                    1.8000000000000003, 0.6, 0.6, 1.1, 1.0,\n",
              "                    1.3000000000000003, 0.2, 1.3000000000000003, 0.9,\n",
              "                    1.5000000000000002, 0.8, 1.1, 1.8000000000000003, 1.0,\n",
              "                    0.30000000000000004, 1.7000000000000002,\n",
              "                    1.4000000000000001, 1.3000000000000003, 0.5,\n",
              "                    0.7000000000000001, 1.2000000000000002,\n",
              "                    1.4000000000000001, 1.0, 0.7000000000000001, 0.1, 0.1,\n",
              "                    1.3000000000000003, 1.6, 1.2000000000000002, 1.0,\n",
              "                    1.2000000000000002, 1.1, 0.9, 0.9, 1.4000000000000001,\n",
              "                    1.0, 1.6, 0.2, 0.5, 1.2000000000000002, 0.5, 0.2, 1.0,\n",
              "                    1.4000000000000001, 1.6, 0.1, 1.5000000000000002,\n",
              "                    0.7000000000000001, 1.8000000000000003,\n",
              "                    1.4000000000000001, 1.7000000000000002, 1.6,\n",
              "                    0.30000000000000004, 1.2000000000000002,\n",
              "                    1.9000000000000001, 1.8000000000000003, 0.1, 0.8, 1.6,\n",
              "                    1.3000000000000003, 1.0, 0.1, 1.0, 1.1,\n",
              "                    1.5000000000000002, 0.4, 1.3000000000000003, 0.5,\n",
              "                    0.30000000000000004, 0.30000000000000004, 0.6,\n",
              "                    1.3000000000000003, 1.4000000000000001, 0.1, 0.2, 1.0,\n",
              "                    0.8, 1.0, 1.2000000000000002, 0.6, 1.6,\n",
              "                    1.8000000000000003, 0.30000000000000004,\n",
              "                    1.5000000000000002, 1.6, 1.2000000000000002,\n",
              "                    1.8000000000000003, 0.5, 1.9000000000000001,\n",
              "                    0.7000000000000001, 0.30000000000000004,\n",
              "                    0.7000000000000001, 0.1, 1.1, 0.1, 0.1,\n",
              "                    1.4000000000000001, 0.1, 1.3000000000000003,\n",
              "                    0.7000000000000001, 0.5, 1.1, 0.7000000000000001,\n",
              "                    1.7000000000000002, 0.6, 1.6, 0.30000000000000004,\n",
              "                    1.4000000000000001, 0.9, 1.4000000000000001,\n",
              "                    0.30000000000000004, 1.4000000000000001,\n",
              "                    1.2000000000000002, 1.0, 0.7000000000000001, 0.6,\n",
              "                    1.5000000000000002, 1.4000000000000001, 1.0, 1.0,\n",
              "                    1.2000000000000002, 1.7000000000000002, 0.4, 1.1,\n",
              "                    1.7000000000000002, 0.2, 1.6, 1.5000000000000002, 1.0,\n",
              "                    0.4, 0.8, 0.8, 1.2000000000000002, 0.7000000000000001,\n",
              "                    0.8, 1.7000000000000002, 1.3000000000000003, 0.9,\n",
              "                    1.4000000000000001, 0.30000000000000004, 0.6,\n",
              "                    1.8000000000000003, 1.2000000000000002, 0.2, 0.5,\n",
              "                    1.5000000000000002, 0.4, 0.1, 1.0, 1.6, 1.0,\n",
              "                    1.8000000000000003, 1.5000000000000002, 0.4, 0.4, 0.5,\n",
              "                    1.2000000000000002, 0.6, 1.4000000000000001, 1.6, 1.1,\n",
              "                    0.30000000000000004, 0.6, 1.5000000000000002, 0.9, 0.9,\n",
              "                    0.6, 1.3000000000000003, 0.8, 0.4, 1.7000000000000002,\n",
              "                    0.30000000000000004, 1.4000000000000001, 0.2, 0.9,\n",
              "                    1.8000000000000003, 0.9, 1.5000000000000002,\n",
              "                    1.5000000000000002, 1.6, 1.2000000000000002, 0.9,\n",
              "                    0.30000000000000004, 0.1, 1.0, 1.4000000000000001, 0.8,\n",
              "                    0.1, 0.8, 1.2000000000000002, 0.6, 0.4, 0.2, 0.6, 0.8,\n",
              "                    1.3000000000000003, 0.30000000000000004,\n",
              "                    1.8000000000000003, 1.7000000000000002, 0.2, 0.1,\n",
              "                    1.8000000000000003, 0.1, 1.3000000000000003, 0.2,\n",
              "                    0.7000000000000001, 1.6, 0.1, 1.4000000000000001,\n",
              "                    0.7000000000000001, 0.1, 0.2, 0.6, 1.6, 0.5, 0.8,\n",
              "                    1.7000000000000002, 0.1, 0.4, 1.0, 1.6, 0.1,\n",
              "                    0.7000000000000001],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_intercept_scaling': masked_array(data=[5.6, 7.5, 1.1, 0.8, 9.0, 9.0, 9.4, 6.3, 7.5, 5.6, 9.5,\n",
              "                    3.6, 5.6, 8.7, 7.6, 2.6, 3.1, 1.8000000000000003,\n",
              "                    2.9000000000000004, 9.8, 6.4, 9.9, 6.7, 6.3, 2.0, 0.1,\n",
              "                    8.1, 2.3000000000000003, 7.2, 0.7000000000000001, 0.1,\n",
              "                    3.4000000000000004, 3.4000000000000004,\n",
              "                    3.8000000000000003, 3.9000000000000004, 7.2, 8.1, 8.2,\n",
              "                    5.4, 3.1, 9.9, 6.6, 4.8, 4.1, 4.9, 0.6, 9.2,\n",
              "                    4.3999999999999995, 5.7, 0.6, 1.9000000000000001, 7.7,\n",
              "                    5.3, 5.8, 1.1, 3.3000000000000003, 7.6, 2.2, 5.0, 7.9,\n",
              "                    1.1, 6.8, 9.0, 0.7000000000000001, 1.1, 0.1,\n",
              "                    1.4000000000000001, 8.9, 8.5, 0.5, 1.0, 5.3, 6.7, 4.1,\n",
              "                    0.4, 2.4000000000000004, 3.8000000000000003, 0.9,\n",
              "                    1.2000000000000002, 2.0, 2.9000000000000004, 6.9, 0.2,\n",
              "                    6.2, 3.4000000000000004, 2.5000000000000004, 3.7, 9.0,\n",
              "                    1.3000000000000003, 3.6, 3.6, 9.9, 0.5,\n",
              "                    1.9000000000000001, 1.5000000000000002, 3.1, 7.4,\n",
              "                    9.700000000000001, 8.1, 6.9, 9.3, 9.3, 7.2, 4.0, 2.1,\n",
              "                    3.2, 2.7, 8.2, 0.8, 6.6, 2.3000000000000003, 9.6, 1.6,\n",
              "                    8.8, 6.5, 1.8000000000000003, 7.7, 8.5, 6.4, 5.9, 8.3,\n",
              "                    7.7, 6.9, 0.8, 9.9, 1.9000000000000001, 7.7, 0.6, 1.0,\n",
              "                    1.6, 5.8, 8.5, 3.9000000000000004, 8.5, 5.2,\n",
              "                    1.9000000000000001, 8.8, 1.7000000000000002, 8.9, 4.1,\n",
              "                    5.7, 0.6, 7.5, 5.1, 0.30000000000000004,\n",
              "                    1.5000000000000002, 2.9000000000000004, 2.6, 2.0, 5.5,\n",
              "                    7.0, 8.9, 4.3999999999999995, 9.1, 6.8, 8.3,\n",
              "                    1.7000000000000002, 5.9, 3.3000000000000003,\n",
              "                    3.3000000000000003, 8.7, 3.0000000000000004, 8.2, 5.0,\n",
              "                    0.1, 8.2, 7.5, 6.2, 3.1, 7.8, 7.3, 2.3000000000000003,\n",
              "                    7.7, 4.7, 9.0, 1.2000000000000002, 2.7,\n",
              "                    1.9000000000000001, 6.1, 6.7, 7.7, 3.5000000000000004,\n",
              "                    5.0, 3.0000000000000004, 6.5, 9.4, 0.5, 6.3, 8.6, 7.2,\n",
              "                    3.8000000000000003, 7.0, 3.0000000000000004, 6.2,\n",
              "                    3.9000000000000004, 9.1, 3.9000000000000004, 9.8, 7.6,\n",
              "                    5.7, 2.0, 8.9, 9.3, 5.3, 4.8, 9.2, 0.30000000000000004,\n",
              "                    7.6, 4.3999999999999995, 5.3, 1.5000000000000002,\n",
              "                    2.5000000000000004, 6.1, 7.4, 7.3, 3.2, 6.9, 8.3, 6.1,\n",
              "                    5.2, 6.0, 5.8, 8.6, 5.3, 3.2, 4.3, 3.4000000000000004,\n",
              "                    2.4000000000000004, 1.0, 5.5, 2.6, 4.6, 6.3,\n",
              "                    3.5000000000000004, 3.3000000000000003, 0.1, 3.2, 0.9,\n",
              "                    2.0, 8.3, 2.9000000000000004, 5.1, 5.1, 1.0, 5.2,\n",
              "                    3.9000000000000004, 7.9, 5.4, 0.2, 6.7, 4.9, 9.4, 9.8,\n",
              "                    6.0, 3.4000000000000004, 4.6, 1.0, 3.9000000000000004,\n",
              "                    2.8000000000000003, 1.3000000000000003, 5.3, 2.2, 7.5,\n",
              "                    3.8000000000000003, 0.5, 8.2, 2.7, 5.4, 8.6, 7.5, 1.6,\n",
              "                    6.5, 7.5, 9.1, 9.4, 2.7, 9.9, 3.6, 1.0, 3.2,\n",
              "                    3.8000000000000003, 2.3000000000000003, 0.2, 8.6, 5.7,\n",
              "                    1.7000000000000002, 5.5, 2.9000000000000004, 2.0, 8.6,\n",
              "                    1.0, 0.9, 2.7, 1.8000000000000003, 3.5000000000000004,\n",
              "                    1.9000000000000001, 1.3000000000000003,\n",
              "                    3.5000000000000004, 4.3, 2.4000000000000004, 8.3, 0.8,\n",
              "                    6.3, 6.5, 2.3000000000000003, 2.3000000000000003,\n",
              "                    3.0000000000000004, 3.5000000000000004, 6.4, 5.5, 4.8,\n",
              "                    5.1, 0.8, 6.2, 5.2, 1.8000000000000003, 3.7, 7.8, 6.4,\n",
              "                    5.7, 1.0, 7.8, 8.3, 4.2, 7.2, 2.0, 3.0000000000000004,\n",
              "                    7.8, 8.4, 6.2, 7.3, 0.1, 3.6, 2.7, 9.2,\n",
              "                    1.8000000000000003, 5.7, 0.2, 7.3, 3.9000000000000004,\n",
              "                    8.2, 3.1, 7.2, 1.8000000000000003, 9.700000000000001,\n",
              "                    4.1, 3.0000000000000004, 4.3, 6.3, 8.9,\n",
              "                    3.8000000000000003, 0.2, 4.6, 1.6, 9.8, 3.1, 6.1, 0.4,\n",
              "                    6.9, 9.700000000000001, 8.6, 3.2, 6.7, 7.7, 7.8,\n",
              "                    2.4000000000000004, 3.1, 9.6, 1.7000000000000002, 3.7,\n",
              "                    6.3, 9.3, 2.3000000000000003, 2.7, 3.9000000000000004,\n",
              "                    5.1, 0.5, 0.9, 7.1, 9.1, 0.5, 4.1, 2.0, 9.6, 6.9, 7.5,\n",
              "                    1.8000000000000003, 7.8, 6.5, 3.3000000000000003,\n",
              "                    9.700000000000001, 0.7000000000000001,\n",
              "                    3.5000000000000004, 2.9000000000000004, 9.5,\n",
              "                    1.7000000000000002, 7.9, 1.8000000000000003, 4.6,\n",
              "                    3.3000000000000003, 1.8000000000000003, 5.3, 8.0, 3.1,\n",
              "                    0.5, 3.2, 1.3000000000000003, 9.4, 4.3,\n",
              "                    0.30000000000000004, 5.3, 9.2, 8.7, 4.0, 4.6, 7.8,\n",
              "                    3.0000000000000004, 5.1, 1.7000000000000002, 5.7, 5.0,\n",
              "                    8.3, 4.3, 6.4, 9.6, 8.5, 4.6, 9.5, 0.4, 9.3,\n",
              "                    1.8000000000000003, 2.9000000000000004,\n",
              "                    3.3000000000000003, 8.0, 5.7, 3.2, 3.5000000000000004,\n",
              "                    8.9, 7.8, 2.3000000000000003, 0.2, 0.6, 3.1,\n",
              "                    3.9000000000000004, 8.7, 2.0, 5.5, 0.8, 5.7, 8.6, 9.5,\n",
              "                    3.0000000000000004, 3.1, 0.5, 8.9, 2.4000000000000004,\n",
              "                    8.1, 9.700000000000001, 0.30000000000000004,\n",
              "                    3.4000000000000004, 9.0, 1.5000000000000002, 8.5,\n",
              "                    0.30000000000000004, 9.6, 8.0, 4.8, 5.2,\n",
              "                    2.5000000000000004, 1.8000000000000003, 2.7, 9.8, 0.1,\n",
              "                    4.1, 5.4, 9.6, 1.3000000000000003, 0.2, 9.1, 7.2, 6.7,\n",
              "                    9.5, 8.9, 9.4, 7.1, 9.4, 1.6, 7.0, 8.7,\n",
              "                    1.8000000000000003, 9.6, 2.8000000000000003, 7.3, 5.9,\n",
              "                    9.4, 2.0, 3.9000000000000004, 4.8, 3.9000000000000004,\n",
              "                    3.0000000000000004],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_penalty': masked_array(data=['elasticnet', 'l1', 'l1', 'elasticnet', 'l1',\n",
              "                    'elasticnet', 'elasticnet', 'elasticnet', 'l1',\n",
              "                    'elasticnet', 'l1', 'elasticnet', 'none', 'l1', 'l1',\n",
              "                    'elasticnet', 'none', 'elasticnet', 'elasticnet', 'l2',\n",
              "                    'none', 'l2', 'none', 'elasticnet', 'l1', 'elasticnet',\n",
              "                    'l1', 'l2', 'none', 'l1', 'elasticnet', 'l1', 'l2',\n",
              "                    'l2', 'elasticnet', 'l2', 'l2', 'none', 'none',\n",
              "                    'elasticnet', 'l1', 'l2', 'none', 'l1', 'elasticnet',\n",
              "                    'l2', 'none', 'l1', 'none', 'none', 'elasticnet', 'l1',\n",
              "                    'l2', 'elasticnet', 'elasticnet', 'l1', 'l1', 'l1',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l1', 'l1', 'none',\n",
              "                    'l2', 'l2', 'l2', 'elasticnet', 'l1', 'l2', 'l2',\n",
              "                    'elasticnet', 'l2', 'elasticnet', 'l2', 'elasticnet',\n",
              "                    'l2', 'none', 'elasticnet', 'elasticnet', 'l1', 'none',\n",
              "                    'none', 'l1', 'none', 'none', 'none', 'l2', 'l2', 'l1',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'none', 'l2', 'none',\n",
              "                    'elasticnet', 'l2', 'elasticnet', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'none', 'l2', 'l1',\n",
              "                    'l1', 'l2', 'elasticnet', 'none', 'l1', 'l1', 'none',\n",
              "                    'l1', 'none', 'l2', 'l2', 'l1', 'l2', 'elasticnet',\n",
              "                    'none', 'none', 'l2', 'elasticnet', 'elasticnet', 'l1',\n",
              "                    'l1', 'none', 'elasticnet', 'l1', 'l2', 'none', 'l2',\n",
              "                    'l1', 'l2', 'l2', 'elasticnet', 'l1', 'l1', 'none',\n",
              "                    'l2', 'l2', 'elasticnet', 'none', 'elasticnet',\n",
              "                    'elasticnet', 'none', 'elasticnet', 'none', 'l1', 'l1',\n",
              "                    'none', 'elasticnet', 'l2', 'elasticnet', 'none',\n",
              "                    'none', 'elasticnet', 'elasticnet', 'elasticnet', 'l2',\n",
              "                    'l2', 'l2', 'l1', 'l2', 'l1', 'l1', 'l1', 'elasticnet',\n",
              "                    'l2', 'l2', 'l1', 'l1', 'l2', 'none', 'l2', 'none',\n",
              "                    'elasticnet', 'l1', 'none', 'elasticnet', 'l1', 'none',\n",
              "                    'elasticnet', 'elasticnet', 'none', 'elasticnet',\n",
              "                    'none', 'elasticnet', 'none', 'none', 'l1', 'l1',\n",
              "                    'elasticnet', 'none', 'l2', 'elasticnet', 'l2', 'none',\n",
              "                    'elasticnet', 'elasticnet', 'elasticnet', 'l2',\n",
              "                    'elasticnet', 'none', 'l2', 'elasticnet', 'none', 'l2',\n",
              "                    'l1', 'l2', 'l1', 'none', 'l1', 'l2', 'none', 'l1',\n",
              "                    'l1', 'l1', 'elasticnet', 'l2', 'elasticnet', 'none',\n",
              "                    'l1', 'l2', 'l1', 'l2', 'none', 'elasticnet',\n",
              "                    'elasticnet', 'l2', 'elasticnet', 'l1', 'elasticnet',\n",
              "                    'l2', 'none', 'l1', 'elasticnet', 'l2', 'l2', 'none',\n",
              "                    'elasticnet', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'none', 'elasticnet', 'l1', 'l1', 'none', 'l2', 'l2',\n",
              "                    'l2', 'none', 'l1', 'none', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l2', 'l2', 'elasticnet', 'l1', 'l2', 'none',\n",
              "                    'l1', 'l2', 'none', 'l1', 'l1', 'none', 'none',\n",
              "                    'elasticnet', 'none', 'elasticnet', 'none', 'l1', 'l2',\n",
              "                    'none', 'l2', 'none', 'none', 'l2', 'none', 'l2',\n",
              "                    'elasticnet', 'l2', 'l2', 'none', 'elasticnet', 'l1',\n",
              "                    'l2', 'elasticnet', 'none', 'l1', 'elasticnet',\n",
              "                    'elasticnet', 'l1', 'none', 'l2', 'elasticnet', 'l2',\n",
              "                    'l2', 'elasticnet', 'none', 'l2', 'l2', 'l2',\n",
              "                    'elasticnet', 'l1', 'elasticnet', 'l1', 'l1', 'none',\n",
              "                    'none', 'l1', 'l2', 'none', 'none', 'l1', 'elasticnet',\n",
              "                    'l1', 'elasticnet', 'elasticnet', 'l2', 'elasticnet',\n",
              "                    'l2', 'l2', 'elasticnet', 'none', 'elasticnet', 'l1',\n",
              "                    'none', 'elasticnet', 'l1', 'l1', 'l1', 'none', 'l2',\n",
              "                    'elasticnet', 'l1', 'elasticnet', 'elasticnet', 'l2',\n",
              "                    'l1', 'none', 'l2', 'none', 'elasticnet', 'none',\n",
              "                    'none', 'elasticnet', 'elasticnet', 'none', 'l1',\n",
              "                    'none', 'none', 'none', 'l1', 'l2', 'none', 'l1', 'l2',\n",
              "                    'elasticnet', 'elasticnet', 'elasticnet', 'l2', 'l2',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'elasticnet', 'none',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'none', 'l1',\n",
              "                    'elasticnet', 'l2', 'none', 'none', 'l1', 'l1', 'none',\n",
              "                    'l1', 'none', 'none', 'l2', 'none', 'l1', 'l1',\n",
              "                    'elasticnet', 'l1', 'l1', 'l1', 'elasticnet', 'none',\n",
              "                    'l1', 'l1', 'none', 'l1', 'l1', 'elasticnet', 'l2',\n",
              "                    'l1', 'elasticnet', 'none', 'l2', 'l2', 'none', 'l1',\n",
              "                    'none', 'l2', 'none', 'l2', 'none', 'l1', 'none', 'l1',\n",
              "                    'none', 'elasticnet', 'elasticnet', 'none', 'l1',\n",
              "                    'none', 'l1', 'elasticnet', 'l2', 'none', 'elasticnet',\n",
              "                    'l2', 'l2', 'l2', 'elasticnet', 'l1', 'none', 'l1',\n",
              "                    'elasticnet', 'l2', 'elasticnet', 'l1', 'none', 'l2',\n",
              "                    'l2', 'l1', 'l1', 'none', 'elasticnet', 'l1', 'l2',\n",
              "                    'l1', 'none', 'none', 'l2', 'none', 'l2', 'l1', 'l2',\n",
              "                    'l1', 'elasticnet', 'l1', 'elasticnet', 'elasticnet',\n",
              "                    'l2', 'l2', 'l1', 'l2', 'elasticnet', 'none',\n",
              "                    'elasticnet', 'l2', 'l2', 'l1', 'l2', 'none',\n",
              "                    'elasticnet', 'none', 'l2', 'l2', 'l2', 'none', 'l2',\n",
              "                    'l1', 'l1', 'elasticnet', 'elasticnet', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l1', 'elasticnet', 'l2', 'l2',\n",
              "                    'l2'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_solver': masked_array(data=['saga', 'newton-cg', 'lbfgs', 'newton-cg', 'lbfgs',\n",
              "                    'lbfgs', 'newton-cg', 'newton-cg', 'sag', 'newton-cg',\n",
              "                    'liblinear', 'saga', 'lbfgs', 'sag', 'lbfgs',\n",
              "                    'newton-cg', 'saga', 'lbfgs', 'saga', 'saga', 'saga',\n",
              "                    'newton-cg', 'newton-cg', 'sag', 'sag', 'sag',\n",
              "                    'liblinear', 'lbfgs', 'liblinear', 'lbfgs', 'lbfgs',\n",
              "                    'liblinear', 'saga', 'lbfgs', 'newton-cg', 'newton-cg',\n",
              "                    'newton-cg', 'sag', 'sag', 'saga', 'lbfgs', 'saga',\n",
              "                    'liblinear', 'newton-cg', 'sag', 'newton-cg', 'lbfgs',\n",
              "                    'newton-cg', 'sag', 'liblinear', 'newton-cg',\n",
              "                    'newton-cg', 'saga', 'newton-cg', 'saga', 'liblinear',\n",
              "                    'liblinear', 'lbfgs', 'liblinear', 'saga', 'liblinear',\n",
              "                    'newton-cg', 'liblinear', 'newton-cg', 'liblinear',\n",
              "                    'saga', 'newton-cg', 'sag', 'sag', 'liblinear', 'sag',\n",
              "                    'lbfgs', 'saga', 'lbfgs', 'lbfgs', 'sag', 'liblinear',\n",
              "                    'liblinear', 'liblinear', 'lbfgs', 'liblinear',\n",
              "                    'lbfgs', 'lbfgs', 'newton-cg', 'saga', 'newton-cg',\n",
              "                    'lbfgs', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'newton-cg', 'lbfgs', 'lbfgs', 'saga', 'lbfgs', 'saga',\n",
              "                    'sag', 'sag', 'lbfgs', 'saga', 'newton-cg', 'sag',\n",
              "                    'newton-cg', 'liblinear', 'saga', 'sag', 'lbfgs',\n",
              "                    'liblinear', 'sag', 'saga', 'saga', 'liblinear',\n",
              "                    'saga', 'liblinear', 'lbfgs', 'lbfgs', 'sag', 'lbfgs',\n",
              "                    'saga', 'saga', 'newton-cg', 'sag', 'newton-cg',\n",
              "                    'newton-cg', 'sag', 'sag', 'saga', 'newton-cg', 'saga',\n",
              "                    'sag', 'liblinear', 'liblinear', 'newton-cg', 'sag',\n",
              "                    'saga', 'saga', 'sag', 'saga', 'newton-cg', 'sag',\n",
              "                    'liblinear', 'lbfgs', 'sag', 'liblinear', 'saga',\n",
              "                    'newton-cg', 'newton-cg', 'liblinear', 'sag', 'sag',\n",
              "                    'saga', 'sag', 'newton-cg', 'saga', 'newton-cg',\n",
              "                    'newton-cg', 'sag', 'lbfgs', 'lbfgs', 'saga',\n",
              "                    'liblinear', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'newton-cg', 'newton-cg', 'saga', 'saga', 'sag',\n",
              "                    'newton-cg', 'saga', 'sag', 'liblinear', 'liblinear',\n",
              "                    'sag', 'liblinear', 'liblinear', 'lbfgs', 'newton-cg',\n",
              "                    'saga', 'lbfgs', 'newton-cg', 'saga', 'liblinear',\n",
              "                    'sag', 'liblinear', 'lbfgs', 'liblinear', 'saga',\n",
              "                    'liblinear', 'sag', 'lbfgs', 'lbfgs', 'lbfgs',\n",
              "                    'liblinear', 'saga', 'sag', 'newton-cg', 'saga',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'liblinear', 'sag',\n",
              "                    'newton-cg', 'sag', 'newton-cg', 'newton-cg', 'lbfgs',\n",
              "                    'lbfgs', 'liblinear', 'liblinear', 'sag', 'liblinear',\n",
              "                    'lbfgs', 'saga', 'liblinear', 'lbfgs', 'lbfgs',\n",
              "                    'newton-cg', 'sag', 'newton-cg', 'sag', 'newton-cg',\n",
              "                    'newton-cg', 'liblinear', 'saga', 'lbfgs', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'liblinear', 'saga', 'lbfgs',\n",
              "                    'newton-cg', 'lbfgs', 'sag', 'sag', 'lbfgs', 'lbfgs',\n",
              "                    'liblinear', 'sag', 'sag', 'newton-cg', 'sag', 'saga',\n",
              "                    'newton-cg', 'sag', 'sag', 'newton-cg', 'lbfgs',\n",
              "                    'lbfgs', 'liblinear', 'sag', 'sag', 'liblinear',\n",
              "                    'newton-cg', 'liblinear', 'newton-cg', 'newton-cg',\n",
              "                    'newton-cg', 'sag', 'lbfgs', 'lbfgs', 'saga', 'saga',\n",
              "                    'lbfgs', 'newton-cg', 'liblinear', 'saga', 'newton-cg',\n",
              "                    'liblinear', 'sag', 'newton-cg', 'liblinear', 'saga',\n",
              "                    'newton-cg', 'newton-cg', 'saga', 'lbfgs', 'newton-cg',\n",
              "                    'liblinear', 'newton-cg', 'sag', 'newton-cg', 'lbfgs',\n",
              "                    'sag', 'saga', 'lbfgs', 'sag', 'newton-cg', 'saga',\n",
              "                    'saga', 'sag', 'sag', 'newton-cg', 'newton-cg',\n",
              "                    'lbfgs', 'lbfgs', 'newton-cg', 'sag', 'newton-cg',\n",
              "                    'lbfgs', 'saga', 'saga', 'lbfgs', 'saga', 'sag',\n",
              "                    'saga', 'newton-cg', 'sag', 'newton-cg', 'liblinear',\n",
              "                    'liblinear', 'liblinear', 'newton-cg', 'sag', 'saga',\n",
              "                    'saga', 'liblinear', 'liblinear', 'lbfgs', 'sag',\n",
              "                    'liblinear', 'liblinear', 'sag', 'newton-cg',\n",
              "                    'liblinear', 'saga', 'newton-cg', 'saga', 'newton-cg',\n",
              "                    'liblinear', 'liblinear', 'saga', 'sag', 'lbfgs',\n",
              "                    'sag', 'liblinear', 'saga', 'liblinear', 'lbfgs',\n",
              "                    'lbfgs', 'sag', 'newton-cg', 'saga', 'liblinear',\n",
              "                    'lbfgs', 'saga', 'sag', 'liblinear', 'sag',\n",
              "                    'newton-cg', 'newton-cg', 'sag', 'lbfgs', 'liblinear',\n",
              "                    'saga', 'sag', 'saga', 'saga', 'saga', 'newton-cg',\n",
              "                    'lbfgs', 'sag', 'sag', 'newton-cg', 'sag', 'sag',\n",
              "                    'lbfgs', 'newton-cg', 'saga', 'liblinear', 'sag',\n",
              "                    'liblinear', 'saga', 'lbfgs', 'newton-cg', 'saga',\n",
              "                    'saga', 'saga', 'sag', 'newton-cg', 'newton-cg', 'sag',\n",
              "                    'lbfgs', 'newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
              "                    'saga', 'newton-cg', 'newton-cg', 'newton-cg',\n",
              "                    'liblinear', 'newton-cg', 'saga', 'saga', 'sag',\n",
              "                    'saga', 'liblinear', 'sag', 'sag', 'saga', 'liblinear',\n",
              "                    'lbfgs', 'liblinear', 'sag', 'sag', 'saga', 'sag',\n",
              "                    'liblinear', 'lbfgs', 'lbfgs', 'liblinear',\n",
              "                    'liblinear', 'lbfgs', 'lbfgs', 'liblinear', 'sag',\n",
              "                    'liblinear', 'saga', 'sag', 'sag', 'lbfgs', 'saga',\n",
              "                    'sag', 'sag', 'newton-cg', 'liblinear', 'newton-cg',\n",
              "                    'saga', 'newton-cg', 'saga', 'newton-cg', 'lbfgs',\n",
              "                    'lbfgs', 'lbfgs', 'liblinear', 'sag', 'newton-cg',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'lbfgs', 'saga',\n",
              "                    'sag', 'newton-cg', 'newton-cg', 'sag', 'liblinear',\n",
              "                    'newton-cg', 'liblinear', 'lbfgs', 'lbfgs',\n",
              "                    'liblinear', 'sag', 'saga', 'newton-cg', 'lbfgs',\n",
              "                    'newton-cg', 'newton-cg', 'newton-cg', 'saga', 'saga',\n",
              "                    'liblinear', 'newton-cg', 'sag', 'sag', 'sag',\n",
              "                    'liblinear', 'sag', 'lbfgs', 'lbfgs', 'newton-cg',\n",
              "                    'sag', 'sag', 'newton-cg', 'saga', 'sag', 'newton-cg',\n",
              "                    'liblinear', 'sag', 'sag', 'newton-cg', 'liblinear',\n",
              "                    'newton-cg', 'sag', 'saga', 'sag', 'liblinear',\n",
              "                    'liblinear', 'liblinear', 'lbfgs', 'lbfgs',\n",
              "                    'liblinear', 'saga', 'liblinear', 'lbfgs', 'saga'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.5,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.8,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.0,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.0,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.4,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.5,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.5,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.6,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.1,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.9000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.4,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.9,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.0,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.3000000000000003,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.7000000000000001,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.4000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.4000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.8000000000000003,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.9000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.2,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.4,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.9,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.6,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.8,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.9,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.6,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.3999999999999995,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.6,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.9000000000000001,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.8,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.3000000000000003,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.2,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.0,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.9,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.8,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.0,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.7000000000000001,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.1,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.4000000000000001,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.9,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.5,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.0,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.7,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.4,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.4000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.8000000000000003,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.9,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.2000000000000002,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.0,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.9000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.9,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.4000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.5000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.0,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.3000000000000003,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.6,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.9,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.9000000000000001,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.5000000000000002,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.4,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.700000000000001,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.9,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.2,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.0,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.1,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.2,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.2,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.3000000000000003,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.8,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.5,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.7,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.5,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.4,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.9,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.9,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.9,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.9000000000000001,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.0,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.8,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.5,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.9000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.5,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.2,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.9000000000000001,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.7000000000000002,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.9,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.6,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.5,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.30000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.5000000000000002,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.9000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.6,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.0,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.5,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.0,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.9,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.3999999999999995,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.7000000000000002,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.9,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.3000000000000003,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.3000000000000003,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.7,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.0000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.2,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.0,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.2,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.5,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.2,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.8,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.3000000000000003,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.0,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.2000000000000002,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.7,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.9000000000000001,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.5000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.0,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.0000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.4,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.5,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.6,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.2,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.8000000000000003,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.0,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.0000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.2,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.9000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.1,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.9000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.8,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.6,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.0,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.9,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.8,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.30000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.3999999999999995,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.5000000000000002,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.5000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.4,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.3,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.2,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.9,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.3,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.2,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.0,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.3,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.2,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.4000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.4000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.0,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.6,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.5000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.3000000000000003,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.9,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.0,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.9000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.1,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.0,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.2,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.9000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.9,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.4,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.2,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.9,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.4,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.0,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.4000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.0,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.9000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.8000000000000003,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.3000000000000003,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.2,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.8000000000000003,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.5,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.4,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.6,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.5,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.5,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.5,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.4,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.7,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.9,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.0,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.8000000000000003,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.3000000000000003,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.6,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.7000000000000002,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.9000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.0,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.6,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.0,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.9,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.7,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.5000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.9000000000000001,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.3000000000000003,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.5000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.3,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.4000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.8,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.5,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.3000000000000003,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.3000000000000003,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.0000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.5000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.4,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.8,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.8,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.2,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.4,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.0,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.8,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.3,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.2,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.2,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.0,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.0000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.4,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.2,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.3,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.2,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.2,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.3,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.9000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.2,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.2,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.700000000000001,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.0000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.3,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.9,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.8000000000000003,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.8,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.1,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.4,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.9,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.700000000000001,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.6,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.7,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.8,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.9000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.4000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.6,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.7000000000000002,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.3000000000000003,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.7,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.9000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.9,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.1,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.0,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.6,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.9,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.5,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.8,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.5,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.3000000000000003,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.700000000000001,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.7000000000000001,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.5000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.9000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.7000000000000002,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.9,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.3000000000000003,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.3,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.0,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.1,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.5,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.2,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.3000000000000003,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.4,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.30000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.2,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.0,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.6,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.0000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.7000000000000002,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.0,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.3,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.3,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.4,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.5,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.5,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.4,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.3,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.9000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.3000000000000003,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.0,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.7,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.2,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.5000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.9,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.8,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.3000000000000003,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.2,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.6,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.9000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.7,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.0,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.5,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.8,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.7,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.6,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.0000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.5,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.9,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.5000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.4000000000000004,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.700000000000001,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.9,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.30000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.4000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.0,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.5000000000000002,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.5,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.30000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.6,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.0,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.2000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.2,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.5000000000000004,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.7,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.8,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.30000000000000004,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.4,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.3000000000000003,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 0.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.8000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.1,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.2,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.3000000000000003,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 6.7,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.5,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.9,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.4,\n",
              "   'penalty': 'none',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.1,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 1.4000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.4,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.6,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'newton-cg'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.0,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 0.2,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 8.7,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 0.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 1.8000000000000003,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'sag'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.6,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.5,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.8000000000000003,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.8,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 7.3,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.7000000000000002,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 5.9,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 9.4,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.4,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 2.0,\n",
              "   'penalty': 'l1',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 1.0,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.9000000000000004,\n",
              "   'penalty': 'elasticnet',\n",
              "   'solver': 'saga'},\n",
              "  {'C': 1.6,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 4.8,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'liblinear'},\n",
              "  {'C': 0.1,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.9000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'lbfgs'},\n",
              "  {'C': 0.7000000000000001,\n",
              "   'class_weight': 'balanced',\n",
              "   'intercept_scaling': 3.0000000000000004,\n",
              "   'penalty': 'l2',\n",
              "   'solver': 'saga'}],\n",
              " 'rank_test_score': array([338, 395, 394, 393, 392, 391, 390, 389, 396, 388, 208, 386,   2,\n",
              "        385, 384, 383,   2, 382, 381,   2,   2,   2,   2, 380, 387, 397,\n",
              "        221,   2, 398, 399, 416, 231, 222,   2, 415,   2,   2,   2,   2,\n",
              "        414, 413,   2, 412, 411, 410,   2,   2, 409,   2, 408, 407, 406,\n",
              "        254, 405, 404, 231, 184, 403, 249, 222, 402, 401, 184, 400, 379,\n",
              "        168,   2,   2, 378, 208, 168,   2, 377,   2, 357,   2, 355,   2,\n",
              "        354, 353, 352, 351,   2,   2, 208,   2,   2,   2, 196, 168, 350,\n",
              "        349, 356, 184,   2,   2,   2, 348,   2, 346, 345, 344, 343, 231,\n",
              "          2, 196, 342, 184, 222, 341,   2, 184, 208, 340, 347,   2,   2,\n",
              "          2, 184,   2, 358,   2,   2, 238, 367, 359, 208, 375,   2, 374,\n",
              "        208,   2,   2,   2, 231,   2,   2, 373, 372, 371, 370,   2,   2,\n",
              "        369,   2, 376, 368, 366, 365,   2, 184, 364,   2, 363, 254, 362,\n",
              "          2,   2, 361, 360, 417, 238,   2,   2, 418,   2, 184, 238, 419,\n",
              "        420, 238, 196, 228, 253,   2, 477,   2,   2, 476, 231,   2, 475,\n",
              "        184, 474, 473, 472,   2, 471,   2, 478,   2,   2, 470, 468, 467,\n",
              "          2,   2, 466, 222,   2, 465, 464, 463, 168, 462,   2, 196, 469,\n",
              "          2,   2, 229,   2, 479, 480, 481, 196, 498, 497, 496, 495, 494,\n",
              "          2, 493,   2, 492,   1, 231,   2,   2, 491, 490,   2, 489, 488,\n",
              "        487,   2,   2, 486, 485,   2,   2,   2, 484, 483, 482, 461,   2,\n",
              "        499, 460, 500,   2,   2, 196,   2,   2, 229,   2, 458, 436, 435,\n",
              "          2,   2, 434, 433,   2,   2, 432,   2, 431, 238, 430, 437,   2,\n",
              "        429, 427, 426,   2, 425, 168,   2,   2, 424,   2, 238,   2,   2,\n",
              "        423,   2,   2,   2, 422, 249,   2, 421,   2, 428, 438, 439, 440,\n",
              "          2, 168, 457, 254,   2, 456,   2,   2,   2,   2, 455, 454, 453,\n",
              "        208, 184, 452,   2, 451, 196,   2, 450, 208, 449, 448, 447, 446,\n",
              "          2, 445,   2,   2, 444,   2, 443, 184, 442, 441, 339, 459, 337,\n",
              "        331,   2, 264, 274, 265, 267, 196, 249, 271, 168,   2, 273, 270,\n",
              "          2, 269, 268,   2, 266, 263,   2,   2, 249,   2,   2, 272,   2,\n",
              "        262, 275, 306, 196, 168, 277,   2, 309, 261, 310, 311, 312, 313,\n",
              "        314,   2, 231, 315, 168,   2,   2, 316, 317,   2, 318, 319,   2,\n",
              "          2,   2, 320, 321, 322, 323, 208, 208, 324,   2, 208, 325,   2,\n",
              "        184, 208, 326, 167, 327, 328,   2, 168,   2,   2, 329, 330,   2,\n",
              "          2, 168, 276, 332, 333, 238,   2, 334, 335,   2, 308,   2, 336,\n",
              "        307, 222,   2, 305,   2, 168,   2, 278, 279, 280, 281, 282,   2,\n",
              "        283, 284,   2,   2, 222, 285, 286,   2, 287, 288,   2, 289,   2,\n",
              "        290,   2,   2,   2, 291, 254, 292, 293, 196, 294, 295,   2, 168,\n",
              "        296, 238, 297,   2, 298, 196,   2, 299, 238,   2, 300,   2,   2,\n",
              "        238, 168,   2, 254, 208, 301, 302, 303, 168,   2, 196,   2,   2,\n",
              "        254, 238, 304,   2, 254, 168], dtype=int32),\n",
              " 'split0_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.6993007 ,        nan, 0.70629371,        nan,        nan,\n",
              "               nan, 0.70629371,        nan,        nan, 0.70629371,\n",
              "        0.70629371, 0.70629371, 0.70629371,        nan,        nan,\n",
              "               nan, 0.6993007 , 0.70629371,        nan,        nan,\n",
              "               nan, 0.6993007 , 0.69230769, 0.70629371,        nan,\n",
              "        0.70629371, 0.70629371, 0.70629371, 0.70629371,        nan,\n",
              "               nan, 0.70629371,        nan,        nan,        nan,\n",
              "        0.70629371, 0.70629371,        nan, 0.70629371,        nan,\n",
              "               nan,        nan, 0.69230769,        nan,        nan,\n",
              "        0.6993007 , 0.6993007 ,        nan, 0.70629371, 0.69230769,\n",
              "               nan,        nan, 0.6993007 ,        nan,        nan,\n",
              "        0.70629371, 0.70629371, 0.70629371,        nan, 0.6993007 ,\n",
              "        0.70629371, 0.70629371,        nan, 0.70629371,        nan,\n",
              "        0.70629371,        nan, 0.70629371,        nan,        nan,\n",
              "               nan,        nan, 0.70629371, 0.70629371, 0.6993007 ,\n",
              "        0.70629371, 0.70629371, 0.70629371, 0.70629371, 0.70629371,\n",
              "               nan,        nan,        nan, 0.6993007 , 0.70629371,\n",
              "        0.70629371, 0.70629371,        nan, 0.70629371,        nan,\n",
              "               nan,        nan,        nan, 0.6993007 , 0.70629371,\n",
              "        0.6993007 ,        nan, 0.6993007 , 0.69230769,        nan,\n",
              "        0.70629371, 0.6993007 , 0.6993007 ,        nan,        nan,\n",
              "        0.70629371, 0.70629371, 0.70629371, 0.6993007 , 0.70629371,\n",
              "               nan, 0.70629371, 0.70629371, 0.69230769,        nan,\n",
              "               nan, 0.6993007 ,        nan, 0.70629371,        nan,\n",
              "        0.6993007 , 0.70629371, 0.70629371, 0.70629371, 0.6993007 ,\n",
              "        0.70629371, 0.70629371,        nan,        nan,        nan,\n",
              "               nan, 0.70629371, 0.70629371,        nan, 0.70629371,\n",
              "               nan,        nan,        nan,        nan, 0.70629371,\n",
              "        0.6993007 ,        nan, 0.70629371,        nan, 0.69230769,\n",
              "               nan, 0.70629371, 0.70629371,        nan,        nan,\n",
              "               nan, 0.69230769, 0.70629371, 0.70629371,        nan,\n",
              "        0.70629371, 0.6993007 , 0.6993007 ,        nan,        nan,\n",
              "        0.69230769, 0.69230769, 0.70629371, 0.70629371, 0.70629371,\n",
              "               nan, 0.70629371, 0.70629371,        nan, 0.6993007 ,\n",
              "        0.70629371,        nan, 0.6993007 ,        nan,        nan,\n",
              "               nan, 0.70629371,        nan, 0.70629371,        nan,\n",
              "        0.70629371, 0.70629371,        nan,        nan,        nan,\n",
              "        0.70629371, 0.70629371,        nan, 0.69230769, 0.70629371,\n",
              "               nan,        nan,        nan, 0.70629371,        nan,\n",
              "        0.70629371, 0.6993007 ,        nan, 0.70629371, 0.70629371,\n",
              "        0.6993007 , 0.70629371,        nan,        nan,        nan,\n",
              "        0.69230769,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.70629371,        nan, 0.70629371,        nan,\n",
              "        0.70629371, 0.6993007 , 0.70629371, 0.70629371,        nan,\n",
              "               nan, 0.70629371,        nan,        nan,        nan,\n",
              "        0.70629371, 0.70629371,        nan,        nan, 0.70629371,\n",
              "        0.70629371, 0.70629371,        nan,        nan,        nan,\n",
              "               nan, 0.70629371,        nan,        nan,        nan,\n",
              "        0.70629371, 0.70629371, 0.6993007 , 0.70629371, 0.70629371,\n",
              "        0.6993007 , 0.70629371,        nan,        nan,        nan,\n",
              "        0.70629371, 0.70629371,        nan,        nan, 0.70629371,\n",
              "        0.70629371,        nan, 0.70629371,        nan, 0.6993007 ,\n",
              "               nan,        nan, 0.70629371,        nan,        nan,\n",
              "               nan, 0.70629371,        nan, 0.70629371, 0.70629371,\n",
              "        0.70629371,        nan, 0.70629371, 0.69230769, 0.70629371,\n",
              "        0.70629371,        nan, 0.70629371, 0.70629371, 0.70629371,\n",
              "               nan, 0.70629371, 0.70629371,        nan, 0.70629371,\n",
              "               nan,        nan,        nan,        nan, 0.70629371,\n",
              "        0.70629371,        nan, 0.69230769, 0.70629371,        nan,\n",
              "        0.70629371, 0.70629371, 0.70629371, 0.70629371,        nan,\n",
              "               nan,        nan, 0.6993007 , 0.6993007 ,        nan,\n",
              "        0.70629371,        nan, 0.6993007 , 0.70629371,        nan,\n",
              "        0.6993007 ,        nan,        nan,        nan,        nan,\n",
              "        0.70629371,        nan, 0.70629371, 0.70629371,        nan,\n",
              "        0.70629371,        nan, 0.6993007 ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.70629371,\n",
              "               nan,        nan,        nan,        nan, 0.6993007 ,\n",
              "        0.70629371,        nan, 0.70629371, 0.70629371,        nan,\n",
              "               nan, 0.70629371,        nan,        nan, 0.70629371,\n",
              "               nan,        nan, 0.70629371, 0.70629371, 0.70629371,\n",
              "        0.70629371, 0.70629371,        nan, 0.70629371,        nan,\n",
              "               nan,        nan, 0.69230769, 0.70629371,        nan,\n",
              "        0.70629371,        nan, 0.6993007 ,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.70629371, 0.6993007 ,\n",
              "               nan, 0.70629371, 0.70629371, 0.70629371,        nan,\n",
              "               nan, 0.70629371,        nan,        nan, 0.70629371,\n",
              "        0.70629371, 0.70629371,        nan,        nan,        nan,\n",
              "               nan, 0.6993007 , 0.6993007 ,        nan, 0.70629371,\n",
              "        0.6993007 ,        nan, 0.70629371, 0.6993007 , 0.6993007 ,\n",
              "               nan, 0.6993007 ,        nan,        nan, 0.70629371,\n",
              "        0.70629371, 0.70629371, 0.70629371,        nan,        nan,\n",
              "        0.70629371, 0.70629371, 0.70629371,        nan,        nan,\n",
              "               nan, 0.6993007 , 0.70629371,        nan,        nan,\n",
              "        0.70629371,        nan, 0.70629371,        nan,        nan,\n",
              "        0.69230769, 0.70629371,        nan, 0.70629371, 0.70629371,\n",
              "        0.70629371,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.70629371,        nan,        nan, 0.70629371,\n",
              "        0.70629371, 0.69230769,        nan,        nan, 0.70629371,\n",
              "               nan,        nan, 0.70629371,        nan, 0.70629371,\n",
              "               nan, 0.70629371, 0.70629371, 0.70629371,        nan,\n",
              "        0.69230769,        nan,        nan, 0.6993007 ,        nan,\n",
              "               nan, 0.70629371, 0.70629371,        nan, 0.69230769,\n",
              "               nan, 0.70629371,        nan, 0.69230769, 0.70629371,\n",
              "               nan, 0.69230769, 0.70629371,        nan, 0.70629371,\n",
              "        0.70629371, 0.69230769, 0.70629371, 0.70629371, 0.69230769,\n",
              "        0.6993007 ,        nan,        nan,        nan, 0.70629371,\n",
              "        0.70629371, 0.6993007 , 0.70629371, 0.70629371, 0.69230769,\n",
              "        0.70629371,        nan, 0.70629371, 0.69230769, 0.70629371]),\n",
              " 'split1_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.76223776,        nan, 0.76223776,        nan,        nan,\n",
              "               nan, 0.76223776,        nan,        nan, 0.76223776,\n",
              "        0.76223776, 0.76223776, 0.76223776,        nan,        nan,\n",
              "               nan, 0.76923077, 0.76223776,        nan,        nan,\n",
              "               nan, 0.76923077, 0.77622378, 0.76223776,        nan,\n",
              "        0.76223776, 0.76223776, 0.76223776, 0.76223776,        nan,\n",
              "               nan, 0.76223776,        nan,        nan,        nan,\n",
              "        0.76223776, 0.76223776,        nan, 0.76223776,        nan,\n",
              "               nan,        nan, 0.78321678,        nan,        nan,\n",
              "        0.76923077, 0.76223776,        nan, 0.76923077, 0.77622378,\n",
              "               nan,        nan, 0.76223776,        nan,        nan,\n",
              "        0.76923077, 0.76223776, 0.76223776,        nan, 0.76223776,\n",
              "        0.76923077, 0.76223776,        nan, 0.76223776,        nan,\n",
              "        0.76223776,        nan, 0.76223776,        nan,        nan,\n",
              "               nan,        nan, 0.76223776, 0.76223776, 0.76223776,\n",
              "        0.76223776, 0.76223776, 0.76223776, 0.76223776, 0.76923077,\n",
              "               nan,        nan,        nan, 0.76223776, 0.76223776,\n",
              "        0.76223776, 0.76223776,        nan, 0.76223776,        nan,\n",
              "               nan,        nan,        nan, 0.76923077, 0.76223776,\n",
              "        0.76923077,        nan, 0.76223776, 0.77622378,        nan,\n",
              "        0.76223776, 0.76223776, 0.76223776,        nan,        nan,\n",
              "        0.76223776, 0.76223776, 0.76223776, 0.76223776, 0.76223776,\n",
              "               nan, 0.76223776, 0.76223776, 0.77622378,        nan,\n",
              "               nan, 0.76223776,        nan, 0.76223776,        nan,\n",
              "        0.76223776, 0.76223776, 0.76223776, 0.76223776, 0.76923077,\n",
              "        0.76223776, 0.76223776,        nan,        nan,        nan,\n",
              "               nan, 0.76223776, 0.76223776,        nan, 0.76223776,\n",
              "               nan,        nan,        nan,        nan, 0.76223776,\n",
              "        0.76223776,        nan, 0.76223776,        nan, 0.78321678,\n",
              "               nan, 0.76223776, 0.76223776,        nan,        nan,\n",
              "               nan, 0.77622378, 0.76223776, 0.76223776,        nan,\n",
              "        0.76223776, 0.76223776, 0.76923077,        nan,        nan,\n",
              "        0.77622378, 0.77622378, 0.76923077, 0.76923077, 0.76223776,\n",
              "               nan, 0.76223776, 0.76223776,        nan, 0.76923077,\n",
              "        0.76223776,        nan, 0.76223776,        nan,        nan,\n",
              "               nan, 0.76223776,        nan, 0.76223776,        nan,\n",
              "        0.76223776, 0.76223776,        nan,        nan,        nan,\n",
              "        0.76223776, 0.76223776,        nan, 0.77622378, 0.76223776,\n",
              "               nan,        nan,        nan, 0.76923077,        nan,\n",
              "        0.76223776, 0.76923077,        nan, 0.76223776, 0.76223776,\n",
              "        0.76223776, 0.76223776,        nan,        nan,        nan,\n",
              "        0.77622378,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.76223776,        nan, 0.76223776,        nan,\n",
              "        0.76923077, 0.76923077, 0.76223776, 0.76223776,        nan,\n",
              "               nan, 0.76223776,        nan,        nan,        nan,\n",
              "        0.76223776, 0.76223776,        nan,        nan, 0.76223776,\n",
              "        0.76223776, 0.76223776,        nan,        nan,        nan,\n",
              "               nan, 0.76223776,        nan,        nan,        nan,\n",
              "        0.76223776, 0.76223776, 0.76923077, 0.76223776, 0.76223776,\n",
              "        0.76223776, 0.76223776,        nan,        nan,        nan,\n",
              "        0.76223776, 0.76223776,        nan,        nan, 0.76223776,\n",
              "        0.76223776,        nan, 0.76223776,        nan, 0.76923077,\n",
              "               nan,        nan, 0.76223776,        nan,        nan,\n",
              "               nan, 0.76223776,        nan, 0.76923077, 0.76223776,\n",
              "        0.76223776,        nan, 0.76223776, 0.77622378, 0.76223776,\n",
              "        0.76223776,        nan, 0.76223776, 0.76223776, 0.76223776,\n",
              "               nan, 0.76923077, 0.76223776,        nan, 0.76223776,\n",
              "               nan,        nan,        nan,        nan, 0.76223776,\n",
              "        0.76923077,        nan, 0.78321678, 0.76223776,        nan,\n",
              "        0.76223776, 0.76223776, 0.76223776, 0.76223776,        nan,\n",
              "               nan,        nan, 0.76223776, 0.76223776,        nan,\n",
              "        0.76223776,        nan, 0.76923077, 0.76223776,        nan,\n",
              "        0.76223776,        nan,        nan,        nan,        nan,\n",
              "        0.76223776,        nan, 0.76223776, 0.76223776,        nan,\n",
              "        0.76223776,        nan, 0.76223776,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.76223776,\n",
              "               nan,        nan,        nan,        nan, 0.76923077,\n",
              "        0.76923077,        nan, 0.76923077, 0.76223776,        nan,\n",
              "               nan, 0.76223776,        nan,        nan, 0.76223776,\n",
              "               nan,        nan, 0.76223776, 0.76223776, 0.76923077,\n",
              "        0.76223776, 0.76223776,        nan, 0.76223776,        nan,\n",
              "               nan,        nan, 0.77622378, 0.76923077,        nan,\n",
              "        0.76223776,        nan, 0.75524476,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.76223776, 0.76923077,\n",
              "               nan, 0.76923077, 0.76223776, 0.76223776,        nan,\n",
              "               nan, 0.76223776,        nan,        nan, 0.76223776,\n",
              "        0.76223776, 0.76223776,        nan,        nan,        nan,\n",
              "               nan, 0.76223776, 0.76223776,        nan, 0.76223776,\n",
              "        0.76223776,        nan, 0.76223776, 0.76223776, 0.76223776,\n",
              "               nan, 0.76923077,        nan,        nan, 0.76223776,\n",
              "        0.76923077, 0.76223776, 0.76223776,        nan,        nan,\n",
              "        0.76223776, 0.76223776, 0.76923077,        nan,        nan,\n",
              "               nan, 0.76923077, 0.76223776,        nan,        nan,\n",
              "        0.76223776,        nan, 0.76223776,        nan,        nan,\n",
              "        0.77622378, 0.76223776,        nan, 0.76223776, 0.76923077,\n",
              "        0.76223776,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.76223776,        nan,        nan, 0.76223776,\n",
              "        0.76223776, 0.77622378,        nan,        nan, 0.76223776,\n",
              "               nan,        nan, 0.76223776,        nan, 0.76223776,\n",
              "               nan, 0.76223776, 0.76223776, 0.76223776,        nan,\n",
              "        0.78321678,        nan,        nan, 0.76923077,        nan,\n",
              "               nan, 0.76223776, 0.76923077,        nan, 0.77622378,\n",
              "               nan, 0.76223776,        nan, 0.77622378, 0.76223776,\n",
              "               nan, 0.77622378, 0.76223776,        nan, 0.76223776,\n",
              "        0.76223776, 0.77622378, 0.76923077, 0.76223776, 0.78321678,\n",
              "        0.76223776,        nan,        nan,        nan, 0.76923077,\n",
              "        0.76223776, 0.76923077, 0.76223776, 0.76223776, 0.78321678,\n",
              "        0.76223776,        nan, 0.76223776, 0.78321678, 0.76923077]),\n",
              " 'split2_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.79577465,        nan, 0.79577465,        nan,        nan,\n",
              "               nan, 0.79577465,        nan,        nan, 0.79577465,\n",
              "        0.79577465, 0.79577465, 0.79577465,        nan,        nan,\n",
              "               nan, 0.78873239, 0.79577465,        nan,        nan,\n",
              "               nan, 0.78873239, 0.79577465, 0.79577465,        nan,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.79577465,        nan,\n",
              "               nan, 0.79577465,        nan,        nan,        nan,\n",
              "        0.79577465, 0.79577465,        nan, 0.79577465,        nan,\n",
              "               nan,        nan, 0.76760563,        nan,        nan,\n",
              "        0.78873239, 0.79577465,        nan, 0.78169014, 0.79577465,\n",
              "               nan,        nan, 0.79577465,        nan,        nan,\n",
              "        0.79577465, 0.79577465, 0.79577465,        nan, 0.79577465,\n",
              "        0.79577465, 0.79577465,        nan, 0.79577465,        nan,\n",
              "        0.79577465,        nan, 0.79577465,        nan,        nan,\n",
              "               nan,        nan, 0.79577465, 0.79577465, 0.79577465,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.79577465, 0.79577465,\n",
              "               nan,        nan,        nan, 0.79577465, 0.79577465,\n",
              "        0.79577465, 0.79577465,        nan, 0.79577465,        nan,\n",
              "               nan,        nan,        nan, 0.78873239, 0.79577465,\n",
              "        0.79577465,        nan, 0.79577465, 0.79577465,        nan,\n",
              "        0.79577465, 0.79577465, 0.79577465,        nan,        nan,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.79577465, 0.79577465,\n",
              "               nan, 0.79577465, 0.79577465, 0.79577465,        nan,\n",
              "               nan, 0.79577465,        nan, 0.79577465,        nan,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.79577465, 0.78873239,\n",
              "        0.79577465, 0.79577465,        nan,        nan,        nan,\n",
              "               nan, 0.79577465, 0.79577465,        nan, 0.79577465,\n",
              "               nan,        nan,        nan,        nan, 0.79577465,\n",
              "        0.79577465,        nan, 0.79577465,        nan, 0.76760563,\n",
              "               nan, 0.79577465, 0.79577465,        nan,        nan,\n",
              "               nan, 0.79577465, 0.79577465, 0.79577465,        nan,\n",
              "        0.79577465, 0.79577465, 0.78169014,        nan,        nan,\n",
              "        0.79577465, 0.79577465, 0.78169014, 0.76760563, 0.79577465,\n",
              "               nan, 0.79577465, 0.79577465,        nan, 0.78873239,\n",
              "        0.79577465,        nan, 0.79577465,        nan,        nan,\n",
              "               nan, 0.79577465,        nan, 0.79577465,        nan,\n",
              "        0.79577465, 0.79577465,        nan,        nan,        nan,\n",
              "        0.79577465, 0.79577465,        nan, 0.79577465, 0.79577465,\n",
              "               nan,        nan,        nan, 0.79577465,        nan,\n",
              "        0.79577465, 0.79577465,        nan, 0.79577465, 0.79577465,\n",
              "        0.78873239, 0.79577465,        nan,        nan,        nan,\n",
              "        0.79577465,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.79577465,        nan, 0.79577465,        nan,\n",
              "        0.79577465, 0.78873239, 0.79577465, 0.79577465,        nan,\n",
              "               nan, 0.79577465,        nan,        nan,        nan,\n",
              "        0.79577465, 0.79577465,        nan,        nan, 0.79577465,\n",
              "        0.79577465, 0.79577465,        nan,        nan,        nan,\n",
              "               nan, 0.79577465,        nan,        nan,        nan,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.79577465, 0.79577465,\n",
              "        0.78873239, 0.79577465,        nan,        nan,        nan,\n",
              "        0.79577465, 0.79577465,        nan,        nan, 0.79577465,\n",
              "        0.79577465,        nan, 0.79577465,        nan, 0.78169014,\n",
              "               nan,        nan, 0.79577465,        nan,        nan,\n",
              "               nan, 0.79577465,        nan, 0.79577465, 0.79577465,\n",
              "        0.79577465,        nan, 0.79577465, 0.79577465, 0.79577465,\n",
              "        0.79577465,        nan, 0.79577465, 0.79577465, 0.79577465,\n",
              "               nan, 0.78169014, 0.79577465,        nan, 0.79577465,\n",
              "               nan,        nan,        nan,        nan, 0.79577465,\n",
              "        0.79577465,        nan, 0.76760563, 0.79577465,        nan,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.79577465,        nan,\n",
              "               nan,        nan, 0.79577465, 0.79577465,        nan,\n",
              "        0.79577465,        nan, 0.79577465, 0.79577465,        nan,\n",
              "        0.79577465,        nan,        nan,        nan,        nan,\n",
              "        0.79577465,        nan, 0.79577465, 0.79577465,        nan,\n",
              "        0.79577465,        nan, 0.79577465,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.79577465,\n",
              "               nan,        nan,        nan,        nan, 0.79577465,\n",
              "        0.78169014,        nan, 0.79577465, 0.79577465,        nan,\n",
              "               nan, 0.79577465,        nan,        nan, 0.79577465,\n",
              "               nan,        nan, 0.79577465, 0.79577465, 0.78169014,\n",
              "        0.79577465, 0.79577465,        nan, 0.79577465,        nan,\n",
              "               nan,        nan, 0.79577465, 0.79577465,        nan,\n",
              "        0.79577465,        nan, 0.76760563,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.79577465, 0.78873239,\n",
              "               nan, 0.79577465, 0.79577465, 0.79577465,        nan,\n",
              "               nan, 0.79577465,        nan,        nan, 0.79577465,\n",
              "        0.79577465, 0.79577465,        nan,        nan,        nan,\n",
              "               nan, 0.79577465, 0.79577465,        nan, 0.79577465,\n",
              "        0.79577465,        nan, 0.79577465, 0.79577465, 0.79577465,\n",
              "               nan, 0.79577465,        nan,        nan, 0.79577465,\n",
              "        0.79577465, 0.79577465, 0.79577465,        nan,        nan,\n",
              "        0.79577465, 0.79577465, 0.79577465,        nan,        nan,\n",
              "               nan, 0.78169014, 0.79577465,        nan,        nan,\n",
              "        0.79577465,        nan, 0.79577465,        nan,        nan,\n",
              "        0.79577465, 0.79577465,        nan, 0.79577465, 0.79577465,\n",
              "        0.79577465,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.79577465,        nan,        nan, 0.79577465,\n",
              "        0.79577465, 0.79577465,        nan,        nan, 0.79577465,\n",
              "               nan,        nan, 0.79577465,        nan, 0.79577465,\n",
              "               nan, 0.79577465, 0.79577465, 0.79577465,        nan,\n",
              "        0.76760563,        nan,        nan, 0.79577465,        nan,\n",
              "               nan, 0.79577465, 0.79577465,        nan, 0.79577465,\n",
              "               nan, 0.79577465,        nan, 0.79577465, 0.79577465,\n",
              "               nan, 0.79577465, 0.79577465,        nan, 0.79577465,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.79577465, 0.76760563,\n",
              "        0.79577465,        nan,        nan,        nan, 0.79577465,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.79577465, 0.76760563,\n",
              "        0.78169014,        nan, 0.79577465, 0.76760563, 0.79577465]),\n",
              " 'split3_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.78169014,        nan, 0.78169014,        nan,        nan,\n",
              "               nan, 0.78169014,        nan,        nan, 0.78169014,\n",
              "        0.78169014, 0.78169014, 0.78169014,        nan,        nan,\n",
              "               nan, 0.78169014, 0.78169014,        nan,        nan,\n",
              "               nan, 0.78169014, 0.77464789, 0.78169014,        nan,\n",
              "        0.78169014, 0.78169014, 0.78169014, 0.78169014,        nan,\n",
              "               nan, 0.78169014,        nan,        nan,        nan,\n",
              "        0.78169014, 0.78169014,        nan, 0.78169014,        nan,\n",
              "               nan,        nan, 0.78169014,        nan,        nan,\n",
              "        0.78169014, 0.78169014,        nan, 0.78169014, 0.77464789,\n",
              "               nan,        nan, 0.78169014,        nan,        nan,\n",
              "        0.78169014, 0.78169014, 0.78169014,        nan, 0.78169014,\n",
              "        0.78169014, 0.78169014,        nan, 0.78169014,        nan,\n",
              "        0.78169014,        nan, 0.78169014,        nan,        nan,\n",
              "               nan,        nan, 0.78169014, 0.78169014, 0.78169014,\n",
              "        0.78169014, 0.78169014, 0.78169014, 0.78169014, 0.78169014,\n",
              "               nan,        nan,        nan, 0.78169014, 0.78169014,\n",
              "        0.78169014, 0.78169014,        nan, 0.78169014,        nan,\n",
              "               nan,        nan,        nan, 0.78169014, 0.78169014,\n",
              "        0.78169014,        nan, 0.78169014, 0.77464789,        nan,\n",
              "        0.78169014, 0.78169014, 0.78169014,        nan,        nan,\n",
              "        0.78169014, 0.78169014, 0.78169014, 0.78169014, 0.78169014,\n",
              "               nan, 0.78169014, 0.78169014, 0.77464789,        nan,\n",
              "               nan, 0.78169014,        nan, 0.78169014,        nan,\n",
              "        0.78169014, 0.78169014, 0.78169014, 0.78169014, 0.78169014,\n",
              "        0.78169014, 0.78169014,        nan,        nan,        nan,\n",
              "               nan, 0.78169014, 0.78169014,        nan, 0.78169014,\n",
              "               nan,        nan,        nan,        nan, 0.78169014,\n",
              "        0.78169014,        nan, 0.78169014,        nan, 0.78169014,\n",
              "               nan, 0.78169014, 0.78169014,        nan,        nan,\n",
              "               nan, 0.77464789, 0.78169014, 0.78169014,        nan,\n",
              "        0.78169014, 0.78169014, 0.78873239,        nan,        nan,\n",
              "        0.77464789, 0.78169014, 0.78873239, 0.78169014, 0.78169014,\n",
              "               nan, 0.78169014, 0.78169014,        nan, 0.78169014,\n",
              "        0.78169014,        nan, 0.78169014,        nan,        nan,\n",
              "               nan, 0.78169014,        nan, 0.78169014,        nan,\n",
              "        0.78169014, 0.78169014,        nan,        nan,        nan,\n",
              "        0.78169014, 0.78169014,        nan, 0.77464789, 0.78169014,\n",
              "               nan,        nan,        nan, 0.78169014,        nan,\n",
              "        0.78169014, 0.78169014,        nan, 0.78169014, 0.78169014,\n",
              "        0.78169014, 0.78169014,        nan,        nan,        nan,\n",
              "        0.78169014,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.78169014,        nan, 0.78169014,        nan,\n",
              "        0.78169014, 0.78169014, 0.78169014, 0.78169014,        nan,\n",
              "               nan, 0.78169014,        nan,        nan,        nan,\n",
              "        0.78169014, 0.78169014,        nan,        nan, 0.78169014,\n",
              "        0.78169014, 0.78169014,        nan,        nan,        nan,\n",
              "               nan, 0.78169014,        nan,        nan,        nan,\n",
              "        0.78169014, 0.78169014, 0.78169014, 0.78169014, 0.78169014,\n",
              "        0.78169014, 0.78169014,        nan,        nan,        nan,\n",
              "        0.78169014, 0.78169014,        nan,        nan, 0.78169014,\n",
              "        0.78169014,        nan, 0.78169014,        nan, 0.78873239,\n",
              "               nan,        nan, 0.78169014,        nan,        nan,\n",
              "               nan, 0.78169014,        nan, 0.78169014, 0.78169014,\n",
              "        0.78169014,        nan, 0.78169014, 0.77464789, 0.78169014,\n",
              "        0.78169014,        nan, 0.78169014, 0.78169014, 0.78169014,\n",
              "               nan, 0.78169014, 0.78169014,        nan, 0.78169014,\n",
              "               nan,        nan,        nan,        nan, 0.78169014,\n",
              "        0.78169014,        nan, 0.78169014, 0.78169014,        nan,\n",
              "        0.78169014, 0.78169014, 0.78169014, 0.78169014,        nan,\n",
              "               nan,        nan, 0.78169014, 0.78169014,        nan,\n",
              "        0.78169014,        nan, 0.78169014, 0.78169014,        nan,\n",
              "        0.78169014,        nan,        nan,        nan,        nan,\n",
              "        0.78169014,        nan, 0.78169014, 0.78169014,        nan,\n",
              "        0.78169014,        nan, 0.78169014,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.78169014,\n",
              "               nan,        nan,        nan,        nan, 0.78169014,\n",
              "        0.78169014,        nan, 0.78169014, 0.78169014,        nan,\n",
              "               nan, 0.78169014,        nan,        nan, 0.78169014,\n",
              "               nan,        nan, 0.78169014, 0.78169014, 0.78169014,\n",
              "        0.78169014, 0.78169014,        nan, 0.78169014,        nan,\n",
              "               nan,        nan, 0.78169014, 0.78169014,        nan,\n",
              "        0.78169014,        nan, 0.78873239,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.78169014, 0.78169014,\n",
              "               nan, 0.78169014, 0.78169014, 0.78169014,        nan,\n",
              "               nan, 0.78169014,        nan,        nan, 0.78169014,\n",
              "        0.78169014, 0.78169014,        nan,        nan,        nan,\n",
              "               nan, 0.78169014, 0.78169014,        nan, 0.78169014,\n",
              "        0.78169014,        nan, 0.78169014, 0.78169014, 0.78169014,\n",
              "               nan, 0.78873239,        nan,        nan, 0.78169014,\n",
              "        0.78169014, 0.78169014, 0.78169014,        nan,        nan,\n",
              "        0.78169014, 0.78169014, 0.78169014,        nan,        nan,\n",
              "               nan, 0.78873239, 0.78169014,        nan,        nan,\n",
              "        0.78169014,        nan, 0.78169014,        nan,        nan,\n",
              "        0.77464789, 0.78169014,        nan, 0.78169014, 0.78169014,\n",
              "        0.78169014,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.78169014,        nan,        nan, 0.78169014,\n",
              "        0.78169014, 0.77464789,        nan,        nan, 0.78169014,\n",
              "               nan,        nan, 0.78169014,        nan, 0.78169014,\n",
              "               nan, 0.78169014, 0.78169014, 0.78169014,        nan,\n",
              "        0.78169014,        nan,        nan, 0.78169014,        nan,\n",
              "               nan, 0.78169014, 0.78169014,        nan, 0.77464789,\n",
              "               nan, 0.78169014,        nan, 0.78169014, 0.78169014,\n",
              "               nan, 0.77464789, 0.78169014,        nan, 0.78169014,\n",
              "        0.78169014, 0.77464789, 0.78169014, 0.78169014, 0.78169014,\n",
              "        0.78169014,        nan,        nan,        nan, 0.78169014,\n",
              "        0.78169014, 0.78169014, 0.78169014, 0.78169014, 0.78169014,\n",
              "        0.78873239,        nan, 0.78169014, 0.78169014, 0.78169014]),\n",
              " 'split4_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.78873239,        nan, 0.79577465,        nan,        nan,\n",
              "               nan, 0.79577465,        nan,        nan, 0.79577465,\n",
              "        0.79577465, 0.79577465, 0.79577465,        nan,        nan,\n",
              "               nan, 0.78873239, 0.79577465,        nan,        nan,\n",
              "               nan, 0.78169014, 0.78873239, 0.79577465,        nan,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.79577465,        nan,\n",
              "               nan, 0.79577465,        nan,        nan,        nan,\n",
              "        0.79577465, 0.79577465,        nan, 0.79577465,        nan,\n",
              "               nan,        nan, 0.77464789,        nan,        nan,\n",
              "        0.78169014, 0.79577465,        nan, 0.78169014, 0.78873239,\n",
              "               nan,        nan, 0.79577465,        nan,        nan,\n",
              "        0.78873239, 0.79577465, 0.79577465,        nan, 0.78873239,\n",
              "        0.78873239, 0.79577465,        nan, 0.79577465,        nan,\n",
              "        0.79577465,        nan, 0.79577465,        nan,        nan,\n",
              "               nan,        nan, 0.79577465, 0.79577465, 0.78873239,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.78873239, 0.78873239,\n",
              "               nan,        nan,        nan, 0.79577465, 0.79577465,\n",
              "        0.79577465, 0.79577465,        nan, 0.79577465,        nan,\n",
              "               nan,        nan,        nan, 0.78169014, 0.79577465,\n",
              "        0.78873239,        nan, 0.79577465, 0.78873239,        nan,\n",
              "        0.79577465, 0.79577465, 0.78873239,        nan,        nan,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.79577465, 0.79577465,\n",
              "               nan, 0.79577465, 0.79577465, 0.78169014,        nan,\n",
              "               nan, 0.78873239,        nan, 0.79577465,        nan,\n",
              "        0.78873239, 0.79577465, 0.79577465, 0.79577465, 0.78169014,\n",
              "        0.79577465, 0.79577465,        nan,        nan,        nan,\n",
              "               nan, 0.79577465, 0.79577465,        nan, 0.79577465,\n",
              "               nan,        nan,        nan,        nan, 0.79577465,\n",
              "        0.79577465,        nan, 0.79577465,        nan, 0.77464789,\n",
              "               nan, 0.79577465, 0.79577465,        nan,        nan,\n",
              "               nan, 0.78169014, 0.79577465, 0.79577465,        nan,\n",
              "        0.79577465, 0.79577465, 0.78169014,        nan,        nan,\n",
              "        0.78169014, 0.78873239, 0.78169014, 0.78169014, 0.79577465,\n",
              "               nan, 0.79577465, 0.79577465,        nan, 0.78169014,\n",
              "        0.79577465,        nan, 0.79577465,        nan,        nan,\n",
              "               nan, 0.79577465,        nan, 0.79577465,        nan,\n",
              "        0.79577465, 0.79577465,        nan,        nan,        nan,\n",
              "        0.79577465, 0.79577465,        nan, 0.78873239, 0.79577465,\n",
              "               nan,        nan,        nan, 0.78873239,        nan,\n",
              "        0.79577465, 0.78873239,        nan, 0.79577465, 0.79577465,\n",
              "        0.78873239, 0.79577465,        nan,        nan,        nan,\n",
              "        0.78873239,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.79577465,        nan, 0.79577465,        nan,\n",
              "        0.79577465, 0.78169014, 0.79577465, 0.79577465,        nan,\n",
              "               nan, 0.79577465,        nan,        nan,        nan,\n",
              "        0.79577465, 0.79577465,        nan,        nan, 0.79577465,\n",
              "        0.79577465, 0.79577465,        nan,        nan,        nan,\n",
              "               nan, 0.79577465,        nan,        nan,        nan,\n",
              "        0.79577465, 0.79577465, 0.78873239, 0.79577465, 0.79577465,\n",
              "        0.78873239, 0.79577465,        nan,        nan,        nan,\n",
              "        0.79577465, 0.79577465,        nan,        nan, 0.79577465,\n",
              "        0.79577465,        nan, 0.79577465,        nan, 0.78169014,\n",
              "               nan,        nan, 0.79577465,        nan,        nan,\n",
              "               nan, 0.79577465,        nan, 0.78873239, 0.79577465,\n",
              "        0.79577465,        nan, 0.79577465, 0.78169014, 0.79577465,\n",
              "        0.79577465,        nan, 0.79577465, 0.79577465, 0.79577465,\n",
              "               nan, 0.78169014, 0.79577465,        nan, 0.79577465,\n",
              "               nan,        nan,        nan,        nan, 0.79577465,\n",
              "        0.78873239,        nan, 0.77464789, 0.79577465,        nan,\n",
              "        0.79577465, 0.79577465, 0.79577465, 0.79577465,        nan,\n",
              "               nan,        nan, 0.78873239, 0.79577465,        nan,\n",
              "        0.79577465,        nan, 0.78873239, 0.79577465,        nan,\n",
              "        0.78873239,        nan,        nan,        nan,        nan,\n",
              "        0.79577465,        nan, 0.79577465, 0.79577465,        nan,\n",
              "        0.79577465,        nan, 0.79577465,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.79577465,\n",
              "               nan,        nan,        nan,        nan, 0.78873239,\n",
              "        0.78169014,        nan, 0.78873239, 0.79577465,        nan,\n",
              "               nan, 0.79577465,        nan,        nan, 0.79577465,\n",
              "               nan,        nan, 0.79577465, 0.79577465, 0.78169014,\n",
              "        0.79577465, 0.79577465,        nan, 0.79577465,        nan,\n",
              "               nan,        nan, 0.78873239, 0.78873239,        nan,\n",
              "        0.79577465,        nan, 0.75352113,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.79577465, 0.78169014,\n",
              "               nan, 0.78873239, 0.79577465, 0.79577465,        nan,\n",
              "               nan, 0.79577465,        nan,        nan, 0.79577465,\n",
              "        0.79577465, 0.79577465,        nan,        nan,        nan,\n",
              "               nan, 0.78873239, 0.78873239,        nan, 0.79577465,\n",
              "        0.78873239,        nan, 0.79577465, 0.79577465, 0.78873239,\n",
              "               nan, 0.78873239,        nan,        nan, 0.79577465,\n",
              "        0.78873239, 0.79577465, 0.79577465,        nan,        nan,\n",
              "        0.79577465, 0.79577465, 0.78873239,        nan,        nan,\n",
              "               nan, 0.78169014, 0.79577465,        nan,        nan,\n",
              "        0.79577465,        nan, 0.79577465,        nan,        nan,\n",
              "        0.78873239, 0.79577465,        nan, 0.79577465, 0.78873239,\n",
              "        0.79577465,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.79577465,        nan,        nan, 0.79577465,\n",
              "        0.79577465, 0.78873239,        nan,        nan, 0.79577465,\n",
              "               nan,        nan, 0.79577465,        nan, 0.79577465,\n",
              "               nan, 0.79577465, 0.79577465, 0.79577465,        nan,\n",
              "        0.77464789,        nan,        nan, 0.78873239,        nan,\n",
              "               nan, 0.79577465, 0.78873239,        nan, 0.78169014,\n",
              "               nan, 0.79577465,        nan, 0.78873239, 0.79577465,\n",
              "               nan, 0.78169014, 0.79577465,        nan, 0.79577465,\n",
              "        0.79577465, 0.78169014, 0.78873239, 0.79577465, 0.77464789,\n",
              "        0.78873239,        nan,        nan,        nan, 0.78873239,\n",
              "        0.79577465, 0.78873239, 0.79577465, 0.79577465, 0.77464789,\n",
              "        0.78169014,        nan, 0.79577465, 0.77464789, 0.78873239]),\n",
              " 'std_fit_time': array([1.63313323e-04, 2.00306338e-03, 2.32080647e-04, 1.14054464e-04,\n",
              "        1.63512085e-04, 5.52177841e-05, 4.19535586e-04, 1.77633292e-03,\n",
              "        1.91612751e-04, 8.47216473e-04, 1.05841628e-03, 4.14632873e-05,\n",
              "        3.56358209e-03, 9.30545485e-05, 8.45226649e-06, 1.62674420e-04,\n",
              "        4.27273899e-03, 7.53382489e-05, 2.08503066e-04, 4.98154595e-03,\n",
              "        2.03303950e-03, 4.61360583e-03, 8.44746425e-04, 1.99400073e-04,\n",
              "        7.55567398e-05, 2.67201365e-03, 3.62628745e-03, 6.92839527e-04,\n",
              "        8.57139164e-05, 4.27933124e-06, 3.53898632e-05, 6.29465369e-04,\n",
              "        5.95877175e-03, 3.46160348e-04, 1.13652354e-04, 1.48253001e-03,\n",
              "        1.58565866e-03, 6.12027550e-03, 2.36454066e-03, 1.42910523e-04,\n",
              "        4.37929178e-05, 2.11128266e-04, 1.32165068e-04, 6.42305847e-05,\n",
              "        5.12701955e-03, 6.87364046e-03, 2.05989156e-03, 1.62175325e-04,\n",
              "        1.34009881e-03, 9.63892318e-05, 1.88505158e-04, 4.63140673e-03,\n",
              "        2.52309439e-03, 1.62640970e-04, 7.13985268e-05, 3.96379629e-04,\n",
              "        3.44727407e-03, 1.76392458e-03, 1.81631643e-03, 7.10844904e-03,\n",
              "        9.42231431e-05, 2.93363768e-05, 4.04100218e-04, 9.09318084e-05,\n",
              "        1.53618210e-04, 2.05373030e-03, 1.59257360e-03, 2.45719930e-03,\n",
              "        1.07290861e-04, 2.94067853e-04, 6.52781665e-04, 1.08197354e-03,\n",
              "        2.96721055e-04, 7.44179436e-04, 9.21883720e-05, 3.79527351e-03,\n",
              "        1.59363758e-04, 8.01284757e-04, 7.80517614e-05, 5.50865598e-06,\n",
              "        5.25505269e-05, 2.37747325e-04, 6.18691327e-03, 8.87555663e-03,\n",
              "        3.03766356e-04, 1.82265985e-03, 9.17284111e-03, 6.36653978e-04,\n",
              "        2.66484202e-03, 3.25838368e-03, 1.34165793e-04, 3.31415204e-05,\n",
              "        4.17736566e-05, 4.00643128e-03, 5.72328900e-04, 4.12755190e-03,\n",
              "        9.55078201e-03, 1.52373954e-04, 4.53148831e-04, 1.21135091e-04,\n",
              "        8.09558562e-05, 1.30669965e-04, 1.56880281e-03, 3.73463808e-03,\n",
              "        6.73053894e-04, 7.77943224e-04, 1.50054722e-04, 1.38797486e-03,\n",
              "        3.03583019e-03, 1.08004027e-04, 8.14831846e-04, 2.38373734e-03,\n",
              "        5.21451627e-04, 1.66383948e-04, 4.12582584e-03, 2.27258414e-03,\n",
              "        5.60674085e-03, 1.22687899e-03, 1.24898850e-03, 8.14802775e-03,\n",
              "        1.42358166e-04, 8.99353420e-03, 2.86781001e-03, 1.57824294e-03,\n",
              "        2.34006416e-04, 5.17374689e-05, 2.68933579e-04, 8.38223663e-04,\n",
              "        6.49674713e-04, 6.43925107e-05, 4.36873744e-04, 4.07499355e-04,\n",
              "        3.48272251e-03, 5.27323666e-03, 4.31020553e-04, 4.65435635e-03,\n",
              "        1.15533288e-03, 1.26082327e-04, 3.36261831e-05, 3.75451659e-05,\n",
              "        1.20331309e-04, 3.94330244e-03, 7.15621623e-04, 1.72772718e-04,\n",
              "        8.15906928e-04, 1.44628302e-04, 5.31927326e-04, 2.82887206e-03,\n",
              "        8.42145014e-04, 1.81583887e-03, 1.08354347e-03, 1.20659080e-04,\n",
              "        1.44134878e-02, 1.30231605e-04, 1.39021095e-03, 1.27221673e-04,\n",
              "        6.11556738e-03, 4.75402086e-03, 1.36109857e-04, 1.58793357e-03,\n",
              "        2.91572202e-04, 1.03357352e-03, 1.66264929e-03, 4.92895093e-03,\n",
              "        8.23468068e-04, 6.69585887e-03, 7.09285141e-04, 5.24355745e-04,\n",
              "        3.72481229e-04, 3.32977815e-05, 5.54382405e-04, 1.33009627e-03,\n",
              "        2.33379061e-04, 1.14609634e-04, 1.00554899e-03, 8.38528142e-05,\n",
              "        8.09309962e-05, 1.01381493e-03, 4.22291564e-03, 7.35495385e-03,\n",
              "        1.39774458e-03, 1.07174856e-04, 5.86968723e-03, 8.82659455e-05,\n",
              "        1.38252140e-04, 2.77657989e-03, 1.24633224e-03, 1.10904922e-04,\n",
              "        9.93616897e-04, 1.92550564e-04, 3.04646935e-03, 1.09521924e-02,\n",
              "        8.32520809e-05, 1.16826077e-05, 7.59323911e-05, 2.48965201e-03,\n",
              "        3.24134193e-03, 1.29475997e-04, 3.78113570e-03, 9.09126934e-04,\n",
              "        8.57663443e-05, 1.13231005e-04, 3.54818115e-05, 1.05353740e-03,\n",
              "        2.17701484e-03, 3.97882589e-03, 1.85159773e-03, 8.28197100e-05,\n",
              "        1.09460696e-03, 3.12546028e-04, 3.29973746e-04, 1.95902521e-04,\n",
              "        3.47450398e-05, 4.93151988e-06, 1.07932109e-04, 1.39224184e-03,\n",
              "        1.02750231e-04, 4.45803643e-03, 4.56964529e-03, 1.48239953e-04,\n",
              "        1.31840085e-05, 6.65312988e-04, 4.42214472e-05, 8.25264202e-03,\n",
              "        1.14116348e-04, 1.41170618e-04, 2.72622111e-04, 3.87892085e-03,\n",
              "        8.44306065e-03, 1.46998974e-04, 2.91533165e-03, 2.14580796e-03,\n",
              "        7.35003298e-05, 2.63754318e-05, 5.19770001e-05, 5.69985230e-04,\n",
              "        2.41768447e-03, 6.49173336e-04, 3.61421353e-04, 6.54253771e-04,\n",
              "        1.00716609e-04, 4.18550442e-03, 2.06216443e-03, 6.69946195e-05,\n",
              "        3.37948055e-05, 1.01216659e-04, 2.69759331e-03, 8.82373730e-05,\n",
              "        1.57605710e-04, 2.86933729e-03, 1.41351633e-03, 4.77075222e-03,\n",
              "        1.48006081e-03, 1.23953605e-03, 6.13143670e-04, 2.98006657e-03,\n",
              "        2.98731479e-03, 1.09516468e-04, 3.14102883e-05, 8.98635776e-05,\n",
              "        3.80711475e-04, 5.32082261e-03, 1.53446168e-04, 7.45916597e-05,\n",
              "        6.28094969e-03, 4.19899858e-03, 1.14147027e-04, 1.72522226e-03,\n",
              "        2.86516913e-03, 7.89641505e-04, 5.66612977e-05, 2.16684029e-04,\n",
              "        1.09492875e-02, 1.35123115e-04, 1.24352567e-04, 1.42097665e-04,\n",
              "        3.61174082e-03, 1.10638696e-04, 7.49487571e-03, 2.04405472e-03,\n",
              "        4.66957484e-03, 1.14596123e-04, 4.04534309e-03, 3.42269029e-04,\n",
              "        6.44868486e-03, 9.12556592e-04, 1.35315817e-04, 1.05855901e-03,\n",
              "        1.12590217e-03, 4.48129527e-03, 1.25272355e-04, 5.81103284e-04,\n",
              "        6.39756145e-03, 2.72199923e-03, 2.24530872e-03, 6.24927069e-05,\n",
              "        8.86127731e-04, 3.12446616e-05, 7.60118515e-05, 1.07034776e-02,\n",
              "        4.69804640e-03, 1.46708575e-04, 5.78200527e-03, 2.92720564e-04,\n",
              "        1.02629093e-04, 2.24769031e-03, 5.43838857e-03, 2.89393793e-03,\n",
              "        1.08794097e-03, 1.06718500e-04, 5.83870696e-05, 5.82042991e-05,\n",
              "        5.51192619e-04, 6.88718656e-04, 1.23172585e-04, 5.97709316e-03,\n",
              "        9.55349405e-05, 1.80874310e-03, 2.90809047e-03, 1.24185956e-04,\n",
              "        2.68118044e-03, 7.03436472e-05, 5.64271049e-05, 4.90691617e-05,\n",
              "        5.07679545e-05, 4.19606539e-04, 8.37969099e-05, 2.21230345e-04,\n",
              "        4.51776713e-04, 6.37723306e-05, 7.96947828e-03, 1.47355983e-04,\n",
              "        3.27855339e-03, 7.45134006e-05, 3.23418647e-05, 1.03926371e-04,\n",
              "        1.09117597e-05, 6.16644663e-05, 8.81329491e-05, 3.78191754e-03,\n",
              "        1.73384810e-04, 2.37957509e-05, 3.96831664e-05, 3.00031002e-05,\n",
              "        4.89519488e-03, 1.56647927e-03, 1.07114220e-03, 1.41700945e-03,\n",
              "        7.94101611e-04, 1.30930436e-04, 9.64507798e-05, 1.96721326e-03,\n",
              "        4.02142522e-04, 4.51008304e-05, 2.98599819e-03, 1.72146839e-04,\n",
              "        8.54669919e-06, 5.39375390e-03, 5.05260091e-04, 5.38262000e-04,\n",
              "        4.84433150e-04, 6.63049859e-03, 1.30694411e-04, 1.23645781e-03,\n",
              "        1.13755638e-04, 2.85080053e-04, 2.49465598e-05, 2.33348018e-04,\n",
              "        6.23814645e-04, 2.58680770e-04, 6.80844573e-03, 2.25621113e-04,\n",
              "        1.41921543e-04, 8.66549176e-05, 1.59315683e-04, 2.27423832e-05,\n",
              "        1.17163596e-04, 1.41010028e-05, 8.43853856e-03, 1.99324901e-03,\n",
              "        1.69312420e-04, 8.22144544e-04, 9.49676935e-03, 2.30442933e-03,\n",
              "        9.73428927e-05, 2.05372386e-05, 3.62205380e-03, 1.12625727e-04,\n",
              "        3.06585899e-05, 2.69871308e-03, 6.94735235e-04, 1.73272700e-03,\n",
              "        1.16708522e-04, 8.22450245e-05, 3.11259633e-05, 2.52276150e-05,\n",
              "        6.82125475e-03, 4.76209810e-04, 9.55845507e-05, 6.54581574e-04,\n",
              "        3.43033099e-04, 6.98326350e-05, 2.98904098e-03, 5.57871841e-03,\n",
              "        3.86972101e-04, 9.92469392e-05, 9.75513267e-05, 8.41812214e-05,\n",
              "        1.20162264e-04, 8.35837021e-03, 2.72756934e-03, 2.64771019e-04,\n",
              "        1.24527568e-03, 1.32795390e-04, 4.50941247e-05, 3.01797293e-04,\n",
              "        1.33606568e-03, 7.33673946e-04, 8.64644757e-05, 1.01904396e-04,\n",
              "        7.56185258e-05, 8.38284084e-03, 5.99738589e-03, 4.21200208e-04,\n",
              "        1.90501225e-04, 2.99913083e-04, 1.66663011e-04, 2.33549096e-03,\n",
              "        1.67192531e-04, 5.46042884e-05, 3.25050640e-04, 6.29818650e-03,\n",
              "        1.18315359e-04, 5.95139594e-03, 5.79757980e-03, 1.46780251e-03,\n",
              "        5.39520542e-05, 3.62974884e-05, 2.01666606e-05, 5.00228316e-05,\n",
              "        1.36064512e-04, 3.98671902e-03, 6.92394810e-05, 4.33591570e-05,\n",
              "        2.93406515e-03, 7.39926541e-04, 3.37115740e-03, 1.62523956e-04,\n",
              "        3.05583800e-05, 6.11746362e-03, 1.65823342e-04, 7.76909540e-05,\n",
              "        1.48689601e-04, 2.25532251e-04, 5.79838698e-03, 1.03062657e-04,\n",
              "        9.12977961e-04, 4.43251300e-03, 5.36441201e-04, 2.48667556e-04,\n",
              "        2.88718878e-03, 7.82360895e-05, 2.78100187e-04, 2.87808536e-04,\n",
              "        6.50140143e-05, 5.64174333e-05, 5.71836475e-03, 1.26596302e-03,\n",
              "        9.94889164e-05, 4.13556098e-04, 9.50688217e-05, 2.56569570e-03,\n",
              "        1.31344326e-04, 3.74201287e-03, 2.27659586e-03, 1.33005655e-04,\n",
              "        5.39261283e-04, 3.57235190e-03, 3.14830570e-04, 3.67848054e-03,\n",
              "        2.02938248e-03, 4.29507465e-04, 1.21446714e-03, 7.27325065e-04,\n",
              "        1.03230759e-03, 2.20980892e-03, 1.50480575e-04, 1.00342492e-04,\n",
              "        1.09482538e-04, 9.49865261e-04, 2.75671063e-04, 2.19217398e-04,\n",
              "        5.47899868e-04, 7.63877902e-04, 9.04784914e-04, 4.67635672e-04,\n",
              "        1.80409244e-03, 3.36409423e-04, 2.32088307e-03, 3.97541044e-03]),\n",
              " 'std_score_time': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.72964711e-04, 0.00000000e+00,\n",
              "        8.24813339e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.01089253e-04, 0.00000000e+00, 0.00000000e+00, 6.11972519e-05,\n",
              "        6.58172441e-05, 1.00906066e-04, 6.59041741e-05, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.08938142e-04, 9.87914764e-05,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.96520217e-03,\n",
              "        7.92010682e-04, 1.27177217e-04, 0.00000000e+00, 2.37617051e-04,\n",
              "        9.06433449e-05, 5.27577146e-03, 6.57083334e-05, 0.00000000e+00,\n",
              "        0.00000000e+00, 6.21632543e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.03840824e-03, 1.76838620e-04, 0.00000000e+00,\n",
              "        2.64379196e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.27693289e-03, 0.00000000e+00, 0.00000000e+00, 2.96420234e-04,\n",
              "        2.92183294e-03, 0.00000000e+00, 1.68892625e-04, 2.37204532e-04,\n",
              "        0.00000000e+00, 0.00000000e+00, 4.90747682e-05, 0.00000000e+00,\n",
              "        0.00000000e+00, 8.68821641e-05, 8.99758235e-05, 5.73103120e-05,\n",
              "        0.00000000e+00, 2.23259898e-03, 2.58823502e-04, 3.39687192e-04,\n",
              "        0.00000000e+00, 1.58207383e-04, 0.00000000e+00, 9.75775215e-05,\n",
              "        0.00000000e+00, 2.98590416e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 8.20401899e-05, 3.15768407e-04,\n",
              "        8.07444004e-05, 2.22537792e-04, 9.63613131e-04, 1.42961872e-04,\n",
              "        1.00486341e-03, 1.64963381e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.59600353e-04, 2.55834152e-04, 2.19543150e-04,\n",
              "        9.61011320e-05, 0.00000000e+00, 2.33970879e-04, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.90588502e-04,\n",
              "        9.05742862e-05, 1.35951400e-04, 0.00000000e+00, 1.66499396e-04,\n",
              "        1.33280925e-04, 0.00000000e+00, 2.26878468e-04, 2.16437463e-04,\n",
              "        8.36902057e-05, 0.00000000e+00, 0.00000000e+00, 1.74343977e-04,\n",
              "        2.92159703e-04, 2.80982582e-04, 1.61779330e-04, 2.23989117e-04,\n",
              "        0.00000000e+00, 8.45432416e-05, 1.94397884e-04, 2.62395806e-04,\n",
              "        0.00000000e+00, 0.00000000e+00, 6.37166861e-05, 0.00000000e+00,\n",
              "        1.70385774e-04, 0.00000000e+00, 1.06674622e-04, 1.13289183e-04,\n",
              "        1.60797451e-04, 2.15581443e-03, 7.79638232e-05, 2.33188952e-04,\n",
              "        1.37670939e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 6.61104412e-05, 2.62139119e-04, 0.00000000e+00,\n",
              "        4.43211353e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.01762837e-04, 1.54844863e-04, 0.00000000e+00,\n",
              "        2.82736354e-04, 0.00000000e+00, 3.34597269e-04, 0.00000000e+00,\n",
              "        1.96846649e-04, 9.67884999e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.62801564e-04, 7.60759876e-05, 1.44097712e-04,\n",
              "        0.00000000e+00, 1.44621133e-04, 2.04366676e-04, 6.21499023e-05,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.19899412e-04, 3.79326504e-04,\n",
              "        1.10267126e-04, 2.84018662e-04, 1.81392327e-04, 0.00000000e+00,\n",
              "        5.71858778e-05, 9.60078670e-05, 0.00000000e+00, 1.01343591e-04,\n",
              "        1.79965419e-04, 0.00000000e+00, 1.80595462e-04, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 4.71159029e-05, 0.00000000e+00,\n",
              "        1.08067649e-04, 0.00000000e+00, 2.98405229e-03, 5.46436755e-04,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.61702884e-04,\n",
              "        5.64347202e-05, 0.00000000e+00, 1.10847092e-04, 7.31952027e-05,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.67053906e-03,\n",
              "        0.00000000e+00, 7.79139368e-05, 1.25733161e-04, 0.00000000e+00,\n",
              "        1.20245341e-04, 8.67603080e-05, 2.40421647e-03, 4.71134900e-05,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.96694247e-04,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 6.92041704e-05, 0.00000000e+00, 1.54319666e-04,\n",
              "        0.00000000e+00, 8.89572915e-05, 1.77628210e-04, 4.43819678e-04,\n",
              "        1.46945833e-04, 0.00000000e+00, 0.00000000e+00, 2.83842476e-04,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.29048524e-05,\n",
              "        1.14967664e-04, 0.00000000e+00, 0.00000000e+00, 9.50840691e-04,\n",
              "        2.70675553e-05, 9.53968003e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.30008897e-04, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 3.44754499e-04, 7.31047107e-04,\n",
              "        1.09241863e-04, 1.29158366e-04, 1.51473491e-04, 3.38734760e-04,\n",
              "        2.65059121e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.68396283e-04, 1.32044759e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.49872854e-04, 9.26700354e-05, 0.00000000e+00, 1.50657709e-04,\n",
              "        0.00000000e+00, 1.45087295e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.57575787e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        2.48044649e-04, 0.00000000e+00, 5.84779296e-05, 1.44542675e-04,\n",
              "        3.31745745e-04, 0.00000000e+00, 2.24075294e-04, 9.09048491e-05,\n",
              "        4.23017936e-04, 3.02132369e-04, 0.00000000e+00, 7.49436635e-05,\n",
              "        1.82280919e-04, 2.80007383e-03, 0.00000000e+00, 1.31114040e-04,\n",
              "        1.08205415e-04, 0.00000000e+00, 7.57766712e-05, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.01653768e-03,\n",
              "        9.43773373e-05, 0.00000000e+00, 7.85396687e-05, 2.54008697e-04,\n",
              "        0.00000000e+00, 1.61084499e-04, 1.40969596e-03, 2.84793347e-04,\n",
              "        1.67987870e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        2.73919751e-03, 5.24693968e-04, 0.00000000e+00, 2.30032225e-04,\n",
              "        0.00000000e+00, 7.28532590e-05, 1.29892192e-04, 0.00000000e+00,\n",
              "        1.99411719e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.43298777e-04, 0.00000000e+00, 5.44144954e-05,\n",
              "        1.24395620e-04, 0.00000000e+00, 2.12995458e-03, 0.00000000e+00,\n",
              "        1.22893564e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.61141810e-03,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        8.46606347e-05, 1.37720659e-04, 0.00000000e+00, 1.03122427e-04,\n",
              "        5.52946915e-05, 0.00000000e+00, 0.00000000e+00, 1.49434892e-04,\n",
              "        0.00000000e+00, 0.00000000e+00, 6.61839078e-04, 0.00000000e+00,\n",
              "        0.00000000e+00, 5.93078088e-05, 6.79486469e-04, 1.07353551e-04,\n",
              "        9.95922550e-05, 2.69176936e-03, 0.00000000e+00, 3.57029350e-04,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.16266218e-04,\n",
              "        1.45892659e-04, 0.00000000e+00, 1.03167265e-04, 0.00000000e+00,\n",
              "        5.17808709e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.32175525e-03, 8.02166529e-05,\n",
              "        0.00000000e+00, 1.30169330e-04, 1.26838559e-04, 1.18155726e-04,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.87346789e-04, 0.00000000e+00,\n",
              "        0.00000000e+00, 5.24609732e-05, 1.01698467e-04, 5.34947539e-05,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        3.25945827e-04, 8.37795424e-05, 0.00000000e+00, 1.36162685e-04,\n",
              "        7.25219939e-05, 0.00000000e+00, 1.71446865e-04, 1.62120076e-04,\n",
              "        1.10103693e-04, 0.00000000e+00, 6.15092950e-05, 0.00000000e+00,\n",
              "        0.00000000e+00, 7.55952191e-05, 3.47520413e-05, 1.33384267e-04,\n",
              "        1.06944317e-04, 0.00000000e+00, 0.00000000e+00, 2.29995516e-03,\n",
              "        1.17232585e-04, 2.94542587e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 5.52573404e-04, 1.58301204e-04, 0.00000000e+00,\n",
              "        0.00000000e+00, 8.87148581e-05, 0.00000000e+00, 1.43652553e-03,\n",
              "        0.00000000e+00, 0.00000000e+00, 8.95148453e-05, 5.98469577e-05,\n",
              "        0.00000000e+00, 7.09351329e-05, 2.05046055e-04, 3.82070069e-05,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 2.72333306e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.12117649e-04, 1.30182518e-04, 2.51189276e-03, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.57983023e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "        4.24356674e-05, 0.00000000e+00, 2.06534031e-03, 0.00000000e+00,\n",
              "        1.31241543e-04, 1.06428298e-03, 9.52118558e-05, 0.00000000e+00,\n",
              "        2.99829631e-04, 0.00000000e+00, 0.00000000e+00, 8.23975989e-05,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.26782527e-04, 1.87827567e-04,\n",
              "        0.00000000e+00, 2.64462781e-03, 0.00000000e+00, 4.91726925e-03,\n",
              "        0.00000000e+00, 3.96115071e-04, 4.54060407e-04, 0.00000000e+00,\n",
              "        1.24284932e-04, 1.23792896e-04, 0.00000000e+00, 9.93480349e-05,\n",
              "        3.43065695e-05, 8.33507261e-05, 1.22002270e-04, 4.22810731e-05,\n",
              "        1.27052954e-04, 7.21055990e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.99361082e-04, 1.05186927e-04, 7.58583329e-05,\n",
              "        1.33259854e-04, 2.55783826e-04, 1.15823834e-04, 2.38682458e-04,\n",
              "        0.00000000e+00, 7.92992667e-05, 3.01262811e-04, 6.43041737e-05]),\n",
              " 'std_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.03496111,        nan, 0.03337821,        nan,        nan,\n",
              "               nan, 0.03337821,        nan,        nan, 0.03337821,\n",
              "        0.03337821, 0.03337821, 0.03337821,        nan,        nan,\n",
              "               nan, 0.03387586, 0.03337821,        nan,        nan,\n",
              "               nan, 0.03301773, 0.03744887, 0.03337821,        nan,\n",
              "        0.03337821, 0.03337821, 0.03337821, 0.03337821,        nan,\n",
              "               nan, 0.03337821,        nan,        nan,        nan,\n",
              "        0.03337821, 0.03337821,        nan, 0.03337821,        nan,\n",
              "               nan,        nan, 0.0342464 ,        nan,        nan,\n",
              "        0.03301773, 0.0359934 ,        nan, 0.02931256, 0.03744887,\n",
              "               nan,        nan, 0.0359934 ,        nan,        nan,\n",
              "        0.03224057, 0.03337821, 0.03337821,        nan, 0.03496111,\n",
              "        0.03224057, 0.03337821,        nan, 0.03337821,        nan,\n",
              "        0.03337821,        nan, 0.03337821,        nan,        nan,\n",
              "               nan,        nan, 0.03337821, 0.03337821, 0.03496111,\n",
              "        0.03337821, 0.03337821, 0.03337821, 0.03232335, 0.03224057,\n",
              "               nan,        nan,        nan, 0.0359934 , 0.03337821,\n",
              "        0.03337821, 0.03337821,        nan, 0.03337821,        nan,\n",
              "               nan,        nan,        nan, 0.03301773, 0.03337821,\n",
              "        0.03494062,        nan, 0.0359934 , 0.03744887,        nan,\n",
              "        0.03337821, 0.0359934 , 0.03496111,        nan,        nan,\n",
              "        0.03337821, 0.03337821, 0.03337821, 0.0359934 , 0.03337821,\n",
              "               nan, 0.03337821, 0.03337821, 0.03667444,        nan,\n",
              "               nan, 0.03496111,        nan, 0.03337821,        nan,\n",
              "        0.03496111, 0.03337821, 0.03337821, 0.03337821, 0.03301773,\n",
              "        0.03337821, 0.03337821,        nan,        nan,        nan,\n",
              "               nan, 0.03337821, 0.03337821,        nan, 0.03337821,\n",
              "               nan,        nan,        nan,        nan, 0.03337821,\n",
              "        0.0359934 ,        nan, 0.03337821,        nan, 0.0342464 ,\n",
              "               nan, 0.03337821, 0.03337821,        nan,        nan,\n",
              "               nan, 0.03667444, 0.03337821, 0.03337821,        nan,\n",
              "        0.03337821, 0.0359934 , 0.03301773,        nan,        nan,\n",
              "        0.03667444, 0.03789481, 0.03027635, 0.02814202, 0.03337821,\n",
              "               nan, 0.03337821, 0.03337821,        nan, 0.03301773,\n",
              "        0.03337821,        nan, 0.0359934 ,        nan,        nan,\n",
              "               nan, 0.03337821,        nan, 0.03337821,        nan,\n",
              "        0.03337821, 0.03337821,        nan,        nan,        nan,\n",
              "        0.03337821, 0.03337821,        nan, 0.03744887, 0.03337821,\n",
              "               nan,        nan,        nan, 0.03224057,        nan,\n",
              "        0.03337821, 0.03494062,        nan, 0.03337821, 0.03337821,\n",
              "        0.03383883, 0.03337821,        nan,        nan,        nan,\n",
              "        0.03789481,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.03337821,        nan, 0.03337821,        nan,\n",
              "        0.03323884, 0.03301773, 0.03337821, 0.03337821,        nan,\n",
              "               nan, 0.03337821,        nan,        nan,        nan,\n",
              "        0.03337821, 0.03337821,        nan,        nan, 0.03337821,\n",
              "        0.03337821, 0.03337821,        nan,        nan,        nan,\n",
              "               nan, 0.03337821,        nan,        nan,        nan,\n",
              "        0.03337821, 0.03337821, 0.03494062, 0.03337821, 0.03337821,\n",
              "        0.03383883, 0.03337821,        nan,        nan,        nan,\n",
              "        0.03337821, 0.03337821,        nan,        nan, 0.03337821,\n",
              "        0.03337821,        nan, 0.03337821,        nan, 0.03301773,\n",
              "               nan,        nan, 0.03337821,        nan,        nan,\n",
              "               nan, 0.03337821,        nan, 0.03224057, 0.03337821,\n",
              "        0.03337821,        nan, 0.03337821, 0.03667444, 0.03337821,\n",
              "        0.03337821,        nan, 0.03337821, 0.03337821, 0.03337821,\n",
              "               nan, 0.02931256, 0.03337821,        nan, 0.03337821,\n",
              "               nan,        nan,        nan,        nan, 0.03337821,\n",
              "        0.03224057,        nan, 0.0342464 , 0.03337821,        nan,\n",
              "        0.03337821, 0.03337821, 0.03337821, 0.03337821,        nan,\n",
              "               nan,        nan, 0.03496111, 0.0359934 ,        nan,\n",
              "        0.03337821,        nan, 0.03494062, 0.03337821,        nan,\n",
              "        0.03496111,        nan,        nan,        nan,        nan,\n",
              "        0.03337821,        nan, 0.03337821, 0.03337821,        nan,\n",
              "        0.03337821,        nan, 0.0359934 ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.03337821,\n",
              "               nan,        nan,        nan,        nan, 0.03494062,\n",
              "        0.02931256,        nan, 0.03224057, 0.03337821,        nan,\n",
              "               nan, 0.03337821,        nan,        nan, 0.03337821,\n",
              "               nan,        nan, 0.03337821, 0.03337821, 0.02931256,\n",
              "        0.03337821, 0.03337821,        nan, 0.03337821,        nan,\n",
              "               nan,        nan, 0.03789481, 0.03224057,        nan,\n",
              "        0.03337821,        nan, 0.02959386,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.03337821, 0.03301773,\n",
              "               nan, 0.03224057, 0.03337821, 0.03337821,        nan,\n",
              "               nan, 0.03337821,        nan,        nan, 0.03337821,\n",
              "        0.03337821, 0.03337821,        nan,        nan,        nan,\n",
              "               nan, 0.03496111, 0.03496111,        nan, 0.03337821,\n",
              "        0.03496111,        nan, 0.03337821, 0.0359934 , 0.03496111,\n",
              "               nan, 0.03564148,        nan,        nan, 0.03337821,\n",
              "        0.03224057, 0.03337821, 0.03337821,        nan,        nan,\n",
              "        0.03337821, 0.03337821, 0.03224057,        nan,        nan,\n",
              "               nan, 0.03301773, 0.03337821,        nan,        nan,\n",
              "        0.03337821,        nan, 0.03337821,        nan,        nan,\n",
              "        0.03744887, 0.03337821,        nan, 0.03337821, 0.03224057,\n",
              "        0.03337821,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.03337821,        nan,        nan, 0.03337821,\n",
              "        0.03337821, 0.03744887,        nan,        nan, 0.03337821,\n",
              "               nan,        nan, 0.03337821,        nan, 0.03337821,\n",
              "               nan, 0.03337821, 0.03337821, 0.03337821,        nan,\n",
              "        0.0342464 ,        nan,        nan, 0.03494062,        nan,\n",
              "               nan, 0.03337821, 0.03224057,        nan, 0.03667444,\n",
              "               nan, 0.03337821,        nan, 0.03789481, 0.03337821,\n",
              "               nan, 0.03667444, 0.03337821,        nan, 0.03337821,\n",
              "        0.03337821, 0.03667444, 0.03224057, 0.03337821, 0.0342464 ,\n",
              "        0.03496111,        nan,        nan,        nan, 0.03224057,\n",
              "        0.03337821, 0.03494062, 0.03337821, 0.03337821, 0.0342464 ,\n",
              "        0.03023446,        nan, 0.03337821, 0.0342464 , 0.03224057])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUMyVqFBLopV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJjgexor-v10",
        "outputId": "4477a759-ba35-4c7b-8b65-53b9d0e4dc81"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "d_clf=DecisionTreeClassifier()\n",
        "\n",
        "cri=['gini', 'entropy']\n",
        "split=['best','random']\n",
        "max_d=list(np.arange(10,500,2))\n",
        "min_ss=[1,2,3,4]\n",
        "min_samples_leaf = [1,2,3,4]\n",
        "max_features = ['auto', 'sqrt', 'log2']\n",
        "max_features.append(None)\n",
        "\n",
        "\n",
        "d_params = { \"criterion\" : cri,\n",
        "           \"splitter\" : split,\n",
        "            'max_depth':max_d,\n",
        "           \"min_samples_split\" :min_ss,\n",
        "           \"min_samples_leaf\" : min_samples_leaf,\n",
        "           \"max_features\" : max_features\n",
        "}\n",
        "\n",
        "rscv_dclf=RandomizedSearchCV(d_clf,d_params,500,scoring='accuracy',n_jobs=-1,cv=5,verbose=1,random_state=2)\n",
        "rscv_dclf.fit(x_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 956 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed:    7.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features=None,\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    presort='deprecated',\n",
              "                                                    random_state=None,\n",
              "                                                    splitter='best'),\n",
              "                   i...\n",
              "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
              "                                        'max_depth': [10, 12, 14, 16, 18, 20,\n",
              "                                                      22, 24, 26, 28, 30, 32,\n",
              "                                                      34, 36, 38, 40, 42, 44,\n",
              "                                                      46, 48, 50, 52, 54, 56,\n",
              "                                                      58, 60, 62, 64, 66, 68, ...],\n",
              "                                        'max_features': ['auto', 'sqrt', 'log2',\n",
              "                                                         None],\n",
              "                                        'min_samples_leaf': [1, 2, 3, 4],\n",
              "                                        'min_samples_split': [1, 2, 3, 4],\n",
              "                                        'splitter': ['best', 'random']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=2, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zse_b14WPseh",
        "outputId": "ba752db5-722a-441e-e263-d2eb0c4d2928"
      },
      "source": [
        "rscv_dclf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=146, max_features='log2', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=4, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXJY5OrwP_D5",
        "outputId": "1d4540b5-b141-41ef-b003-38738b7b71d8"
      },
      "source": [
        "rscv_dclf.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7877094972067039"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnQdsriqvMAQ"
      },
      "source": [
        "dclf_best=clone(rscv_dclf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM_CaAUhVMl6",
        "outputId": "b78444a9-29b5-46ca-af58-34c0938a4092"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "n_esti=list(np.arange(100,300,4))\n",
        "max_features = ['auto', 'sqrt','log2','None']\n",
        "#\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [1,2,3]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2,3,4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_esti,\n",
        "               'max_features': max_features,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "rf=RandomForestClassifier()\n",
        "\n",
        "rscv_rf=RandomizedSearchCV(rf,random_grid,500,scoring='accuracy',n_jobs=-1,cv=5,verbose=1,random_state=20)\n",
        "rscv_rf.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   34.5s\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1246 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=-1)]: Done 1796 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=-1)]: Done 2446 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed:  7.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_features': ['auto', 'sqrt', 'log2',\n",
              "                                                         'None'],\n",
              "                                        'min_samples_leaf': [1, 2, 3, 4],\n",
              "                                        'min_samples_split': [1, 2, 3],\n",
              "                                        'n_estimators': [100, 104, 108, 112,\n",
              "                                                         116, 120, 124, 128,\n",
              "                                                         132, 136, 140, 144,\n",
              "                                                         148, 152, 156, 160,\n",
              "                                                         164, 168, 172, 176,\n",
              "                                                         180, 184, 188, 192,\n",
              "                                                         196, 200, 204, 208,\n",
              "                                                         212, 216, ...]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=20, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgWtFiY5Z3sH",
        "outputId": "d8cfb0da-9a57-4e60-c7f1-8916d00f2388"
      },
      "source": [
        "rscv_rf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='log2',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=3, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=120,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WbUnNzUZ_H0",
        "outputId": "068388f5-a07b-4821-fb80-a7f51d4c1143"
      },
      "source": [
        "rscv_rf.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8379888268156425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjoFLfkEvlda"
      },
      "source": [
        "rf_best=clone(rscv_rf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jw85aGxjuek"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "c=[0.1,0.2,0.5,1.0,1.5,2.0,2.5,3.0]\n",
        "kernel=['linear', 'poly', 'rbf', 'sigmoid']\n",
        "decision_function_shape=['ovo', 'ovr']\n",
        "gamma=['scale', 'auto']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J8XsPd4oulU"
      },
      "source": [
        "svm_params={\n",
        "            'C':c,\n",
        "            'kernel':kernel,\n",
        "            'decision_function_shape':decision_function_shape,\n",
        "            'gamma':gamma,\n",
        "          \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "48bNNE7XpJqH",
        "outputId": "00d40558-67a3-4289-ed01-dff22369f257"
      },
      "source": [
        "svm=SVC(probability=True)\n",
        "rs_svm=RandomizedSearchCV(svm,svm_params,100,scoring='accuracy',n_jobs=-1,cv=5,verbose=1,random_state=21)\n",
        "rs_svm.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    5.3s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-200-02b9b0bc1dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrs_svm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msvm_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrs_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ6dn84XqjEK",
        "outputId": "87dfa680-a42e-4d9a-ad4d-c44a1ef7469f"
      },
      "source": [
        "rs_svm.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
              "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "JaCxiHCnqnM6",
        "outputId": "177b663d-3187-46e5-9d11-b07fc17a9ab4"
      },
      "source": [
        "rs_svm.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-199-0230cf5e5481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrs_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    446\u001b[0m                              % self.best_estimator_)\n\u001b[1;32m    447\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    167\u001b[0m                           stacklevel=2)\n\u001b[1;32m    168\u001b[0m         return self._score(partial(_cached_call, None), estimator, X, y_true,\n\u001b[0;32m--> 169\u001b[0;31m                            sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_factory_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \"\"\"\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \"\"\"\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=np.float64, order=\"C\",\n\u001b[0;32m--> 447\u001b[0;31m                         accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzF6w1YMudQV"
      },
      "source": [
        "svm_best=clone(rs_svm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02Q0QRV_zD6a",
        "outputId": "77d0d8fc-ee74-443d-ecaf-c5b242c9b1c4"
      },
      "source": [
        "rs_svm.predict(x_test.head(n=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KpgLuOgzfKL"
      },
      "source": [
        "x_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK2sqCLFzWWP"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAJY3K77v6is",
        "outputId": "8bf4f55f-a2bd-4ef4-8f70-c4289448bd61"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "estimator=[('knn', knn_best), ('lr', lt_best)]\n",
        "\n",
        "vc = VotingClassifier(estimators=estimator,n_jobs=-1,voting='soft')\n",
        "vc.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('knn',\n",
              "                              RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                                                 estimator=KNeighborsClassifier(algorithm='auto',\n",
              "                                                                                leaf_size=30,\n",
              "                                                                                metric='minkowski',\n",
              "                                                                                metric_params=None,\n",
              "                                                                                n_jobs=None,\n",
              "                                                                                n_neighbors=5,\n",
              "                                                                                p=2,\n",
              "                                                                                weights='uniform'),\n",
              "                                                 iid='deprecated', n_iter=100,\n",
              "                                                 n_jobs=-1,\n",
              "                                                 param_distributions={'algorithm': ['auto',\n",
              "                                                                                    'ball_tree',\n",
              "                                                                                    'kd_tree',\n",
              "                                                                                    'brute'],\n",
              "                                                                      'leaf_size': [1,\n",
              "                                                                                    2...\n",
              "                                                                                            2.5000000000000004,\n",
              "                                                                                            2.6,\n",
              "                                                                                            2.7,\n",
              "                                                                                            2.8000000000000003,\n",
              "                                                                                            2.9000000000000004,\n",
              "                                                                                            3.0000000000000004, ...],\n",
              "                                                                      'penalty': ['l1',\n",
              "                                                                                  'l2',\n",
              "                                                                                  'elasticnet',\n",
              "                                                                                  'none'],\n",
              "                                                                      'solver': ['newton-cg',\n",
              "                                                                                 'lbfgs',\n",
              "                                                                                 'liblinear',\n",
              "                                                                                 'sag',\n",
              "                                                                                 'saga']},\n",
              "                                                 pre_dispatch='2*n_jobs',\n",
              "                                                 random_state=20, refit=True,\n",
              "                                                 return_train_score=False,\n",
              "                                                 scoring='accuracy',\n",
              "                                                 verbose=1))],\n",
              "                 flatten_transform=True, n_jobs=-1, voting='soft',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rYY4dpd-HBZ"
      },
      "source": [
        "VotingClassifier?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGgYUG2Wyy_1",
        "outputId": "0543fb31-9dc3-45bf-a110-03240b7752b0"
      },
      "source": [
        "vc.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8268156424581006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub_iZgoV1V2J",
        "outputId": "8ba4be25-597d-40a5-d06e-270832959d60"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada=AdaBoostClassifier(base_estimator=rf,n_estimators=100,learning_rate=0.3,random_state=2)\n",
        "ada.fit(x_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                   base_estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                         ccp_alpha=0.0,\n",
              "                                                         class_weight=None,\n",
              "                                                         criterion='gini',\n",
              "                                                         max_depth=None,\n",
              "                                                         max_features='auto',\n",
              "                                                         max_leaf_nodes=None,\n",
              "                                                         max_samples=None,\n",
              "                                                         min_impurity_decrease=0.0,\n",
              "                                                         min_impurity_split=None,\n",
              "                                                         min_samples_leaf=1,\n",
              "                                                         min_samples_split=2,\n",
              "                                                         min_weight_fraction_leaf=0.0,\n",
              "                                                         n_estimators=100,\n",
              "                                                         n_jobs=None,\n",
              "                                                         oob_score=False,\n",
              "                                                         random_state=None,\n",
              "                                                         verbose=0,\n",
              "                                                         warm_start=False),\n",
              "                   learning_rate=0.3, n_estimators=100, random_state=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpPm6MHH4cqw",
        "outputId": "086f2baf-a3f5-4838-ade8-0c3ce509891a"
      },
      "source": [
        "ada.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8156424581005587"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "fC6c2-ZHtG1S",
        "outputId": "2dc6e391-3349-4abb-bda1-a51767729e8c"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-97c983fd-db8e-46a1-b0b1-f063c902d55c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-97c983fd-db8e-46a1-b0b1-f063c902d55c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.csv to test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8zy0Ak845sC"
      },
      "source": [
        "test_data=pd.read_csv('/content/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHEwy2Zi5EEd"
      },
      "source": [
        "test_data['Sex']=en.fit_transform(test_data['Sex'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVOuES165p3m"
      },
      "source": [
        "test_data=pd.concat((test_data,pd.get_dummies(test_data['Embarked'])),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "HCbDF3jD66D7",
        "outputId": "350da85c-eed1-4a2d-e64c-b08e3400c8db"
      },
      "source": [
        "test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>C</th>\n",
              "      <th>Q</th>\n",
              "      <th>S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>27.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1306</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>108.9000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1307</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>27.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>27.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>22.3583</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows  10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Pclass  Sex   Age  SibSp  Parch      Fare  C  Q  S\n",
              "0            892       3    1  34.5      0      0    7.8292  0  1  0\n",
              "1            893       3    0  47.0      1      0    7.0000  0  0  1\n",
              "2            894       2    1  62.0      0      0    9.6875  0  1  0\n",
              "3            895       3    1  27.0      0      0    8.6625  0  0  1\n",
              "4            896       3    0  22.0      1      1   12.2875  0  0  1\n",
              "..           ...     ...  ...   ...    ...    ...       ... .. .. ..\n",
              "413         1305       3    1  27.5      0      0    8.0500  0  0  1\n",
              "414         1306       1    0  39.0      0      0  108.9000  1  0  0\n",
              "415         1307       3    1  38.5      0      0    7.2500  0  0  1\n",
              "416         1308       3    1  27.5      0      0    8.0500  0  0  1\n",
              "417         1309       3    1  27.5      1      1   22.3583  1  0  0\n",
              "\n",
              "[418 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0aui0Vl6XFO"
      },
      "source": [
        "test_data.drop(['Name','Ticket','Cabin','Embarked'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waiEQKRjAYa8",
        "outputId": "773231aa-1bd6-4877-f701-2bcf260a2a0c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27.0, 28.0, 30.272590361445783, 29.36158249158249)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3igSn3yAGws"
      },
      "source": [
        "test_data['Age'].fillna((data['Age'].median()+test_data['Age'].median())/2,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBvcidmyA--h",
        "outputId": "6797fab7-11e6-4eac-f449-8082e519dbbb"
      },
      "source": [
        "test_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId    0\n",
              "Pclass         0\n",
              "Sex            0\n",
              "Age            0\n",
              "SibSp          0\n",
              "Parch          0\n",
              "Fare           0\n",
              "C              0\n",
              "Q              0\n",
              "S              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMWkA-G5BiHm"
      },
      "source": [
        "test_data['Fare'].fillna(test_data['Fare'].mean(),inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZnM8Tf47Hcx"
      },
      "source": [
        "x_test_data=test_data.drop('PassengerId',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5GndgbD70AR"
      },
      "source": [
        "ssvc=SVC(C=2.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "    decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
        "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
        "    verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYFrXkc78CIC",
        "outputId": "1c6bb513-eb59-4aba-8a3c-540841024757"
      },
      "source": [
        "ssvc.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
              "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFiLxedQ8MZM",
        "outputId": "441b29a1-ceec-4676-ea16-035e0956f4e7"
      },
      "source": [
        "ssvc.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8435754189944135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 335
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuHzGR_JCLvj"
      },
      "source": [
        "for a in x_test_data.columns:\n",
        "  x_test_data[a]=s.transform(x_test_data[a].values.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daELWnpmEv-l",
        "outputId": "152c29d0-d1eb-4281-dca9-69076696f30e"
      },
      "source": [
        "x_test_data.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass     3.446566\n",
              "Sex       -0.193063\n",
              "Age       64.740378\n",
              "SibSp     -0.615281\n",
              "Parch     -0.738206\n",
              "Fare      77.977002\n",
              "C         -1.069567\n",
              "Q         -1.368861\n",
              "S         -0.171685\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYUwOuYZCXtS",
        "outputId": "9d62a637-ab44-4263-fb99-1a2fe11f25ec"
      },
      "source": [
        "x_test.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass    0.071892\n",
              "Sex       0.094512\n",
              "Age      -0.068144\n",
              "SibSp     0.007003\n",
              "Parch    -0.022921\n",
              "Fare      0.060369\n",
              "C         0.046406\n",
              "Q         0.050319\n",
              "S        -0.067123\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWIgK29v7Xqu"
      },
      "source": [
        "ans=ssvc.predict(x_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qsLJFgnGgoV",
        "outputId": "42002304-3598-4a0c-f8ae-7581d4e4bbe9"
      },
      "source": [
        "ans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sESYCfquHr91"
      },
      "source": [
        "d={'PassengerId':test_data['PassengerId'],\n",
        "   'Survived':ans}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpJeScI1HkrA"
      },
      "source": [
        "ans_data=pd.DataFrame(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyLS1H2CH_kk"
      },
      "source": [
        "ans_data.to_csv('submission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "L2-SGjqGI7eu",
        "outputId": "bccd5da7-16c3-40eb-b336-8d04d8282e45"
      },
      "source": [
        "ans_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1306</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1307</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived\n",
              "0            892         0\n",
              "1            893         0\n",
              "2            894         0\n",
              "3            895         0\n",
              "4            896         0\n",
              "..           ...       ...\n",
              "413         1305         0\n",
              "414         1306         0\n",
              "415         1307         0\n",
              "416         1308         0\n",
              "417         1309         0\n",
              "\n",
              "[418 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 352
        }
      ]
    }
  ]
}